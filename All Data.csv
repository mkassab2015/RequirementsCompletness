Covidence #,Study ID,Title,Reviewer Name,Should this paper be included in our research?,1. Study ID,2. Title,3. Countries of the authors,4. Year of Publication,5. Publication Type,6. Name of the venue,7. Paper Abstract ,8. Does the paper define completeness of requirements ,"9. If yes, list the definitions provided", 10. Does the paper propose or reference any methods or techniques used to detect incompleteness of requirements?,"11. If yes, list all methods or techniques used to detect incompleteness of requirements:",1 Name,1 Description,1 Proposed/Referenced,1 Reference (if applicable),1 Detection Process,2 Name,2 Description,2 Proposed/Referenced,2 Reference (if applicable),2 Detection Process,3 Name,3 Description,3 Proposed/Referenced,3 Reference (if applicable),3 Detection Process,4 Name,4 Description,4 Proposed/Referenced,4 Reference (if applicable),4 Detection Process,5 Name,5 Description,5 Proposed/Referenced,5 Reference (if applicable),5 Detection Process,6 Name,6 Description,6 Proposed/Referenced,6 Reference (if applicable),6 Detection Process,7 Name,7 Description,7 Proposed/Referenced,7 Reference (if applicable),7 Detection Process,8 Name,8 Description,8 Proposed/Referenced,8 Reference (if applicable),8 Detection Process,9 Name,9 Description,9 Proposed/Referenced,9 Reference (if applicable),9 Detection Process,10 Name,10 Description,10 Proposed/Referenced,10 Reference (if applicable),10 Detection Process,12. Does the paper suggest methods to quantify the completeness of requirements?,"13. If yes, what were the specific metrics or criteria used for quantification::",1 Name,1 Description,1 Formula,1 Proposed/Referenced,1 Reference (if applicable),2 Name,2 Description,2 Formula,2 Proposed/Referenced,2 Reference (if applicable),3 Name,3 Description,3 Formula,3 Proposed/Referenced,3 Reference (if applicable),4 Name,4 Description,4 Formula,4 Proposed/Referenced,4 Reference (if applicable),5 Name,5 Description,5 Formula,5 Proposed/Referenced,5 Reference (if applicable),6 Name,6 Description,6 Formula,6 Proposed/Referenced,6 Reference (if applicable),7 Name,7 Description,7 Formula,7 Proposed/Referenced,7 Reference (if applicable),8 Name,8 Description,8 Formula,8 Proposed/Referenced,8 Reference (if applicable),9 Name,9 Description,9 Formula,9 Proposed/Referenced,9 Reference (if applicable),10 Name,10 Description,10 Formula,10 Proposed/Referenced,10 Reference (if applicable),14. What methodologies were used to quantify completeness?:,1 Name,1 Description,1 Proposed/Referenced,1 Reference (if applicable),1 Quantification Process,2 Name,2 Description,2 Proposed/Referenced,2 Reference (if applicable),2 Quantification Process,3 Name,3 Description,3 Proposed/Referenced,3 Reference (if applicable),3 Quantification Process,4 Name,4 Description,4 Proposed/Referenced,4 Reference (if applicable),4 Quantification Process,5 Name,5 Description,5 Proposed/Referenced,5 Reference (if applicable),5 Quantification Process,6 Name,6 Description,6 Proposed/Referenced,6 Reference (if applicable),6 Quantification Process,7 Name,7 Description,7 Proposed/Referenced,7 Reference (if applicable),7 Quantification Process,8 Name,8 Description,8 Proposed/Referenced,8 Reference (if applicable),8 Quantification Process,9 Name,9 Description,9 Proposed/Referenced,9 Reference (if applicable),9 Quantification Process,10 Name,10 Description,10 Proposed/Referenced,10 Reference (if applicable),10 Quantification Process,"15. Does the paper propose or reference any concepts, methods, or frameworks to correct the completeness of requirements?","16. If yes, list all methods or concepts used for correction:",1 Name,1 Description,1 Proposed/Referenced,1 Reference (if applicable),1 Process,2 Name,2 Description,2 Proposed/Referenced,2 Reference (if applicable),2 Process,3 Name,3 Description,3 Proposed/Referenced,3 Reference (if applicable),3 Process,4 Name,4 Description,4 Proposed/Referenced,4 Reference (if applicable),4 Process,5 Name,5 Description,5 Proposed/Referenced,5 Reference (if applicable),5 Process,6 Name,6 Description,6 Proposed/Referenced,6 Reference (if applicable),6 Process,7 Name,7 Description,7 Proposed/Referenced,7 Reference (if applicable),7 Process,8 Name,8 Description,8 Proposed/Referenced,8 Reference (if applicable),8 Process,9 Name,9 Description,9 Proposed/Referenced,9 Reference (if applicable),9 Process,10 Name,10 Description,10 Proposed/Referenced,10 Reference (if applicable),10 Process,17. How were these methods or concepts evaluated?,18. Does the paper propose or reference any tools for achieving or measuring the completeness of requirements?,19.  Tools:,1 Tool Name,1 Proposed/Referenced,1 Reference (if applicable),"1 Purpose (Detect, Measure, Correct, Other)",1 Description of Tool Implementation,1 Description of Functionality,"1 Status (Proposed, Implemented, Validated)",1 Method of Validation (if applicable),2 Tool Name,2 Proposed/Referenced,2 Reference (if applicable),"2 Purpose (Detect, Measure, Correct, Other)",2 Description of Tool Implementation,2 Description of Functionality,"2 Status (Proposed, Implemented, Validated)",2 Method of Validation (if applicable),3 Tool Name,3 Proposed/Referenced,3 Reference (if applicable),"3 Purpose (Detect, Measure, Correct, Other)",3 Description of Tool Implementation,3 Description of Functionality,"3 Status (Proposed, Implemented, Validated)",3 Method of Validation (if applicable),4 Tool Name,4 Proposed/Referenced,4 Reference (if applicable),"4 Purpose (Detect, Measure, Correct, Other)",4 Description of Tool Implementation,4 Description of Functionality,"4 Status (Proposed, Implemented, Validated)",4 Method of Validation (if applicable),5 Tool Name,5 Proposed/Referenced,5 Reference (if applicable),"5 Purpose (Detect, Measure, Correct, Other)",5 Description of Tool Implementation,5 Description of Functionality,"5 Status (Proposed, Implemented, Validated)",5 Method of Validation (if applicable),6 Tool Name,6 Proposed/Referenced,6 Reference (if applicable),"6 Purpose (Detect, Measure, Correct, Other)",6 Description of Tool Implementation,6 Description of Functionality,"6 Status (Proposed, Implemented, Validated)",6 Method of Validation (if applicable),7 Tool Name,7 Proposed/Referenced,7 Reference (if applicable),"7 Purpose (Detect, Measure, Correct, Other)",7 Description of Tool Implementation,7 Description of Functionality,"7 Status (Proposed, Implemented, Validated)",7 Method of Validation (if applicable),8 Tool Name,8 Proposed/Referenced,8 Reference (if applicable),"8 Purpose (Detect, Measure, Correct, Other)",8 Description of Tool Implementation,8 Description of Functionality,"8 Status (Proposed, Implemented, Validated)",8 Method of Validation (if applicable),9 Tool Name,9 Proposed/Referenced,9 Reference (if applicable),"9 Purpose (Detect, Measure, Correct, Other)",9 Description of Tool Implementation,9 Description of Functionality,"9 Status (Proposed, Implemented, Validated)",9 Method of Validation (if applicable),10 Tool Name,10 Proposed/Referenced,10 Reference (if applicable),"10 Purpose (Detect, Measure, Correct, Other)",10 Description of Tool Implementation,10 Description of Functionality,"10 Status (Proposed, Implemented, Validated)",10 Method of Validation (if applicable),20. Does the paper mention the use of Artificial Intelligence (AI) or Large Language Models (LLMs) in the context of requirements?,21. AI/LLMs:,1 Model Used or Proposed,1 Purpose (Detecting/Measuring/Quantifying/Other),1 Details/Description,1 Proposed/Referenced,1 Reference (if applicable),2 Model Used or Proposed,2 Purpose (Detecting/Measuring/Quantifying/Other),2 Details/Description,2 Proposed/Referenced,2 Reference (if applicable),3 Model Used or Proposed,3 Purpose (Detecting/Measuring/Quantifying/Other),3 Details/Description,3 Proposed/Referenced,3 Reference (if applicable),4 Model Used or Proposed,4 Purpose (Detecting/Measuring/Quantifying/Other),4 Details/Description,4 Proposed/Referenced,4 Reference (if applicable),5 Model Used or Proposed,5 Purpose (Detecting/Measuring/Quantifying/Other),5 Details/Description,5 Proposed/Referenced,5 Reference (if applicable),6 Model Used or Proposed,6 Purpose (Detecting/Measuring/Quantifying/Other),6 Details/Description,6 Proposed/Referenced,6 Reference (if applicable),7 Model Used or Proposed,7 Purpose (Detecting/Measuring/Quantifying/Other),7 Details/Description,7 Proposed/Referenced,7 Reference (if applicable),8 Model Used or Proposed,8 Purpose (Detecting/Measuring/Quantifying/Other),8 Details/Description,8 Proposed/Referenced,8 Reference (if applicable),9 Model Used or Proposed,9 Purpose (Detecting/Measuring/Quantifying/Other),9 Details/Description,9 Proposed/Referenced,9 Reference (if applicable),10 Model Used or Proposed,10 Purpose (Detecting/Measuring/Quantifying/Other),10 Details/Description,10 Proposed/Referenced,10 Reference (if applicable)
290,Zowghi 2003,"On the interplay between consistency, completeness, and correctness in requirements evolution",Consensus,Yes,290,"On the interplay between consistency, completeness, and correctness in requirements evolution","Australia, Italy",2004,Journal,Information and Software Technology,"The initial expression of requirements for a computer-based system is often informal and possibly vague. Requirements engineers need to examine this often incomplete and inconsistent brief expression of needs. Based on the available knowledge and expertise, assumptions are made and conclusions are deduced to transform this 'rough sketch' into more complete, consistent, and hence correct requirements. This paper addresses the question of how to characterize these properties in an evolutionary framework, and what relationships link these properties to a customer's view of correctness. Moreover, we describe in rigorous terms the different kinds of validation checks that must be performed on different parts of a requirements specification in order to ensure that errors (i.e. cases of inconsistency and incompleteness) are detected and marked as such, leading to better quality requirements.",Yes,"Completeness refers to situations where a specification entails everything that is desired to hold in a certain context.
Source: Proposed in this paper

To be considered complete, the requirements document must exhibit three fundamental characteristics: (1) No information is left unstated or 'to be determined', (2) The information does not contain any undefined objects or entities, (3) No information is missing from this document.
Source: Boehm, B.W., ""Verifying and validating software requirements and design specifications,"" IEEE Software, vol. 1, no. 1, pp. 75-88, 1984.

External completeness ensures that all of the information required for problem definition is found within the specification.
Source: Cordes, D.W., and Carver, D.L., ""Evaluation methods for user requirements documents,"" Information and System Technology, vol. 31, no. 4, pp. 181-188, 1989.",Yes,,Evolutionary proof obligations,"At each step of requirements evolution, prove completeness with respect to the previous version of requirements.",Proposed in this paper,,"Formally prove that the new requirements and domain model entail the previous requirements. If this proof fails, incompleteness is detected. The paper states: ""If at each step we discharge the appropriate proof obligations (summarized in Table 1), we are assured that the final specification, deployed in the domain described by our final domain model, satisfies the customer's business goals.""",Maximal entailed subset,Find the largest subset of a specification that is entailed by the requirements and domain model.,Proposed in this paper,,"Compare the size of the maximal entailed subset to the full specification. The difference indicates incompleteness. The paper defines this as: ""As a measure for the 'degree of completeness' of a set S w.r.t. R ∪ D, we consider the ratio between the size of a maximal subset of S that is entailed by R ∪ D (maximal entailed subset, or mes) and the size of the whole set S.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Degree of completeness,Ratio between size of maximal entailed subset and full specification,"d_compl(R,D,S) = |mes(R ∪ D, S)| / |S|",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Incremental completeness checking,Check completeness at each evolution step rather than only at the end,Proposed in this paper,,"Apply completeness measure at each step to track progress. The paper states: ""The proof obligations we discussed in Section 3 can be interpreted as validation checks that can (and should) be made during requirements evolution in order to identify and expose possibly latent errors.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Adding missing information,Copy relevant missing information from previous version of requirements/domain model,Proposed in this paper,,"Identify missing elements and add them to current version. The paper states: ""If something is missing from R_{i+1} (resp. D_{i+1}), the relevant information can be copied from R_i (resp. D_i) and added to the new set.""",Retracting conflicting information,Remove requirements/domain statements that conflict with previous version,Proposed in this paper,,"Identify conflicting elements and remove from current version. The paper states: ""If R_{i+1} ∪ D_{i+1} entails something that is in contradiction with the contents of R_i ∪ D_i, the offending requirements or domain description statements can be retracted from the new set.""",Finding closest correct ancestor,Backtrack to find most recent correct version to build upon,Proposed in this paper,,"Check completeness with respect to progressively earlier versions until a correct one is found. The paper states: ""The most economic way to maintain it is to find the closest preceding step which allows us to maintain completeness.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated theoretically and through a case study example in the paper. The authors applied their framework to a simple control system (an automatic gate to regulate access to a building) to demonstrate how it works in practice. However, no formal empirical evaluation was conducted. The paper states: ""We assume the role of a requirements engineer, and show how the requirements analysis for a simple control system—an automatic gate to regulate access to a building—can be performed in a rigorous way according to our framework.""",Yes,,SMACK,Proposed in this paper,,"Detect, Measure",Simple propositional logic model checker,Checks consistency and completeness of requirements expressed in propositional logic,"Implemented, Validated","Used on case study example in paper, no formal validation described. The paper states: ""We carry on the proof using a simple ad-hoc model checker for propositional logic, called SMACK, that we developed in-house in support of our framework.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
280,Issa 2010,Use case patterns driven requirements engineering,Consensus,Yes,280,Use Case Patterns Driven Requirements Engineering,Jordan,2010,Conference ,Second International Conference on Computer Research and Development,"Based on a novel multi-phases process, a new use case patterns catalogue is constructed. This catalogue is then utilized as a framework for a new use case patterns driven approach for requirement engineering. The application of the approach in a TestWarehouse environment showed two main promising results. First, the approach could save up to 30% of the time required for the requirements engineering phase of software development projects. Second, resulted requirements models from the proposed approach showed high completeness percentage between 85% and 95%. Nevertheless, users raised a number of concerns that has been considered to outline prospective phases of this research.",No,,Yes,,Use Case Patterns Catalogue Comparison,"The approach involves comparing the requirements of a new project against a pre-constructed catalogue of use case patterns to identify missing requirements.
",Proposed in this paper,,Analysts browse through the catalogue to extract up to 80% of software systems requirements model. The difference between the extracted requirements and the complete set of project requirements indicates incompleteness.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Requirements Model Completion Percentage,A percentage measure of how complete the requirements model is compared to the final set of requirements for the project.,"implied to be:
(Number of requirements in the model / Total number of final project requirements) * 100",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Use Case Patterns Reusability Analysis,A statistical analysis of the reusability of use case patterns across different application domains to estimate the potential completeness of requirements derived from the catalogue.,Proposed in this paper,,"The authors conducted statistical studies to determine the percentages of Application Domain Dependent Use Case Patterns (ADDUCPs) and Application Domain Independent Use Case Patterns (ADIUCPs) in software systems. They found that on average, 43% of functionalities are ADIUCPs, and 57% are ADDUCPs. Of the ADDUCPs, 65% are shared across domains. This analysis suggests that approximately 80% of a system's functionalities can be derived from the use case patterns catalogue, providing an estimate of potential completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Use Case Patterns Driven Requirements Engineering Approach,"An approach that uses a pre-constructed use case patterns catalogue as a starting point for requirements elicitation and modeling, followed by customization and addition of project-specific requirements.",Proposed in this paper,,"Browse the use case patterns catalogue
Extract relevant use cases (up to 80% of system functionalities)
Customize selected use case patterns to fit the system under development
Add new use cases that are missing from the catalogue",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through application in a real-world environment (TestWarehouse) over 18 months across six projects. The evaluation approaches included:

Statistical analysis of use case reusability and addition across different projects and application domains
Regular bimonthly interviews with main users (analysts) of the catalogue
Analysis of project historical records

Metrics used to assess effectiveness:

Percentage of added use cases to the project
Percentage of added use cases to the catalogue from those added to the project
Time saving in the requirements engineering phase
Requirements model completion percentage

Key results and findings:

The average percentage of added use cases to projects was 9%
The average percentage of added use cases to the catalogue from those added to projects was 56%
Time saving in the requirements engineering phase varied between 10% and 30% of the total software development project time
Requirements model completion varied between 85% and 95%

Limitations or challenges mentioned:

The effectiveness of the approach depends on the completeness and comprehensiveness of the use case patterns catalogue
The accuracy of browsing the catalogue and selecting relevant use cases affects the results
Users reported issues with use case patterns naming conventions
The need for an automated CASE tool to support the approach was identified
Users suggested further specialization of catalogue application domains",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
277,Menzel 2010,An experimental comparison regarding the completeness of functional requirements specifications,Consensus,Yes,277,An Experimental Comparison regarding the Completeness of Functional Requirements Specifications,Germany,2010,Conference ,18th IEEE International Requirements Engineering Conference,"Providing high-quality software within budget is a goal pursued by most software companies. Incomplete requirements specifications can have an adverse effect on this goal and thus on a company's competitiveness. Several empirical studies have investigated the effects of requirements engineering methods on the completeness of a specification. In order to increase this body of knowledge, we suggest using an objective evaluation scheme for assessing the completeness of specification documents, as objectifying the term completeness facilitates the interpretation of evaluations and hence comparison among different studies.
This paper reports experience from applying the scheme to a student experiment comparing a use case with a textual approach common in industry. The statistical analysis of the specification's completeness indicates that use case descriptions lead to more complete requirements specifications. We further experienced that the scheme is applicable to experiments and delivers meaningful results.",No,,Yes,,Information Model Approach,"An objective, model-based approach for measuring the completeness of requirements specifications. It consists of an information model combined with a set of assignment rules and a guideline.",Proposed in this paper,,The information model formalizes the concept of completeness for a specific problem domain. Assignment rules define how specification text fragments map to the information model. The guideline describes how to analyze a given requirements specification based on the information model. Completeness is assessed by counting the occurrence of different information elements defined in the model.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Number of goals described,Counts the number of system goals addressed in the requirements specification,,Proposed in this paper,,Number of information elements per goal,Counts the occurrences of different types of information elements for each goal described in the specification,,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Information Model-based Quantification,Uses an information model to define different types of information elements that should be present in a complete specification. Completeness is quantified by counting occurrences of these elements.,Proposed in this paper,,"Define an information model with different types of information elements (e.g., HMI, CCI, SYS IF, etc.)
Analyze the specification text and map fragments to information element types
Count the occurrences of each information element type
Compare the counts between different specification approaches or against a baseline to assess relative completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
274,Liu 2009,Domain component-based service requirements modeling and analysis,Consensus,Yes,274,Domain Component-based Service Requirements Modeling and Analysis,China,2009,Conference ,2009 International Conference on Computational Science and Engineering,"Service-oriented computing (SOC) is the computing paradigm that utilizes services as fundamental elements for developing applications. The modeling and analysis of services-oriented software requirements is one of important study contents in SOC. Owing to frequent changes of individual or collective requirements, continuous evolution of system function and structure, the study object of services-oriented requirement complete analysis is relative completeness of services requirements but not absolute completeness. Our study focuses this key problem of services-oriented software engineering. First of all, domain knowledge and software reuse technology are combined to present a framework of services-oriented requirement components modeling; then, constructing and optimizing the requirement components directed graph to automatically realize completeness analysis for service requirements; lastly, the concepts of expected requirements and excited requirements are introduced into our study for quantitatively evaluating the completeness results. The study productions provide theoretical foundation and tool support for modeling in semantic level and analyzing of services-oriented software requirements automatically, simultaneity it will adapt to the new challenges of software on network environments development mode and improve the agreement degree of stakeholders by a large margin.",,"Owing to frequent changes of individual or collective requirements, continuous evolution of system function and structure, the study object of services-oriented requirement complete analysis is relative completeness of services requirements but not absolute completeness.
Source: Proposed in this paper
",Yes,,Requirement Component Directed Graph Construction,"This method involves constructing a directed graph where requirement components are vertices and semantic relations (decomposition and dependency) between components are arcs. The graph is built through a process of analyzing initial requirements, inducing new requirement components through decomposition and dependency relations, and optimizing the resulting model.",Proposed in this paper,,The process constructs a graph by starting with initial requirements and iteratively adding related components through decomposition and dependency relations. Incompleteness is detected by identifying missing components or relations in the graph structure.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Expected Requirements and Excited Requirements,"The paper introduces the concepts of ""expected requirements"" and ""excited requirements"" for quantitatively evaluating the completeness results.",Proposed in this paper,,,Requirement Component Directed Graph Analysis,"While not explicitly described as a quantification method, the paper uses the construction and analysis of a Requirement Component Directed Graph as a basis for assessing completeness.",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Requirement Component Directed Graph Optimization,"After constructing the initial Requirement Component Directed Graph, the method includes a step to optimize the RC model.", Proposed in this paper,,"The paper mentions ""The direct acyclic in requirement component directed graph will be eliminate in step 4"" as part of the optimization process. However, it does not provide detailed steps for this optimization process.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"It mentions a case study using a ""requirement complete analyzer"" developed based on the proposed approach, but does not present formal evaluation methods, metrics, or results.",Yes,,Service Requirements Complete Analyzer, Proposed in this paper,,"Detect, Measure, Correct", A software tool developed to implement the proposed approach,"The tool constructs a requirement component directed graph automatically based on initial requirements and domain knowledge. It can generate, clear, delete, optimize, and submit requirement components.",Implemented,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
273,Issa 2011,Automated requirements engineering: Use case patterns-driven approach,Consensus,Yes,273,Automated requirements engineering: use case patterns-driven approach,Jordan,2011,Journal, IET Software,"Based on a novel multi-phases process, a new use case patterns catalogue is constructed. This catalogue is then utilised as a framework for a new use case patterns-driven approach for requirement engineering. The application of the proposed approach in a TestWarehouse environment showed promising results in saving up to 30% of the total software development project time, yet the resulted requirements models showed high, 85–95%, completeness percentage. Furthermore, the application of an automated version of the proposed approach saved an extra 43% of the time saved by its manual application. This had direct implications on improving requirements and design deliverables of agile software development processes. Nevertheless, users raised a number of concerns that have been considered to outline prospective phases of this research.",No,,Yes,,Use Case Patterns Catalogue Approach,Analysts browse through a pre-constructed catalogue of use case patterns to extract up to 80% of software systems requirements model. The remaining uncovered requirements indicate potential incompleteness.,Proposed in this paper,,"y selecting relevant use case patterns from the catalogue, analysts can quickly construct a substantial portion of the requirements model. Any functionality not covered by the selected patterns indicates potential gaps or incompleteness in the requirements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Overall Catalogue Recall,"Measures the percentage of use cases covered by the catalogue compared to the total use cases in the project
",(Number of reused patterns / Total use cases of the project) * 100,Proposed in this paper,,"Actual Catalogue Recall
","Measures the percentage of use cases covered by the catalogue, accounting for new patterns added to the catalogue during the project
",(Number of reused patterns + Number of added use case patterns to catalogue) / Total use cases of the project * 100,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Comparative Analysis,"Compare the number of reused use case patterns from the catalogue to the total number of use cases in the final project, including any newly added patterns.",Proposed in this paper,,Calculate the Overall Catalogue Recall and Actual Catalogue Recall metrics for each project. Higher percentages indicate greater completeness of the requirements model based on the catalogue coverage.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Use Case Patterns Catalogue Maintenance,Continuously update the use case patterns catalogue with new patterns discovered during projects,Proposed in this paper,,"Retrieve final use case models of software projects
Use synonyms analysis to identify new use cases not archived in the catalogue
Analyse frequency of use of new use cases
Identify candidate new use cases for archiving in the catalogue
Determine level of reuse and abstraction of candidate use cases
User decides whether to add use cases as patterns to the catalogue and their categorization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through:

Application in real projects:


The approach was applied in 6 projects over 12 months at TestWarehouse
Project sizes ranged from small to large
Various application domains were covered (e.g., human resources, financial, e-Commerce, CRM software, insurance)


Metrics used:


Time saving percentage
Completeness percentage (measured by catalogue recall)
Number of reused patterns vs. added use cases


Key results:


Manual approach saved 10-30% of total project time
Automated approach saved an additional 43% on top of manual approach savings
Completeness (recall) ranged from 85-95%
On average, only 9% of use cases needed to be added to projects beyond catalogue patterns


Evaluation methods:


Comparative analysis between projects using the approach vs. historical data
Interviews with business and system analysts (25 interviews conducted)
Controlled comparisons between manual and automated approaches


Limitations mentioned:


Catalogue structure and content dependent on available historical projects
Potential bias from user experience and understanding
More effective for small and medium projects compared to large projects
Ambiguities from natural language specifications",Yes,,Automated Use Case Patterns Catalogue,Proposed in this paper,,"Detect, Measure, Correct",Implemented as a plugin for the StarUML open-source CASE tool,"Browse and select use case patterns from catalogue
Create and maintain user projects
Load selected patterns into StarUML
Maintain catalogue (add/update patterns and application domains)
Calculate completeness metrics (Overall Catalogue Recall, Actual Catalogue Recall)","Implemented, Validated","Applied in 2 additional projects, compared against manual approach. Showed 43% additional time savings over manual approach while maintaining similar completeness levels.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
266,Kaiya 2010,Enhancing domain knowledge for requirements elicitation with Web mining,Consensus,Yes,266,Enhancing Domain Knowledge for Requirements Elicitation with Web Mining,Japan,2010,Conference ,2010 Asia Pacific Software Engineering Conference,"To elicit software requirements, we have to have knowledge about a problem domain, e.g., healthcare, shopping or banking where the software is applied. A description of domain knowledge such as a domain ontology helps requirements analysts to elicit requirements completely and correctly to some extent even if they do not have such knowledge sufficiently. Several requirements elicitation methods and tools using domain knowledge description have been thus proposed, but how to develop and to enhance such description is rarely discussed. Summarizing existing documents related to the domain is one of the typical ways to develop such description, and an interview to domain experts is another typical way. However, requirements cannot be elicited completely only with such domain-specific knowledge because a user of such knowledge, i.e., a requirements analyst is not a domain expert in general. Requirements could be also elicited more correctly with both specific and general knowledge because general knowledge sometimes improves understandings of analysts about domain-specific knowledge. In this paper, we propose a method and a tool to enhance an ontology of domain knowledge for requirements elicitation by using Web mining. In our method and our tool, a domain ontology consists of concepts and their relationships. Our method and tool helps an analyst with a domain ontology to mine general concepts necessary for his requirements elicitation from documents on Web and to add such concepts to the ontology. We confirmed enhanced ontologies contribute to improving the completeness and correctness of elicited requirements through a comparative experiment.",No,,Yes,,Ontology Enhancement Method,A method to enhance domain ontologies by adding general concepts mined from web documents to complement domain-specific concepts.,Proposed in this paper,,"The enhanced ontology helps analysts identify missing requirements by providing more complete domain knowledge, including general concepts related to the domain that may not be present in the initial domain-specific ontology.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Completeness,The ratio of correctly elicited requirements to the total number of correct requirements,"Comp(Od) = |RRDd ∩ ERLd(Od)| / |RRDd|

Where:
RRDd: Right requirements list for domain d
ERLd(Od): Extended requirements list elicited using ontology Od",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Ontology Enhancement Method,A method to enhance domain ontologies by adding general concepts mined from web documents to complement domain-specific concepts.,Proposed in this paper,,"Divide the initial ontology into sub-domain ontologies
Gather relevant web pages for each sub-domain
Mine candidates of new concepts and prioritize them
Choose new concepts to be added to the ontology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Comparison of requirements elicitation using initial vs. enhanced ontologies
Measurement of completeness and correctness of elicited requirements

Metrics used:

Completeness: Comp(Od) = |RRDd ∩ ERLd(Od)| / |RRDd|
Correctness: Corr(Od) = |RRDd ∩ ERLd(Od)| / |ERLd(Od)|

Datasets:

Two domains: POS (point of sales) systems and conference management systems
Initial ontologies created from domain documents or by domain experts
Enhanced ontologies created using the proposed method

Key results:

Enhanced ontologies led to higher completeness and correctness of elicited requirements
Completeness nearly doubled when using enhanced ontologies
Correctness also improved when using enhanced ontologies

Limitations:

Limited to two domains
Small number of subjects (two students) for requirements elicitation
Time limit of two hours for requirements elicitation may have affected results",Yes,,OREW (domain Ontology Reconstruction Environment by Web search),Proposed in this paper,,"Detect, Measure", Supports the proposed ontology enhancement method,"Divides ontology into sub-domains
Performs web mining using Yahoo! Web API
Identifies and prioritizes candidate concepts
Provides GUI for selecting new concepts to add to the ontology"," Implemented, Validated","Used in the comparative experiment to enhance ontologies, which led to improved completeness and correctness of elicited requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
263,Iqbal 2012,Yet another set of requirement metrics for software projects,Consensus,Yes,263,Yet another Set of Requirement Metrics for Software Projects,Pakistan,2012,Journal,,,No,,Yes,,"Requirements completeness metrics

",Metrics used to check whether specified requirements are complete or not,Referenced,"Asthana and Olivieri [8]
Citation: A. Asthana, and J. Olivieri, ""Quantifying Software Reliability and Readiness"", The MITRE Corporation (2009)",The paper does not provide details on how these metrics detect incompleteness,"Volatility metrics
", Checks changes in the requirements,Referenced,"Rational Software [11]
Citation: Rational Software, IBM Information Centre, ""Managing and Composing Requirements"", Available at: http://publib.boulder.ibm.com/infocenter/reqpro/v7r1m0/index.jsp?topic=/com.ibm.reqpro.help/integ/c_req_metrics.html.","Tracks changes in requirements, which could indicate incompleteness","Traceability evaluation
","Evaluates links between requirements within a document
",Referenced,"Rational Software [11]
Citation: Rational Software, IBM Information Centre, ""Managing and Composing Requirements"", Available at: http://publib.boulder.ibm.com/infocenter/reqpro/v7r1m0/index.jsp?topic=/com.ibm.reqpro.help/integ/c_req_metrics.html.","Analyzes relationships between requirements, which could reveal missing requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Requirement Completeness Index (RCoI),Measures the completeness of gathered requirements,"RCoI = CoR / TR * 100 where CoR = Complete Requirements, TR = Total Requirements
",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Multiple metric approach
","Using a combination of metrics to assess overall requirement quality, including completeness",Proposed in this paper,,"Applies multiple metrics (including RCoI and others like Requirement Stability Index, Requirement Clarity Index, etc.) to get a comprehensive view of requirement quality",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Proposed steps for requirement gathering,A set of 15 steps to follow for more accurate and planned requirement gathering,Proposed in this paper,,"Formulate a team of experts in which majority of members have the relevant domain knowledge.
b. List down all the stakeholders and their role in the project.
c. Clearly express the data collection procedures.
d. Make a prototype of the measurement process.
e. Prepare list of potential quality requirements for the system.
f. Setup a discussion forum for the requirement engineering team.
g. Reconcile the quality requirements list for future validation of the same.
h. Perform a cost-benefit analysis of all the requirements.
i. Organize a meeting with the stakeholders for further verification and refinement of the process.
j. Keep track of changes in the requirements.
k. In case a new requirement pop ups then perform step ""e"" onward.
l. Interpret the performance metric results.
m. Determine the expected software quality by making software quality predictions.
n. Ensure compliance of the software artefacts with the requirements.
o. Document the performance metric results.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
261,Espada 2011,Measuring complexity and completeness of KAOS goal models,Consensus,Yes,261,Measuring Complexity and Completeness of KAOS Goal Models,Portugal,2011,Conference ,2011 Fifth International Conference on Research Challenges in Information Science,"KAOS is one of the most well-known goal-oriented requirements engineering approaches. Nevertheless, building large KAOS models sometimes results in incomplete and/or complex requirements models that are difficult to understand and maintain. These shortcomings often lead to an increase in costs of product development and evolution. Therefore, for large-scale systems, the ability to manage the complexity and completeness of KAOS models is essential. In this paper, we propose a metrics suite for supporting the quantitative assessment of KAOS models complexity and completeness, in order to support their early identification. We apply the metrics to an example taken from a health club system specification.",Yes,"In a complete KAOS goal model, all leaf goals must be assigned to an agent.
Source: Proposed in this paper",Yes,,"Percentage of leaf goals with associated agents
",This metric calculates the proportion of leaf goals in the model that have been assigned to an agent.,Proposed in this paper,,"By calculating this percentage, analysts can identify how many leaf goals are missing agent assignments, thus detecting incompleteness in the model.",Percentage of leaf goals with associated objects,This metric calculates the proportion of leaf goals in the model that have associated objects.,Proposed in this paper,,"While not directly related to the formal completeness definition, this metric helps detect incompleteness in terms of model detail. A low percentage indicates that many leaf goals lack associated objects, suggesting potential incompleteness in the model's detail.",Minimum number of leaf goals associated with an agent,This metric identifies the agent with the fewest assigned leaf goals and reports that number.,Proposed in this paper,,A very low value (especially 0) could indicate incompleteness in agent responsibility assignment.,Maximum number of leaf goals associated with an agent,This metric identifies the agent with the most assigned leaf goals and reports that number.,Proposed in this paper,,"While primarily a complexity metric, an unusually high value could indicate incomplete agent assignment across the model.",Average number of leaf goals associated with an agent,This metric calculates the mean number of leaf goals assigned to agents in the model.,Proposed in this paper,,A low average could suggest incomplete assignment of goals to agents across the model.,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"M1 - Percentage of leaf goals that have an associated agent
","This metric directly quantifies the completeness of the KAOS model in terms of agent assignments.
", (Number of leaf goals with an associated agent / Total number of leaf goals) * 100,Proposed in this paper,,M2 - Percentage of leaf goals that have an associated object,"his metric quantifies the completeness of the KAOS model in terms of object associations, providing a measure of model detail.",(Number of leaf goals with an associated object / Total number of leaf goals) * 100,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GQM (Goal-Question-Metric) approach,The paper uses the GQM approach to systematically derive metrics for quantifying completeness and complexity of KAOS models.,Referenced,"Basili, V. R., Caldiera, G. and Rombach, H. D. ""The Goal Question Metric Approach"". Encyclopedia of Software Engineering, J. J. Marciniak: John Wiley & Sons, Inc., 1994, pp. 528-532.","The GQM approach starts by defining goals (in this case, assessing completeness and complexity), then formulates questions to characterize how these goals can be achieved, and finally defines metrics to provide quantitative answers to these questions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Model Refinement,The paper demonstrates a process of refining an incomplete KAOS goal model to improve its completeness.,Proposed in this paper,,"Identify missing elements (agents, objects) in the current model.
Add environment agents and system agents to leaf goals lacking agent assignments.
Introduce additional objects to goals where applicable.
Reassess the model using the defined metrics to verify improvement in completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Case study: Application of the metrics to two versions of a KAOS goal model for an access control system.

Metrics used to assess effectiveness:

All proposed metrics (M1-M10) were applied to both an initial incomplete model and a refined, more complete model.

Datasets or case studies employed:

A health club system specification, focusing on the access control functionality.

Key results and findings:

The refined model showed significant improvement in completeness metrics:

M1 (agent assignment) increased from 11% to 100%
M2 (object association) increased from 44% to 66.7%


The refinement process also affected complexity metrics, showing increased detail without harmful impact on overall complexity.

Limitations or challenges mentioned:

The evaluation is limited to a single, relatively small example.
The paper notes that further validation on larger models is needed to fully assess the usefulness of the metrics.",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
255,Hu 2010,Semantic-based requirements analysis and verification,Consensus,Yes,255,Semantic-based Requirements Analysis and Verification,China,2010,Conference ,2010 International Conference on Electronics and Information Engineering (ICEIE 2010),"Requirements verification for complex software system has become more and more important in requirements engineering and it is one of the most helpful strategies for improving the quality of software system. Related work shows that requirement elicitation and analysis can be facilitated by semantic technologies and domain ontology. A new methodology for verifying software requirements with structural and formal semantics based on domain ontology is proposed in this paper. Requirement specification processed with natural language can be decomposed into a set of atomic requirement items which are represented with triplet of semantic elements in their domain ontology. Mapping semantic requirement items to concepts and their relationships in the domain ontology leads to a set of inference rules that are represented by description logics to verify the completeness, consistency and correctness of requirement specifications. The process of requirements verification is defined in order to evaluate the quality of requirement specifications, and its effectiveness is analyzed and evaluated with an experimental case study.",Yes,"Formula 4: Completeness = |Fm|/|O|
Source: Proposed in this paper
",Yes,,Ontology-based Completeness Verification,This method uses domain ontology to detect incompleteness in requirements specifications. It involves mapping atomic requirement items to semantic elements in the domain ontology and checking for unmapped elements.,Proposed in this paper,,"Decompose the original requirements into atomic requirement items.
Map these items to semantic elements (concepts and relationships) in the domain ontology.
Check for any unmapped elements in the ontology.
If there are ontology elements without corresponding requirement items, the specification is considered incomplete.",Completeness Verification Rule,A formal rule to detect incompleteness in requirements,Proposed in this paper,,"The rule states that for any relation p in the ontology, if there exist concepts s and o related by p, and s is described in the requirement specification, then p and o should also be introduced in the requirement specification. If not, the specification is incomplete.

Formula 1: ∀p∃s∃o | (D(s) ⊓ p(s, o)) ⇒ (D(p) ⊓ D(o))
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Completeness Ratio,A ratio that quantifies the completeness of the requirements specification,"Completeness = |Fm| / |O|

Where:
|Fm| is the number of triples O(x,y) in the ontology system that are mapped to requirement items
|O| is the total number of triples O(x,y) in the ontology system",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Ontology-based Requirements Verification Process,A step-by-step process to verify and quantify the completeness of requirements,Proposed in this paper,,"Decompose original requirements into atomic requirement items
Map these items to semantic elements in the domain ontology
Apply the completeness verification rule (Formula 1)
Count the number of mapped and total triples in the ontology
Calculate the completeness ratio using the formula",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
254,Zhu 2000,Automating scenario-driven structured requirements engineering,Consensus,Yes,254,Automating Scenario-Driven Structured Requirements Engineering,UK,2000,Conference ,"Proceedings of the 2000 IEEE International Conference on Systems, Man, and Cybernetics","Scenario analysis is a vehicle of separating concerns in the elicitation of users' requirements. It is also a means of requirements validation and verification. In the practical application of the method, a number of key activities must be supported by automated tools, which include: (a) the analysis of consistency among scenarios, (b) the analysis of the consistency and Completeness of a set of scenarios with respect to requirements models, (c) the synthesis of requirements models from a set of scenarios, and (d) the generation of scenarios from requirements models for requirements validation. This paper presents an automatic toolkit that supports these activities. It adapts the idea of scenario analysis originally proposed in OO analysis to the structured analysis method.",Yes,"Checking the consistency against the set of scenarios covers all the information contained in the model. In this sense, the completeness of a set of scenarios with respect to a requirements model means the adequacy of validation.
Source: Proposed in this paper


Assuming that a set of scenarios is complete in the sense that it already contains all the information of the required system, incompleteness then means that the model must contain unnecessary or incorrect information.
Source: Proposed in this paper

A data flow model M can be uniquely synthesised from a set of scenarios that is consistent and complete with respect to M, if and only if the set of scenarios is consistent and self-complete.
Source: Proposed in this paper",Yes,, Scenario Consistency Analysis,Analyzing the consistency between scenario descriptions and requirements models to identify missing information.,Proposed in this paper,,Automatically checks if the information in a scenario is a subset of the information in the requirements model. Inconsistencies may indicate incompleteness in either the scenario or the model., Inter-Scenario Consistency Analysis,Analyzing the consistency among a set of scenarios to identify missing information.,Proposed in this paper,," Checks if there exists a requirements model that all scenarios in the set are consistent with. If not, it may indicate incompleteness in the set of scenarios.",Scenario Completeness Analysis,Checking if a set of scenarios covers all the information in a requirements model.,Proposed in this paper,,Analyzes if every piece of information in the requirements model is represented in at least one scenario. Uncovered information indicates potential incompleteness in the scenarios.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Test Adequacy Measurement,Measures the adequacy of a set of test scenarios in covering the requirements model.,,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Data Flow Testing,Selects test scenarios according to the data flow model to measure completeness.,Proposed in this paper,,Generates test scenarios based on the data flow model and measures coverage of the requirements.,State Transition Testing,Selects test scenarios based on the state transition model to measure completeness.,Proposed in this paper,,Generates test scenarios based on the state transition model and measures coverage of the requirements.,Entity Testing,Selects test scenarios based on the entity relationship model to measure completeness.,Proposed in this paper,,Generates test scenarios based on the entity relationship model and measures coverage of the requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Scenario Synthesis,Synthesizing requirements models from a set of scenarios to ensure completeness.,Proposed in this paper,,"Collect a set of consistent and self-complete scenarios
Automatically synthesize a requirements model from these scenarios
The resulting model incorporates all information from the scenarios, addressing completeness",Iterative Scenario Refinement,Iteratively refining scenarios based on completeness checks.,Proposed in this paper,,"Describe initial scenarios
Perform completeness checks
Identify incomplete areas
Refine scenarios to address identified issues
Repeat until scenarios are complete",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Empirical studies (details not provided in this paper)

Metrics or criteria used to assess effectiveness:

Number of task scenarios generated
Length of activity lists generated

Key results and findings:

The numbers of task scenarios and the lengths of activity lists were found to be acceptable for practical use.

Note: Detailed evaluation results are not provided in this paper.",Yes,,RASS (Requirements Analysis and Specification System),Proposed in this paper,,"Detect, Measure, Correct",Automated toolkit for scenario analysis and requirements validation,"Scenario consistency and completeness checking
Requirements model synthesis
Test scenario generation
Test adequacy measurement","Implemented, Validated","Empirical studies conducted, but detailed results not provided in this paper.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
251,Huertas 2012,"NLARE, a natural language processing tool for automatic requirements evaluation",Consensus,Yes,251,"NLARE, A Natural Language Processing Tool for Automatic Requirements Evaluation",Mexico,2012,Conference ,CUBE 2012,"Most research works have found that an important root cause of
software project failure comes from the requirements; their
quality has an important impact over other artifacts. As the
requirements are expressed in natural language, they can be an
important source of defects. Aspects such as non ambiguity,
completeness, and atomicity can be affected due the
characteristics of natural language. Traditional practices focus
on finding software bugs, as a corrective approach, until the
project has been coded already, instead assuring quality since
the beginning. By other hand, evaluating such quality attributes
can be a difficult task. In this paper we propose some
guidelines for a disciplined sentence structure for expressing
the requirements, which allows natural language processing
techniques to evaluate quality. We also propose a tool for
automatic requirement evaluation based on the grammar
structure of sentences expressed in natural language. With this
tool we have a huge speed increase over manual evaluation. In
order to validate our proposal we have implemented a set of
experiments with real projects, assessing the impact of
requirements quality over project results.",Yes,"In order to validate the completeness, we propose that a requirement must have the following elements: Actor A, Function F and Detail
Source: Proposed in this paper
",Yes,,NLARE Completeness Sub-module,"This module uses a regular expression parser to find three key elements expected in functional requirements: Actor, Function, and Detail.",Proposed in this paper,,"The module searches for patterns in the requirement text that match the expected structure of Actor, Function, and Detail. If any of these elements are missing, the requirement is flagged as incomplete.",RegeX Parser,"A grammar-based chunk parser that uses a set of regular expression patterns to specify its behavior. It looks for patterns to find if the requirement structure meets the required elements (Actor, Function, Detail).",Proposed in this paper,," The parser uses predefined grammar rules to chunk the requirement text and identify the presence or absence of the required elements. If at least one element cannot be found, the requirement is tagged as incomplete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,NLARE (Natural Language Automatic Requirement Evaluator),Proposed in this paper,,"Detect, Measure","The tool is implemented as a command-line application using Python, with the NLTK (Natural Language ToolKit) for processing and PyEnchant library for spell checking.","NLARE processes requirements text to detect issues related to atomicity, ambiguity, and completeness. For completeness, it checks for the presence of Actor, Function, and Detail elements in each requirement.","Implemented, Validated","The tool was validated by comparing its results to human evaluation on a real project. For completeness detection, it achieved 56% concordance with human evaluation. The tool was also evaluated for speed, processing 237.6 requirements per minute compared to 0.9 requirements per minute for manual evaluation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
250,Kamalrudin 2011,Improving requirements quality using essential use case interaction patterns,Consensus,Yes,250,Improving Requirements Quality using Essential Use Case Interaction Patterns,"New Zealand, Australia",2011,Conference ,ICSE '11: Proceedings of the 33rd International Conference on Software Engineering,"Requirements specifications need to be checked against the 3C's -
Consistency, Completeness and Correctness – in order to achieve
high quality. This is especially difficult when working with both
natural language requirements and associated semi-formal
modelling representations. We describe a technique and support
tool that allows us to perform semi-automated checking of natural
language and semi-formal requirements models, supporting both
consistency management between representations but also
correctness and completeness analysis. We use a concept of
essential use case interaction patterns to perform the correctness
and completeness analysis on the semi-formal representation. We
highlight potential inconsistencies, incompleteness and
incorrectness using visual differencing in our support tool. We
have evaluated our approach via an end user study which focused
on the tool's usefulness, ease of use, ease of learning and user
satisfaction and provided data for cognitive dimensions of
notations analysis of the tool.",Yes,"The set of requirements are assumed to be ""complete"" [18] once all the requirements model elements satisfy a match or matches in the EUC interaction pattern library.
Source: Proposed in this paper
",Yes,,EUC Interaction Pattern Matching,The extracted EUC model is compared against templates in an EUC interaction pattern library to check for completeness.,"Proposed in this paper
",,"The tool compares the extracted EUC model to a set of template EUC interaction patterns representing valid, common ways of capturing EUC models for various domains. Deviations from the pattern indicate potential incompleteness. These are highlighted to the engineer using visual annotations on the EUC model elements.",Visual Differencing,A technique to visually highlight differences between the extracted EUC model and the matched pattern template.,Proposed in this paper,adapted from Mehra et al. [19],"The tool uses visual link annotations to connect corresponding elements in the extracted EUC and pattern. Unmatched items in the pattern template or in the extracted EUC are highlighted, indicating potential missing elements (incompleteness).",Inter-model Consistency Checking,"Checks consistency between textual natural language requirements, abstract interactions, and EUC models.",Proposed in this paper,,The tool checks for consistency in naming and sequencing of elements across the three representations. Inconsistencies may indicate incompleteness in one or more representations.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Interactive Visual Differencing
","A visual approach to highlight differences between the extracted EUC model and the matched pattern template, allowing users to interactively resolve incompleteness.",Proposed in this paper,,"The tool visually highlights differences between the extracted EUC model and the matched pattern template.
Users can choose to change their EUC model to conform to the template view, incorporate some of the recommended changes, or keep their existing model.
Changes made to one representation (e.g., EUC model) are propagated to other representations (abstract interactions and textual requirements) to maintain consistency.",Automated Suggestion for Abstract Interactions,The tool suggests alternative abstract interactions when users modify elements that cause inconsistencies.,Proposed in this paper,,"When a user changes an abstract interaction that causes inconsistency, the tool provides a list of alternative words or phrases.
These alternatives are recognized as correct and complete, as they match essential interaction phrases contained in the EUC interaction pattern library.
Users can create a new natural language requirement phrase based on the suggestions they think are relevant to the context.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

User study with 11 software engineering post-graduate students
Standard usability survey
Cognitive Dimensions of Notations (CD) framework evaluation


Metrics used:

Usefulness
Ease of use
Ease of learning
User satisfaction
Various Cognitive Dimensions (visibility, viscosity, diffuseness, etc.)


Key results and findings:

Strong agreement on usefulness (over 80% strongly agree or agree)
High ratings for ease of use (over 90%)
High ratings for ease of learning (over 90%)
High user satisfaction (over 80%)
Positive ratings for most Cognitive Dimensions, particularly visibility, viscosity, and closeness of mapping",Yes,,MaramaAI (Automated Inconsistency checker),Proposed in this paper,,"Detect, Measure, Correct","Developed using Marama meta-tools and specialized components for requirements extraction, analysis, comparison to pattern library, and visual differencing.","Extracts abstract interactions from textual natural language requirements
Generates EUC models from abstract interactions
Checks consistency between textual requirements, abstract interactions, and EUC models
Compares extracted EUC models against a library of EUC interaction patterns
Highlights inconsistencies, incompleteness, and incorrectness using visual differencing
Supports interactive resolution of identified issues","Implemented, Validated","Validated through a user study with 11 participants, focusing on usefulness, ease of use, ease of learning, and user satisfaction. The study also included a Cognitive Dimensions of Notations analysis.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
245,Yu 2008,Completeness and consistency analysis on requirements of distributed event-driven systems,Consensus,Yes,245,Completeness and Consistency Analysis on Requirements of Distributed Event-Driven Systems,China,2008,Conference ,2nd IFIP/IEEE International Symposium on Theoretical Aspects of Software Engineering,"For many event-driven systems, the completeness and consistency (C&C) are the most important characteristics of those software requirements. This paper presents a systematic approach to perform C&C analysis on the requirements, and an intelligent approach to correcting the inconsistencies identified. A formal scenario model is used to represent requirements such that scenario elements of condition guards, events and actions can be extracted automatically. Condition guards associated with a same event are constructed into a tree on which to perform completeness analysis and supplement missing specification. Consistency analysis focuses on three types of inconsistencies and is performed according to the intra-relations among condition guards and inter-relations with actions. An algorithm of inconsistent correction is proposed to guide eliminating the inconsistency identified interactively. Finally, we provide an example of car-alarm system to illustrate the proposed process and techniques.",Yes,"Completeness: Presence of all event handlers or actions for condition guards of all events.
Source: Proposed in this paper

If the system is considered as complete, the system must respond to all the specified events, internal or external, in any system states defined as conditions guards.
Source: Proposed in this paper",Yes,,Condition Guard Tree Construction and Analysis,"This method involves constructing a tree structure from the condition guards associated with each event, and then analyzing this tree to identify unspecified scenarios.
","Proposed in this paper
",,"The process involves the following steps:
a) Extract condition guards and associated events from the formal scenario model.
b) For each event, construct a tree where each node represents a combination of condition variables.
c) Mark nodes as ""specified"" if they correspond to explicitly defined requirements, and ""unspecified"" otherwise.
d) Analyze the tree, focusing on the leaf nodes. Any leaf node marked as ""unspecified"" indicates an incomplete requirement.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Completeness Correction through Tree Analysis,This method involves identifying unspecified nodes in the condition guard tree and providing options for addressing these incomplete areas.,Proposed in this paper,,") Identify ""unspecified"" leaf nodes in the condition guard tree.
b) For each unspecified node, choose one of three options:

Add a new event handler to that condition tuple
Specify explicitly ""no action"" for that condition tuple
Specify explicitly an exception handler for that condition tuple",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper does not provide a formal evaluation of the completeness correction method. Instead, it illustrates the process using a Car Alarm System (CAS) example. This serves as an informal, illustrative evaluation of the approach. The example demonstrates how the method can identify unspecified conditions in a real-world scenario, but does not provide quantitative metrics or comparative analysis with other methods.",Yes,,Not specified,Proposed in this paper,,"Detect, Measure","The paper mentions that the process of extracting scenario elements from the formal scenario model is ""implemented in Java."" However, it does not provide detailed information about the full tool implementation.","The tool functionality includes:

Parsing a formal scenario model to recognize tokens and organize the syntax tree
Generating an XML format file based on the syntax tree
Traversing the XML DOM tree to extract condition guards, associated events, and actions
Constructing a condition guard tree
Performing completeness analysis on the tree
Performing consistency analysis on the tree
Status: Proposed, Partially Implemented
Validation: Not validated in this paper. The paper provides an example application (Car Alarm System) to illustrate the approach, but does not present a formal validation of the tool.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
241,España 2010,An empirical comparative evaluation of requirements engineering methods,Consensus,Yes,241,An empirical comparative evaluation of requirements engineering methods,Spain,2010,Journal,Journal of the Brazilian Computer Society,"Requirements Engineering (RE) is a relatively young discipline, and still many advances have been achiev- ed during the last decades. In particular, numerous RE ap- proaches are proposed in the literature with the aim of un- derstanding a certain problem (e.g. information systems de- velopment) and establishing a knowledge base that is shared between domain experts and developers (i.e. a requirements specification). However, there is a growing concern for em- pirical validations that assess RE proposals and statements. This paper is related to the assessment of the quality of func- tional requirements specifications, using the Method Evalu- ation Model (MEM) as a theoretical framework. The MEM distinguishes the actual efficacy and the perceived efficacy of a method. In order to assess the actual efficacy or RE methods, the conceptual model quality framework by Lind- land et al. can be applied; in this paper, we focus on the completeness and granularity of requirements models and extend this framework by defining four new metrics (e.g. de- gree of functional encapsulations completeness with respect This paper revises and extends previous work that has been published in the 17th IEEE International Requirements Engineering Conference (RE’09) [1]. S. España () · N. Condori-Fernandez · Ó. Pastor Centro de Investigación en Métodos de Producción de Software, Universidad Politécnica de Valencia, Valencia, Spain e-mail: sergio.espana@pros.upv.es N. Condori-Fernandez e-mail: nelly@pros.upv.es Ó. Pastor e-mail: opastor@pros.upv.es A. González Departamento de Sistemas Informáticos y Computación, Universidad Politécnica de Valencia, Valencia, Spain e-mail: agdelrio@dsic.upv.es to a reference model, number of functional fragmentation er- rors). In order to assess the perceived efficacy, conventional questionnaires can be used. A laboratory experiment with master students has been carried out, in order to compare (using the proposed metrics) two RE methods; namely, Use Cases and Communication Analysis. With respect to actual efficacy, results indicate greater model quality (in terms of completeness and granularity) when Communication Analy- sis guidelines are followed. With respect to perceived effi- cacy, we found that Use Cases was perceived to be slightly easier to use than Communication Analysis. However, Com- munication Analysis was perceived to be more useful in terms of determining the proper business processes granu- larity. The paper discusses these results and highlights some key issues for future research in this area",Yes,"Lindland et al. [26] define that a model (M) has achieved semantic completeness if it contains all the statements about the domain (D) that are correct and relevant. That is, D\M = ∅.
Source: Referenced from Lindland OI, Sindre G, Sølvberg A (1994) Understanding quality in conceptual modeling. IEEE Softw 11(2):42–49

A model has achieved feasible completeness when there is no relevant statement about the domain, not yet included in the model, such that the additional benefit to the conceptual model from including the relevant statement exceeds the drawbacks of including it. That is, D\M = S = ∅, where S is the set of correct and relevant statements not yet in the model.
Source: Referenced from Lindland OI, Sindre G, Sølvberg A (1994) Understanding quality in conceptual modeling. IEEE Softw 11(2):42–49

A germinal definition states that a model has achieved feasible functional completeness whenever all relevant functional requirements that are worth being specified have been included in the model (adapted from [26]).
Source: Proposed in this paper, adapted from Lindland OI, Sindre G, Sølvberg A (1994) Understanding quality in conceptual modeling. IEEE Softw 11(2):42–49",Yes,,Degree of functional encapsulations completeness (degFEC),Measures the completeness of functional requirements by comparing the specified functions to a reference model.,Proposed in this paper,,"Calculate the ratio of functional encapsulations in the evaluated model to those in the reference model. degFEC = |F| / |Fr|, where F is the set of functions in the evaluated model and Fr is the set of functions in the reference model.",Degree of linked communications completeness (degLCC),Measures the completeness of linked communications (outputs triggered by functions) by comparing to a reference model.,Proposed in this paper,,"Calculate the ratio of linked communications in the evaluated model to those in the reference model. degLCC = |LC| / |LCr|, where LC is the set of linked communications in the evaluated model and LCr is the set in the reference model.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Degree of functional encapsulations completeness (degFEC),Quantifies the completeness of functional requirements relative to a reference model.,degFEC = |F| / |Fr|,Proposed in this paper,,Degree of linked communications completeness (degLCC),Quantifies the completeness of linked communications relative to a reference model.,degLCC = |LC| / |LCr|,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Reference model comparison,"Completeness is quantified by comparing the requirements specification to a reference model created by expert modelers.
Source: Proposed in this paper",Proposed in this paper,,"Create a reference model through expert consensus
Compare the evaluated model to the reference model
Calculate completeness metrics (degFEC and degLCC) based on the comparison",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
240,Kaiya 2006,Using domain ontology as domain knowledge for requirements elicitation,Consensus,Yes,240,Using Domain Ontology as Domain Knowledge for Requirements Elicitation,Japan,2006,Conference , 14th IEEE International Requirements Engineering Conference (RE'06),"Domain knowledge is one of crucial factors to get a great success in requirements elicitation of high quality, and only domain experts, not requirements analysts, have it. We propose a new requirements elicitation method ORE (Ontology based Requirements Elicitation), where a domain ontology can be used as domain knowledge. In our method, a domain ontology plays a role on semantic domain which gives meanings to requirements statements by using a semantic function. By using inference rules on the ontology and a quality metrics on the semantic function, an analyst can be navigated which requirements should be added for improving completeness of the current version of the requirements and/or which requirements should be deleted from the current version for keeping consistency. We define this process as a method and evaluate it by an experimental case study of software music players.",Yes,"Completeness (CMP) : The ontological elements that did not have any mapped requirements items can be candidates for missing requirements items
Source: Proposed in this paper
",Yes,,Ontology-based Requirements Elicitation (ORE) method,ORE uses a domain ontology to detect missing requirements by identifying unmapped ontological elements and tracing relationships between concepts.,Proposed in this paper,,"Map requirements items to ontological concepts
Calculate completeness measure
If completeness is low, trace relationships (e.g., ""apply"", ""perform"", ""is-a"", ""has-a"", ""require"") from mapped concepts to find unmapped concepts
These unmapped concepts represent potential missing requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Completeness (CMP),Measures the ratio of unmapped ontological elements to the total number of ontological elements,CMP = # {ontological elements that no requirements items are mapped into} / # {ontological elements (total number of ontological elements)},Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Ontology-based Requirements Elicitation (ORE) method,A systematic approach to quantify and improve requirements completeness using domain ontologies,Proposed in this paper,,"Map requirements items to ontological concepts
Calculate the completeness metric
Identify unmapped concepts through relationship tracing
Add new requirements items based on unmapped concepts
Recalculate completeness after updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Ontology-based Requirements Elicitation (ORE) method,A systematic approach to improve requirements completeness using domain ontologies,Proposed in this paper,,"Evaluate current requirements list using quality metrics (completeness, correctness, consistency, unambiguity)
If completeness is low:
a. Focus on mapped concepts of type ""function"", ""object"", and ""environment""
b. Trace ""apply"" and ""perform"" relationships to find new concepts
c. Trace ""is-a"", ""has-a"", and ""require"" relationships to find new concepts
Compose new requirements items based on newly found concepts
Add these new items to the requirements list
Repeat the process iteratively until desired completeness is achieved",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Comparative experiment with three subjects (two using ORE, one not using ORE)
Analysis of numerical data and process data from the experiment

Metrics used:

Number of requirements items
Number of mapped concepts
Correctness, Completeness, Consistency, and Unambiguity measures

Datasets:

Domain ontology of software music players (48 concepts, 67 relationships)
Initial requirements list of 6 items for a music player application

Key results and findings:

ORE led to semantically simpler requirements items
Mapping activities seemed objective across subjects
ORE encouraged iteration in the requirements elicitation process
Quality measures improved for all subjects, with most reaching near 100% except for completeness
The method aligned with natural human approaches to exploring domain concepts

Limitations:

Small sample size (only three subjects)
Limited to a single domain (software music players)",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
238,Gnesi 2005,An automatic tool for the analysis of natural language requirements,Consensus,Yes,238,An Automatic Tool for the Analysis of Natural Language Requirements,Italy,2005,Conference ,Not explicitly stated,"The availability of automatic tools for the quality analysis of Natural Language requirements is
recognized as a key factor for achieving software quality. Unfortunately, the state of the art and 
practice witnesses a lack of tools and techniques for the Natural Language requirements analysis.
This paper presents a methodology and a tool (called QuARS - Quality Analyzer for Requirement 
Specifications), for analyzing Natural Language requirements in a systematic and automatic way. 
The QuARS tool allows the requirements engineers to perform an initial parsing of the
requirements for automatically detecting potential linguistic defects that can determine ambiguity 
problems at the following development stages of the software product. This tool is also able to
support automaticaaly the consistency and completeness analysis by clustering the requirements 
",No,,Yes,,Under-specification detection,Detects sentences containing words that need to be instantiated or specified further.,Proposed in this paper,,"The tool searches for words needing instantiation (e.g., ""flow"" instead of ""data flow"" or ""control flow"", ""access"" instead of ""write access"" or ""remote access""). These are considered indicators of under-specification, which relates to incompleteness.",View derivation,Clusters requirements related to specific topics or aspects of the system.,Proposed in this paper,,Uses domain-specific dictionaries to identify and group related requirements. This can help detect missing requirements within a particular topic or aspect of the system.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Defect rate,Number of defective sentences divided by the total number of sentences,implied to be: (Number of defective sentences) / (Total number of sentences), Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,QuARS analysis,"Uses linguistic analysis to detect and count various types of defects in requirements, including those related to completeness (e.g., under-specification).",Proposed in this paper,,"The tool analyzes each sentence in the requirements document, detects defects based on predefined criteria and dictionaries, and calculates metrics such as the defect rate for different types of defects, including those related to incompleteness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,QuARS (Quality Analyzer for Requirement Specifications),Proposed in this paper,,"Detect, Measure",Software tool implemented in C++ with a graphical user interface,"Performs linguistic analysis of natural language requirements
Detects potential defects related to expressiveness, consistency, and completeness
Calculates metrics such as defect rates and readability index
Clusters requirements into ""Views"" based on specific topics or aspects","Implemented, Validated",Validated through multiple case studies with industrial requirements documents. The tool demonstrated ability to detect defects not found by manual analysis and provided consistent results across different domains.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
230,Xiaoxia 2008,Verifying service-oriented requirements using model checking,Consensus,Yes,230,Verifying Service-Oriented Requirements using Model Checking,China,2008,Conference ,IEEE International Conference on e-Business Engineering,"Software reuse has long been recognized to be an
effective way to improve software quality and produc-
tivity. Obtaining a proper set of reusable requirement
is the key to achieve successful domain engineering. By
tailoring the domain engineering, developers can ac-
quire requirements models for application engineering.
Early requirements analysis is one of the most impor-
tant and difficult phases in the software development
process. This paper presents an approach to model the
user requirements in a service-oriented view. We uses
the SOFM (Service-Oriented Feature Model) to struc-
ture requirements as SOCIM (Service-Oriented Com-
puter Independent Model), furthermore, automated
verification of requirements specification is done by
model checking. Model checking in this paper involves
two aspects such as completeness and consistency of
requirements. To do so, we transform the SOCIM into
a formal specification using a Kripke structure. An
electric book store is introduced throughout the paper,
which is used as an example to demonstrate our ap-
proach more clearly.",Yes,"Suppose fm is service-oriented feature model, f is a service feature, fm is called as complete service-oriented feature model iff ∀f ∈ fm.F ⇒ f. Rs ⊆ fm.F.
Source: Proposed in this paper
",Yes,,Model Checking for Completeness,"The paper proposes using model checking to verify the completeness of the Service-Oriented Feature Model (SOFM). This involves transforming the SOFM into a Simple Service Model (SSM) represented as a Kripke structure, and then verifying reachability properties for each service in the model.",Proposed in this paper,,"Transform the SOFM into a Simple Service Model (SSM) represented as a Kripke structure.
Generate Computational Tree Logic (CTL) formulas for each service in the model using the EF (Exists Finally) operator.
Use a model checker to verify these formulas on the Kripke structure.
If all services are reachable (i.e., all EF formulas are satisfied), the model is considered complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,SMV (Symbolic Model Verifier),Referenced ,no explicit citation provided,Measure,Not described in detail in the paper,SMV is mentioned as the model checker used to verify the CTL formulas generated from the SOFM.,, Not validated in this paper.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
226,Kim 2003,"Assessment of high integrity software components for completeness, consistency, fault-tolerance, and reliability",Consensus,Yes,226,"Assessment of High Integrity Software Components for Completeness, Consistency, Fault-Tolerance, and Reliability","South Korea, USA",2003,Book,"Component-Based Software Quality, Lecture Notes in Computer Science, vol 2693","The use of formal model based (FMB) methods to evaluate the quality of components is an important research area. Except for a growing number of exceptions, FMB methods are still not really used in practice. This chapter presents two case studies that illustrate the value of FMB approaches for developing and evaluating component-based software. In the first study, Zed (or Z) and Statecharts are used to evaluate (a priori) the software requirement specification of a Guidance Control System for completeness, consistency and fault-tolerance. The second study evaluates (post-priori) the reliability of a complex vehicle system using Stochastic Activity Networks (SANs). The FMB approach presented here provides further evidence that such methods can indeed be useful by showing how these two different industrial strength systems were assessed and the results. Clearly, future investigations of this nature will help to convince software system developers using component based approaches that such FMB methods should be considered as a valuable tool toward improving the software product lifecycle (quality, schedule and cost).",Yes,"The completeness of a specification is defined as a lack of ambiguity in terms of creating an implementation that can satisfy the specified requirements. Thus, the specification is incomplete if the system behavior is not precisely stated because the required behavior for some events or conditions is omitted or is subject to multiple interpretations
Source: Proposed in this paper",Yes,,"Z and Statecharts Translation Method
"," This method involves translating natural language requirements into Z notation and then into Statecharts. The process of translation helps uncover ambiguities and inconsistencies in the original requirements.
", Proposed in this paper,,"Ambiguities and incompleteness are revealed during the construction of Z schemas. When a misinterpreted specification in Z is uncovered during the execution of the Statecharts model, the Z specification can be refined using the test results.",Fault Injection Simulation,This technique involves injecting faults into the Statechart model at various breakpoints and comparing the outputs with expected values.,"Proposed in this paper
",,Faults are injected by altering system state variables at certain states or breakpoints during simulation. The outputs are then compared to the expected output determined by equations given in the requirements specification. Discrepancies can reveal incomplete or inconsistent requirements.,Statemate Simulation,"This method uses the Statemate tool to develop Activity-charts and Statecharts, which are then used for symbolic simulation.
",Proposed in this paper,,"The simulation method is used to verify assumptions, inject faults, and identify hidden errors that represent inconsistencies or incompleteness in the specification.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Fault Injection Test Results
","While not a direct metric of completeness, the paper uses the results of fault injection tests to indirectly measure the completeness of requirements",,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Z and Statecharts Translation and Simulation,"This methodology involves translating requirements into Z notation, then into Statecharts, and finally simulating the model to detect incompleteness.
",Proposed in this paper,,"While not providing a numerical quantification, this process helps identify specific instances of incompleteness or inconsistency in the requirements.",Reliability Analysis using Stochastic Activity Networks (SANs),"This methodology uses SANs to model and analyze the reliability of a system based on its components.
",Proposed in this paper,,"While not directly quantifying completeness, this method quantifies reliability, which can be seen as an indirect measure of the completeness and correctness of requirements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,, Iterative Refinement using Z and Statecharts,"This method involves iteratively refining the Z specifications based on issues uncovered during Statechart simulation.
"," Proposed in this paper
",,"Translate natural language requirements to Z notation
Convert Z specifications to Statecharts
Simulate Statecharts model
Identify issues through simulation
Refine Z specifications based on simulation results
Repeat steps 2-5 until no more issues are found",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through two case studies:

Guidance Control System (GCS) case study:


Evaluation approach: Applied the Z and Statecharts method to a subset of GCS requirements
Metrics: Completeness, consistency, and fault-tolerance of requirements
Dataset: Software Requirements Specification for GCS
Key results:

Identified incomplete and inconsistent requirements associated with ambiguities
Found that the SRS was incomplete and suggested specific additions to remedy the situation


Limitations: Only applied to a subset of the GCS requirements


Anti-lock Braking System (ABS) case study:


Evaluation approach: Used Stochastic Activity Networks to model and analyze system reliability
Metrics: System reliability over time, considering severity of failures and coincident failures
Dataset: Hypothetical ABS component data
Key results:

Demonstrated that incorporating severity and coincident failures in the model leads to different (and potentially more realistic) reliability predictions
Showed a difference in Mean Time to Failure of about 4,000 hours when considering coincident failures


Limitations:

Used hypothetical data rather than real-world data
Limited number of coincident failures and levels of severity modeled",Yes,,"Z/Eves
",Referenced,"ORA Canada, http://www.ora.on.ca/","Detect
",Not described in detail in the paper,"Z/Eves is a tool for analyzing and proving Z specifications
"," Implemented, Validated",,"Statemate
",Referenced,"ilogix, www.ilogix.com","Detect, Measure",Not described in detail in the paper,"Statemate is used to create and simulate Statechart models
","Implemented, Validated",,"UltraSAN
",Proposed in this paper,,"Measure
","X-window based software tool
",UltraSAN is used for evaluating systems represented as Stochastic Activity Networks (SANs),"Implemented, Validated",Used in the ABS case study to perform transient analysis and calculate reliability measures,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
219,Alrajeh 2012,Generating obstacle conditions for requirements completeness,Consensus,Yes,219,Generating Obstacle Conditions for Requirements Completeness,"UK, Belgium",2012,Conference ,International Conference on Software Engineering (ICSE),"Missing requirements are known to be among the major causes of software failure. They often result from a natural inclination to conceive over-ideal systems where the software-to-be and its environment always behave as expected. Obstacle analysis is a goal-anchored form of risk analysis whereby exceptional conditions that may obstruct system goals are identified, assessed and resolved to produce complete requirements. Various techniques have been proposed for identifying obstacle conditions systematically. Among these, the formal ones have limited applicability or are costly to automate. This paper describes a tool-supported technique for generating a set of obstacle conditions guaranteed to be complete and consistent with respect to the known domain properties. The approach relies on a novel combination of model checking and learning technologies. Obstacles are iteratively learned from counterexample and witness traces produced by model checking against a goal and converted into positive and negative examples, respectively. A comparative evaluation is provided with respect to published results on the manual derivation of obstacles in a real safety-critical system for which failures have been reported.",No,,Yes,,Obstacle generation through model checking and learning,"The approach uses a combination of model checking and inductive logic programming (ILP) to iteratively generate obstacles to goals, which represent potential incompleteness in requirements.",Proposed in this paper,,"Synthesize a behavior model from background properties
Use model checking to generate counterexamples (violations) and witnesses (satisfactions) of the goal
Convert counterexamples to positive examples and witnesses to negative examples for learning
Use ILP to learn potential obstacles from these examples
Repeat the process with newly identified obstacles negated and added to background properties until no more counterexamples are found",Manual regression-based obstacle identification,A formal technique for generating obstacles by regressing goal negations through available domain properties.,Referenced ,"van Lamsweerde and Letier, ""Handling obstacles in goal-oriented requirement engineering,"" IEEE Trans. on Softw. Eng., vol. 26, no. 10, pp. 978–1005, 2000.",Not described in detail in this paper.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Iterative obstacle generation and resolution," The approach iteratively generates obstacles and allows analysts to select significant ones, negate them, and add them to the background properties for further analysis.",Proposed in this paper,,"Generate obstacles using model checking and learning
Analyst selects significant obstacles
Negate selected obstacles and add to background properties
Repeat process to find more refined or additional obstacles
Process terminates when a domain-complete set of obstacles is generated",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Application to a real safety-critical system (LAS)
Comparison with manually derived obstacles from previous work

Metrics or criteria:

Ability to generate all manually identified obstacles
Ability to generate additional valid obstacles not found manually

Datasets:

London Ambulance Service specification

Key results and findings:

The approach generated all obstacles which were manually obtained in previous work
Additional obstacles were found that were not identified manually
The approach provided support for eliciting new domain properties
Finer sub-obstacles were produced depending on the granularity of provided domain properties

Limitations mentioned:

In some cases, the computed obstacles appeared too general
The approach may need multiple witnesses to a goal to produce more precise obstacles",Yes,,XHAIL,Referenced ,"O. Ray, ""Nonmonotonic abductive inductive learning,"" J. of Applied Logic, vol. 7, no. 3, pp. 329–340, 2009.",Detect,Inductive Logic Programming system,Used for learning obstacles from examples,"Implemented, Validated",Used in experiments on the London Ambulance Service case study,TAL,Referenced ,"D. Corapi, A. Russo, and E. Lupu, ""Inductive logic programming as abductive search,"" in Tech. Comm. of 26th Intl. Conf. on Log. Program., ser. (LIPIcs), vol. 7, 2010, pp. 54–63.",Detect, Inductive Logic Programming system,Used for learning obstacles from examples,"Implemented, Validated",Used in experiments on the London Ambulance Service case study, LTSA (Labelled Transition System Analyzer),Referenced ,"J. Magee and J. Kramer, Concurrency : State Models and Java Programs. John Wiley and Sons, 1999.",Detect,Model checking tool,Used for synthesizing behavior models and performing model checks to generate counterexamples and witnesses,"Implemented, Validated",Used in experiments on the London Ambulance Service case study,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Inductive Logic Programming (ILP),Detecting,ILP is used to learn obstacle conditions from positive and negative examples generated by model checking. It generalizes from specific traces to produce potential obstacles that could prevent goals from being achieved.,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
193,Ahuja 2014,Systems and context modeling approach to requirements analysis,Consensus,Yes,193,Systems and Context Modeling Approach to Requirements Analysis,India,2014,Conference ,"Proceedings of SPIE Vol. 9150 - Modeling, Systems Engineering, and Project Management for Astronomy VI","Ensuring completeness and correctness of the requirements for a complex system such as the SKA is challenging. Current system engineering practice includes developing a stakeholder needs definition, a concept of operations, and defining system requirements in terms of use cases and requirements statements. We present a method that enhances this current practice into a collection of system models with mutual consistency relationships. These include stakeholder goals, needs definition and system-of-interest models, together with a context model that participates in the consistency relationships among these models. We illustrate this approach by using it to analyze the SKA system requirements.",No,,Yes,,Consistency Checking across Models,"This method involves converting requirements artifacts into structured information and performing consistency checks across different models (stakeholder needs, system requirements, and domain knowledge)",Proposed in this paper,," The method detects incompleteness by identifying mismatches between different models. For example, it checks if all capabilities identified in the stakeholder needs are addressed by corresponding functions in the system requirements.",Domain Knowledge as Checklists,Utilizing domain knowledge models as checklists for completeness during the requirements gathering process.,Proposed in this paper,,"Incompleteness is detected by comparing the requirements against a comprehensive checklist derived from domain knowledge. If any expected capability or attribute is missing, it suggests that the requirements set is incomplete.",EMF Validation Framework,This is a tool used to implement consistency rules for checking across various documents of the SKA project.,Referenced ,"Eclipse Modeling Framework”, 26 May 2014, http://www.eclipse.org/modeling/emf/","It implements specific rules to check for consistency across different artifacts, such as entity and attribute name consistency, value consistency, and capability allocation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Model-Based Requirements Establishment,"This approach involves creating structured models of stakeholder needs, system requirements, and domain knowledge. It allows for easier identification and correction of inconsistencies and incompleteness.
",Proposed in this paper,,"Create domain knowledge models for stakeholder needs and system requirements
Convert use cases and requirements into structured information
Populate the structured information into system models derived from domain knowledge models
Use consistency checks to identify gaps or inconsistencies
Correct the identified issues by updating the appropriate models",Knowledge Reuse,Reusing knowledge from previous projects to fill gaps in the current set of requirements.,Proposed in this paper,,This method involves reviewing and incorporating relevant elements from past projects into the current requirements set to ensure no significant aspects are omitted.,Round-Trip Engineering across Tools,"This concept involves propagating changes across different tools used in the requirements engineering process, facilitated by a shared system model.",Proposed in this paper,,"Make changes in one tool (e.g., modifying a use case)
Import the changes into the shared system model
Perform consistency checking to identify needed updates in other artifacts
Propagate necessary changes to other tools (e.g., requirements management tool)
Import any additional changes or constraints back into the shared model
Propagate these back to the original tool if necessary",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper mentions that these concepts were piloted on the SKA (Square Kilometre Array) use cases and requirements. However, it does not provide a detailed evaluation methodology or results. ",Yes,,Eclipse Modeling Framework (EMF), Referenced,"Eclipse Modeling Framework”, 26 May 2014, http://www.eclipse.org/modeling/emf/",Detect,"Used to create metamodels for domain knowledge and system information
","Provides a framework for creating structured models of domain knowledge and system information
","Implemented
",Not validated in this paper,"EMF Validation Framework
",Referenced,"Eclipse Modeling Framework”, 26 May 2014, http://www.eclipse.org/modeling/emf/",Detect,Used to implement consistency rules for checking across various documents of the SKA project,"Implements specific rules to check for consistency across different artifacts, such as entity and attribute name consistency, value consistency, and capability allocation","Implemented
","The paper mentions using this tool to perform consistency checks on SKA project documents, but does not provide detailed validation results",Remote Application Platform (RAP),Referenced ,"Remote Application Platform formerly Rich Ajax Platform”, 26 May 2014, http://eclipse.org/rap/",Other (data entry),Automatically generated by EMF to create a web-based forms interface,Provides an interface for populating the models with domain knowledge and system information,"Implemented
",Not validated in this paper,Domain-aware tooling (concept),Proposed ,,"Detect, Measure",Proposed concept of integrating domain knowledge into existing systems engineering tools,Would allow tools to ingest domain models and provide domain-specific support for requirements engineering tasks,"Proposed
",,Jama (requirements management tool),Referenced,"Karl Wiegers Series, “Getting the Most from a Requirements Management Tool”, 26 May 2014, 
http://www.jamasoftware.com",Other (requirements management),"Existing commercial tool, with proposed modifications to support structured information","The authors propose adding fields to Jama to support structured representation of requirements, which would enable better consistency checking and information exchange with their proposed approach",existing tool,,Cameo Systems Modeler (SysML modeling tool),Referenced ,"Cameo Systems Modeler™”, 26 May 2014, http://www.nomagic.com/products/cameo-systems-modeler.html",Other (systems modeling),"Existing commercial tool, with proposed usage in a modeling mode rather than diagramming mode","The authors suggest using this tool in a way that directly maps interactions to entities and capabilities, supporting their structured modeling approach",existing tool,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
191,Nwokeji 2014,Automated completeness check in KAOS,Consensus,Yes,191,Automated Completeness Check in KAOS," UK, India",2014,Conference , ER Workshops 2014,"KAOS is a popular and useful goal oriented requirements engineering (GORE) language, which can be used in business requirements modelling, specification, and analysis. Currently, KAOS is being used in areas such as business process modelling, and enterprise architecture (EA). But, an incomplete or malformed KAOS model can result to incomplete and erroneous requirements analysis, which in turn can lead to overall systems failure . Therefore, it is necessary to check that a requirements specification in KAOS language are complete and well formed. The contribution at hand is to provide an automated technique for checking the completeness and well-formed-ness of a requirements specification in KAOS language. Such a technique can be useful, especially to business or requirements analysts in industries and research, to check that requirements specification in KAOS language is well formed.",,"A KAOS goal model is said to be complete when all leaf goals are assigned to agents-active entities, machine or human, in a system
Source: Referenced from [15] (Respect-IT. A kaos tutorial (2007))

Completeness Criteria 1: All goals must be refined until they become either leaf goals (expectations and requirements) or domain property.
Source: Proposed in this paper

Completeness Criteria 2: All leaf goals must be assigned to agents.
Source: Proposed in this paper

Completeness Criteria 3: All agents, especially machine or software agents, must be assigned to operations.
Source: Proposed in this paper",Yes,,Automated Completeness Check Tool,The tool is implemented by integrating a set of constraints defined in Epsilon Validation Language (EVL) with a graphics editor (Ktool) developed using the Eclipse Modelling Framework (EMF).,Proposed in this paper,,The tool checks the KAOS model against the three completeness criteria defined earlier. It uses EVL constraints to validate the model and provides visual feedback (error signs) and error messages when incompleteness is detected.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Iterative Refinement and Assignment,"The paper demonstrates a process of iteratively refining goals, assigning agents, and associating operations to correct incompleteness in KAOS models.",Proposed in this paper,,"Refine goals into leaf goals (expectations and requirements) or domain properties
Assign agents to leaf goals
Assign operations to agents
Validate the model using the automated tool
Repeat steps 1-4 until no incompleteness is detected",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used: Case study demonstration
Metrics or criteria used to assess effectiveness: Visual feedback (error signs) and error messages provided by the tool
Datasets or case studies employed: A simple case study of a card payment system for Bank xyz
Key results and findings: The tool successfully detected incompleteness in the KAOS model at each stage of refinement and provided appropriate feedback
Limitations or challenges mentioned: The tool is still at the pilot stage and has only been demonstrated with a basic KAOS model. The authors mention that they are still working on supporting more complex KAOS models.",Yes,,Ktool with Automated Completeness Check,Proposed in this paper,,"Detect, Measure",The tool is implemented by integrating Epsilon Validation Language (EVL) constraints with a graphics editor (Ktool) developed using the Eclipse Modelling Framework (EMF).,The tool provides a graphical interface for creating KAOS models and automatically checks the model against the three completeness criteria. It provides visual feedback (error signs) and error messages when incompleteness is detected.,"Proposed, Implemented, Validated",The tool was validated using a simple case study of a card payment system. The validation demonstrated the tool's ability to detect incompleteness in KAOS models and guide users towards completing the model.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
186,Miao 2016,Automated requirements validation for ATP software via specification review and testing,Consensus,Yes,188,Automated Requirements Validation for ATP Software via Specification Review and Testing,"China, Japan",2016,Conference ,International Conference on Formal Engineering Methods (ICFEM),"Complete and correct requirements specification is the foundation for
developing high-quality Automatic Train Protection (ATP) software. Requirements validation aims at facilitating the completeness and correctness of the
specification. In this paper, we propose a novel requirements validation approach
combining diagram-guided specification review and scenario-based specification
testing for ATP software. The specification is transformed into an executable
prototype. Diagrams are generated from the prototype to visualize the interactions between variables for an effective review. To check whether the specification conforms to the user's concerned scenarios of train operation, the
scenarios are specified as test cases for testing the prototype. The conformance is
then determined via test analysis. Through the review and the testing, the
requirements specification is validated. The case study and experiments show
that the approach achieves a higher error detection rate and while it reduces the
time costs comparing to the traditional review method used by our industrial
partner.",No,,Yes,,Syntax Error Detection,Detects syntax errors in the CASDL specification during transformation to executable prototype,"Proposed in this paper
",,Uses a Model Parser to analyze the syntax of the CASDL specification and detect errors during transformation to executable prototype,Circular Dependency Detection,Detects circular dependencies between variables in the specification,"Proposed in this paper
",,Analyzes variable dependencies to identify cycles in data flows between variables,Variable Dependency Diagram (VDD) Review,Generates diagrams to visualize variable dependencies for manual review,"Proposed in this paper
",,Engineer reviews generated VDDs to identify incorrect or missing variable relationships,State Transition Diagram (STD) Review,Generates diagrams to visualize state transitions for manual review,"Proposed in this paper
",,Engineer reviews generated STDs to identify incorrect or missing state transitions,Scenario-Based Testing,Tests executable prototype against user-defined operational scenarios,"Proposed in this paper
",,"Transforms scenarios to test scripts, executes prototype, compares results to expected outputs to detect inconsistencies",,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Statement Coverage,Percentage of statements in the prototype executed by test scenarios,"Not provided explicitly, but implies: (Executed Statements / Total Statements) * 100",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Scenario-Based Coverage Analysis,Executes test scenarios derived from operational scenarios and measures statement coverage of the prototype,Proposed in this paper,,"Executes test scripts generated from scenarios, tracks statement execution, calculates overall statement coverage percentage",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Unnamed supporting tool,Proposed in this paper,,"Detect, Measure",Custom tool developed by authors,"Transforms CASDL specification to executable prototype
Generates Variable Dependency Diagrams (VDDs) and State Transition Diagrams (STDs)
Executes prototype against test scenarios
Calculates statement coverage
Generates test reports and visualizations"," Implemented, Validated",Applied to real ATP software project specification with 455 requirements items. Detected more errors and reduced validation time compared to manual review.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
181,Espada 2013,A framework to evaluate complexity and completeness of KAOS goal models,Consensus,Yes,181,A Framework to Evaluate Complexity and Completeness of KAOS Goal Models,Portugal,2013,Conference ,CAiSE 2013 (International Conference on Advanced Information Systems Engineering),"Goal-Oriented Requirements Engineering (GORE) approaches have been developed to facilitate the requirements engineers work by, for example, providing abstraction mechanisms to help eliciting and modeling requirements. One of the well-established GORE approaches is KAOS. Nevertheless, in large-scale systems building KAOS models may result in incomplete and/or complex goal models, which are difficult to understand and change. This may lead to an increase in costs of product development and evolution. Thus, for large-scale systems, the effective management of complexity and completeness of goal models is vital. In this paper, we propose a metrics framework for supporting the quantitative assessment of complexity and completeness of KAOS goal models. Those metrics are formally specified, implemented and incorporated in a KAOS modeling tool. We validate the metrics with a set of real-world case studies and discuss the identified recurring modeling practices.",Yes,"For the sake of completeness of the goal model, each leaf goal must be assigned to an agent
Source: Proposed in this paper
",Yes,,PLGWA (Percentage of Leaf Goals With an Agent),Percentage of leaf goals that have an associated agent in the model.,Proposed in this paper,,Calculates the ratio of leaf goals with assigned agents to total leaf goals. A lower percentage indicates incompleteness in agent assignment.,PLGWO (Percentage of Leaf Goals With an Object),Percentage of leaf goals that have an associated object in the model.,Proposed in this paper,,Calculates the ratio of leaf goals with associated objects to total leaf goals. A lower percentage indicates incompleteness in object association.,PLOWS (Percentage of Leaf Obstacles With a reSolution),Percentage of leaf obstacles that have an associated goal resolution in the model.,Proposed in this paper,,Calculates the ratio of leaf obstacles with resolutions to total leaf obstacles. A lower percentage indicates incompleteness in obstacle resolution.,PLGWOp (Percentage of Leaf Goals With an Operation),Percentage of leaf goals that have at least one associated operation in the model.,Proposed in this paper,,Calculates the ratio of leaf goals with associated operations to total leaf goals. A lower percentage indicates incompleteness in goal operationalization.,POpWA (Percentage of Operations With an Agent),Percentage of operations that have an associated agent in the model.,Proposed in this paper,,Calculates the ratio of operations with assigned agents to total operations. A lower percentage indicates incompleteness in operation-agent assignment.,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,PLGWA (Percentage of Leaf Goals With an Agent),Percentage of leaf goals that have an associated agent in the model.,"PLGWA = NLGWA / NLG, where NLGWA is Number of Leaf Goals With an Agent and NLG is Number of Leaf Goals",Proposed in this paper,,PLGWO (Percentage of Leaf Goals With an Object),Percentage of leaf goals that have an associated object in the model.,"PLGWO = NLGWO / NLG, where NLGWO is Number of Leaf Goals With an Object and NLG is Number of Leaf Goals",Proposed in this paper,,PLOWS (Percentage of Leaf Obstacles With a reSolution),Percentage of leaf obstacles that have an associated goal resolution in the model.,"PLOWS = NLOWS / NLO, where NLOWS is Number of Leaf Obstacles With a reSolution and NLO is Number of Leaf Obstacles",Proposed in this paper,,PLGWOp (Percentage of Leaf Goals With an Operation),Percentage of leaf goals that have at least one associated operation in the model.,"PLGWOp = NLGWOp / NLG, where NLGWOp is Number of Leaf Goals With an Operation and NLG is Number of Leaf Goals",Proposed in this paper,,POpWA (Percentage of Operations With an Agent),Percentage of operations that have an associated agent in the model.,"POpWA = NOpWA / NOp, where NOpWA is Number of Operations With an Agent and NOp is Number of Operations",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,GQM (Goal Question Metric),An approach used to define metrics based on specific goals and questions.,Referenced,"Basili, V.R., Caldiera, G., Rombach, H.D.: The Goal Question Metric Approach. In: Marciniak, J.J. (ed.) Encyclopedia of Software Engineering, pp. 528–532. Wiley (1994)","Define goals, formulate questions to assess if goals are met, and specify metrics to answer those questions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,modularKAOS,Proposed in this paper,," Detect, Measure","Extension of an existing KAOS modeling tool, implemented using Model-Driven Development techniques on the Eclipse platform.",Allows building KAOS goal models and provides real-time feedback on completeness and complexity metrics.,"Implemented, Validated",Used to model and analyze several real-world case studies. Results of applying the metrics to these case studies are presented in the paper.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
171,Moketar 2016,TestMEReq: Generating abstract tests for requirements validation,Consensus,Yes,171,TestMEReq: Generating Abstract Tests for Requirements Validation,"Malaysia, USA, Australia",2016,Conference ,2016 3rd International Workshop on Software Engineering Research and Industrial Practice,"This paper introduces TestMEReq, an automated tool for early validation of requirements. TestMEReq supports requirements engineers (REs) in the validation of the correctness, completeness and consistency of elicited requirements with minimum effort and time through generated abstract tests components: test requirements and test cases, and a mock-up prototype of the user interface (UI). Abstract tests are derived from abstract models called Essential Use Cases (EUCs) and the Essential User Interface (EUI). Our evaluation results show that TestMEReq is useful in the requirements validation process: it reduces the effort and time spent to ensure good quality requirements.",No,,Yes,,Abstract Tests Generation,TestMEReq automatically generates abstract tests (test requirements and test cases) from Essential Use Case (EUC) and Essential User Interface (EUI) models. These abstract tests can help identify incomplete requirements.,Proposed in this paper,,"The tool transforms natural language requirements into EUC and EUI models, then generates test requirements and test cases from these models. Requirements engineers can review these generated tests to identify potential incompleteness in the original requirements.",Mock-up UI Prototype Generation,TestMEReq generates a mock-up UI prototype based on the EUI model and test requirements.,Proposed in this paper,,"The generated UI prototype provides a visual representation of the requirements, allowing stakeholders to identify missing or incomplete requirements by interacting with the prototype and comparing it to their expectations.",Traceability Function,"TestMEReq includes a traceability function that allows users to trace back and forth between textual requirements, EUC and EUI models, test requirements, and test cases.",Proposed in this paper,,"This traceability helps ensure correctness, completeness, and consistency by allowing users to verify that all aspects of the requirements are properly represented across different artifacts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Iterative Validation Process,TestMEReq supports an iterative process of requirements validation and correction through the generation and review of abstract tests and UI prototypes.,Proposed in this paper,,"Generate EUC and EUI models from textual requirements
Generate abstract tests (test requirements and test cases) from the models
Generate a mock-up UI prototype
Review and validate the generated artifacts
Identify and correct any incompleteness or inconsistencies in the requirements
Update the models and regenerate artifacts as needed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper describes two main evaluation approaches:

Accuracy Evaluation:


Approach: Applied TestMEReq to nearly 100 requirements scenarios from 15 software application systems
Metrics: Correctness ratio of generated abstract tests
Key results: Average correctness across all scenarios was approximately 84%
Limitations: The tool cannot produce 100% correct answers due to potential issues in extracting information from textual requirements


Usability Study:


Approach: Conducted interviews with three expert requirements engineers and a survey with 79 undergraduate students
Metrics: Usefulness, ease of use, ease of learning, and satisfaction (5-level Likert scale)
Key results:

86% found the tool useful
89% agreed the tool is easy to use
87% agreed the tool is easy to learn
80% were satisfied with the tool
",Yes,,TestMEReq,Proposed in this paper,,"Detect, Measure, Correct",utomated tool that generates abstract tests and mock-up UI prototypes from requirements,"Transforms natural language requirements into Essential Use Case (EUC) and Essential User Interface (EUI) models
Generates test requirements and test cases from the EUC and EUI models
Creates mock-up UI prototypes based on the generated tests
Provides traceability between textual requirements, models, and generated artifacts
Allows users to validate requirements by reviewing and testing the generated artifacts","Implemented, Validated","Accuracy evaluation using 100 requirements scenarios from 15 software applications (84% average correctness)
Usability study with 3 expert requirements engineers and 79 undergraduate students (high ratings for usefulness, ease of use, and satisfaction)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
166,Zhou 2014,A TASM-based requirements validation approach for safety-critical embedded systems,Consensus,Yes,166, A TASM-based Requirements Validation Approach for Safety-critical Embedded Systems,Sweden,2014,Conference ,"19th Ada-Europe International Conference on Reliable Software Technologies, Paris, France, June 23-27, 2014. Proceedings","Requirements validation is an essential activity to carry out in the system development life cycle, and it confirms the completeness and consistency of requirements through various levels. Model-based formal methods can provide a cost-effective solution to requirements validation in a wide range of domains such as safety-critical applications. In this paper, we extend a formal language Timed Abstract State Machine (TASM) with two newly defined constructs Event and Observer, and propose a novel requirements validation approach based on the extended TASM. Specifically, our approach can: 1) model both functional and non-functional (e.g. timing and resource consumption) requirements of the system at different levels and, 2) perform requirements validation by utilizing our developed toolset and a model checker. Finally, we demonstrate the applicability of our approach in real world usage through an industrial case study of a Brake-by-Wire system.",Yes,"ompleteness refers to situations where the requirements must possess two fundamental characteristics, in terms of neither objects nor entities are left undefined and the requirements can address all of the features.
Source: Proposed in this paper",Yes,,Coverage Checking,Checks whether the desired behaviors specified in features can be observed in the TASM model.,Proposed in this paper,,"Features are translated into observers which observe the execution of TASM models at runtime. If the Observation holds, the corresponding feature is regarded as covered by the requirements. This helps detect if any features are not addressed by the requirements.",Auxiliary Machine Checking,"Checks for undefined auxiliary machines (functions and sub machines) in the TASM model.
",Proposed in this paper,,"When executing the TASM model, the TASM Toolset detects if there are any undefined auxiliary machines, stops execution, and generates an error message. The existence of undefined auxiliary machines violates the completeness of the TASM model specifying requirements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,TASM-based Requirements Modeling Approach,"A systematic approach to model requirements using the extended TASM language, which helps in identifying and addressing incompleteness.
","Proposed in this paper
",,"Requirements Preprocessing: Distinguishes functional from non-functional requirements
Components Identification: Extracts software components and maps them to TASM main machines
Connections Identification: Identifies connections between components
Behavior Specification: Specifies behaviors of components
Property Annotation: Adds timing and resource consumption annotations",Features Modeling,"A process to formalize high-level requirements (features) into TASM observers.
","Proposed in this paper
",,"Listener Specification: Specifies events sequence representing observable behaviors
Observation Specification: Formalizes a predicate depending on observer variables
Events Filtering: Identifies interesting events and filters out irrelevant ones
Traceability Creation: Links the specified Observer to textual requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through a case study of a Brake-by-Wire (BbW) system developed by a major automotive company. The evaluation process included:
Evaluation approaches:

Case study application
Tool-supported analysis

Metrics or criteria:

Logical consistency
Completeness of auxiliary machines
Coverage of features
Deadlock freedom
Satisfaction of specific requirements (e.g., ReqH3)

Datasets or case studies:

Brake-by-Wire (BbW) system

Key results and findings:

No inconsistencies were detected in the TASM model
Some undefined auxiliary machines were identified, indicating areas where requirements needed more detail
Coverage checking showed that all features were satisfied by the requirements
Model checking confirmed deadlock freedom and satisfaction of ReqH3

Limitations or challenges:

The approach assumes semantic equivalence between requirements/features and their TASM/observer representations
The validity of the TASM model depends on the modelers' understanding of the system
Potential scalability issues with model checking for larger systems (state explosion problem mentioned)",Yes,,TASM Toolset,Proposed in this paper,,"Detect, Measure"," Not described in detail
","Executes TASM models, performs logical consistency checking, and detects undefined auxiliary machines","Implemented, Validated
",Validated through application to the BbW case study. Successfully detected undefined auxiliary machines and performed logical consistency checking.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
155,Zenuna 2013,A framework for completeness in requirements engineering: An application in aircraft maintenance scenario,Consensus,Yes,155,A Framework for Completeness in Requirements Engineering: An Application in Aircraft Maintenance Scenario,Brazil,2013,Conference , 20th ISPE International Conference on Concurrent Engineering,"This paper presents a framework for Completeness in Requirements Engineering (RE) to be used by civil aircraft industry in order to achieve a sufficient degree of completeness in requirements. In civil aircraft industry, completeness is crucial to the success of product development, where a missing requirement can mean a missing attribute. The completeness of requirements is such a need, and at the same time it is a huge challenge. In order to improve the requirements elicitation processes, in a manner that all requirements receive the same level of attention, this work proposes a framework which considers the entire system life cycle, all processes, and people involved. The proposed framework is applied in civil aircraft maintenance scenario, starting at the early stages of development, achieving a sufficient degree of completeness in civil aircraft for maintenance.",Yes,"Completeness in transport category airplane is defined by Aerospace Recommended Practice (ARP) 4754A as the degree to which a set of correct requirements, when met by a system, satisfy the interests of customers, users, maintainers, certification authorities as well as aircraft, system and item developers under all modes of operation and life cycle phases for the defined operating environment.
Source: Society of Automotive Engineers – (SAE), Aerospace Recommended Practice (ARP) 4754A: Development of civil aircraft and systems, Warrendale, 2011.

According to Carson et al. (2004), the completeness of the problem statement step is that all stakeholder interfaces are identified and quantified for all applicable life cycle phases (development, production, certification, training, operation, maintenance, and disposal phases) and relating operating modes.
",Yes,,Template or checklist approach,"Using predefined templates or checklists to ensure all aspects are covered
Source:",Referenced from multiple,"S. Robertson and J. Robertson, Mastering the Requirements Process, 2nd Edition, Boston: Addison Wesley Professional, 2006, v.1, 592 p.
A. Gabb, D. Haines, D. Jones, J. van Gaasbeek, W. Vietinghoff, P. Davies, G. Caple, S. Eppig, A. Hall, D. Lamont, ""Requirements Categorisation,"" In: Incose Annual International Symposium, 11th, 2001, Melbourne, Proceedings... Melbourne, 2001, p.1-8.
U.S. Department of Defense – (DoD), Military Standard: Defense and Program-Unique Specifications Format and Content Mil-Std-961E, Arlington, 2003.
Society of Automotive Engineers – (SAE), Aerospace Recommended Practice (ARP) 4754A: Development of civil aircraft and systems, Warrendale, 2011.","By addressing all elements in the checklist or template, incompleteness can be detected through missing items",Requirements-elicitation basis,"Approaches that involve users, such as Quality Function Deployment (QFD) and prototyping",Referenced,"R. S. Carson, E. Aslaksen, G. Caple, P. Davies, R. Gonzales, R. Kohl, A. Sahraoui, ""Requirements Completeness,"" In: Incose Annual International Symposium, 14th, 2004, Toulouse, Proceedings... Toulouse, 2004, p.1-15.
","By involving stakeholders directly, gaps in requirements can be identified through user feedback and interaction","Operating concepts and use case
","Use of functional analyses based on mission and concept of operations
",Referenced,"R. S. Carson, E. Aslaksen, G. Caple, P. Davies, R. Gonzales, R. Kohl, A. Sahraoui, ""Requirements Completeness,"" In: Incose Annual International Symposium, 14th, 2004, Toulouse, Proceedings... Toulouse, 2004, p.1-15.","By analyzing what the system must do in various scenarios, missing functional requirements can be detected",Review method,Reviewing requirements multiple times until no new items are identified,Referenced,"J.O. Grady, System Validation and Verification, Boca Raton: CRC Press, 1997, v.1, 327 p.","Through repeated reviews, missing requirements are gradually identified and added",Context analysis,Formal approach involving stakeholder identification and interface quantification,Referenced,"R. S. Carson, E. Aslaksen, G. Caple, P. Davies, R. Gonzales, R. Kohl, A. Sahraoui, ""Requirements Completeness,"" In: Incose Annual International Symposium, 14th, 2004, Toulouse, Proceedings... Toulouse, 2004, p.1-15.
","By systematically analyzing stakeholders and interfaces, gaps in requirements coverage can be detected",Framework for CoRE,"A structured process following three dimensions: analysis, integration, and structure
Source: Proposed in this paper",Proposed in this paper,,"By analyzing product and organization elements, flows, and attributes across multiple dimensions and lifecycle phases, incompleteness can be detected through missing elements or relationships",,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Framework for CoRE,"A structured process following three dimensions (analysis, integration, and structure) to elicit and write requirements in a way to achieve a sufficient degree of completeness",Proposed in this paper,,"Identify the product mission
Identify product entire life cycle processes
Identify product and organization stakeholders and their concerns
Identify system context for product and organization
Identify implementation architecture context for product and organization
Identify attributes for elements of product and organization
Write requirements
Add traceability
Add traceability to the architecture",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper mentions that a complete pilot study is planned to be conducted to confirm the method validation. However, no formal evaluation is presented in this paper. The authors applied the framework to an aircraft maintenance scenario as an illustrative example, but this is not a formal evaluation.",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
154,Sarmiento 2016,"Using correctness, consistency, and completeness patterns for automated scenarios verification",Consensus,Yes,154,"Using Correctness, Consistency, and Completeness Patterns for Automated Scenarios Verification",Brazil,2015,Conference ,2015 IEEE Second International Workshop on Requirements Patterns (RePa),"Scenario-based approaches are often used for Soft-
ware Requirements Specification (SRS). Since scenarios are usu-
ally written in natural language, they may be ambiguous and,
sometimes, inaccurate, which impair requirements quality. One
of the major factors for this problem is because interactions
among scenarios are seldom represented explicitly. As such, the
importance of correctness, consistency and completeness, in the
context of scenario-based representations should be rethought. In
this paper, we employ the NFR approach to organize the non-
functional requirements related to correctness, consistency and
completeness as a catalog of non-functional requirements (NFR).
We represent the initial catalog as non-functional requirements
patterns. These initial patterns can be effectively used for auto-
mated scenario-based SRS verification. The identified patterns
can be operationalized by evaluating properties related to these
NFRs. We demonstrate the applicability of this catalog by instan-
tiating it to the evaluation of an SRS based on a scenario lan-
guage.",Yes,"A specification is complete to the extent that all of its parts are present and each part is fully developed
Source: Referenced from Boehm, B. W. ""Guidelines for verifying and validating software requirements and design specifications,"" Proc. European Conf. Applied Information Technology (IFIP ',79), pp. 711-719, Sept. 1979.

We understand that a fully developed SRS is uniform and feasible, i.e. (1) each operation or condition is constructed using syntax and semantic rules; and (2) it is possible to perform each operation described by them and each internal/external condition is not violated.
Source: Proposed in this paper
",Yes,,Checklist for Scenario-based SRS,A method to detect missing information by following a checklist with heuristics in Scenario-based SRS.,Proposed in this paper,,It checks if the syntax of each element in the scenario and its relationships are described as established in the scenario model. This helps identify any missing or incomplete elements in the scenario description.,Analysis of Petri-Net Model, A method to detect missing information by traversing the equivalent Petri-Net (PN) model of the scenario.,Proposed in this paper,"referencing work by Lee et al. (J. Lee, J. I. Pan, and J. Y. Kuo, ""Verifying scenarios with time petri-nets,"" Inf. Softw. Technol., vol. 43, num. 13, pp. 769–781, 2001.)","It checks two main aspects:

If a place in the PN model is sent from a particular transition and received by a destination transition. Missing connections indicate that tokens cannot pass correctly.
If the transitions in the PN model interact with each other to exchange information (tokens). Isolated sub-Petri-Nets indicate missing interactions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Uniformity,Measures the consistency of syntax and semantic rules used in scenario descriptions.,,Proposed in this paper,,Feasibility,Measures the possibility of performing each operation described in the scenarios without violating internal/external conditions.,,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Petri-Net Analysis for Completeness,Uses Petri-Net models derived from scenarios to evaluate completeness through static and dynamic property analysis.,Proposed in this pape,,"Transform scenarios into Petri-Net models
Analyze static properties (Correct Token Passing, Fully Connected) to evaluate Feasibility
Analyze dynamic properties (Determinism, Bounded, Reversibility, Deadlock free) to evaluate Non-interferential, Bounded, Reversibility, and Live aspects
Use the results of these analyses to quantify the overall completeness of the scenarios",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,NFR Pattern-based Approach,Uses a catalog of Non-Functional Requirements (NFR) patterns to organize properties related to completeness and guide the correction process.,Proposed in this paper,"building on the NFR Framework (L. Chung and N. Subramanian, ""Software architecture adaptability: an NFR approach,"" Proceedings of the 4th International Workshop on Principles of Software Evolution, pp. 52--61, 2001.)","Identify relevant NFR patterns related to completeness (e.g., Uniformity, Feasibility)
Apply these patterns to the scenario-based SRS
Use the operationalizations suggested by the patterns to correct incompleteness issues",Petri-Net Based Correction,Uses Petri-Net analysis results to identify and correct completeness issues in scenarios., Proposed in this paper,,"Analyze the Petri-Net model derived from scenarios
Identify issues related to static properties (e.g., missing connections, isolated sub-nets)
Identify issues related to dynamic properties (e.g., non-determinism, unboundedness, irreversibility, deadlocks)
Use these identified issues to guide corrections in the original scenarios",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper demonstrates the applicability of the proposed methods through a sample application involving a simple scenario (""Submit Order"" in a Broker System). The evaluation approach used is a case study.
Key results and findings:

The approach successfully identified a deadlock in the sample scenario, demonstrating its ability to detect completeness issues.
The NFR pattern-based approach provides a systematic way to organize and evaluate completeness-related properties.
The Petri-Net based analysis allows for both static and dynamic property verification, which is crucial for comprehensive completeness evaluation.

Limitations mentioned:

The approach assumes that requirements engineers can properly write scenarios using the syntax and semantic rules described as a restricted form of natural language (RNL).
The sample application involved simple sentences and a simpler scenario. The scalability to complex scenarios needs further investigation.",Yes,,PIPE2 (Platform Independent Petri net Editor 2),Referenced,http://pipe2.sourceforge.net,"Detect, Measure",Not described in detail in the paper,"Allows creation and analysis of Petri-Net models, which are used in the paper's approach to verify completeness-related properties of scenarios",Implemented,"The paper demonstrates the use of PIPE2 for verifying the Petri-Net of the ""Submit Order"" scenario, successfully detecting a deadlock. However, no formal validation of the tool itself is presented in the paper.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
147,Cailliau 2013,Assessing requirements-related risks through probabilistic goals and obstacles,Consensus,Yes,147,Assessing requirements-related risks through probabilistic goals and obstacles,Belgium,2013,Journal,Requirements Engineering,"Requirements completeness is among the most critical and difficult software engineering challenges. Missing requirements often result from poor risk analysis at requirements engineering time. Obstacle analysis is a goal-oriented form of risk analysis aimed at anticipating exceptional conditions in which the software should behave adequately. In the identify-assess-control cycles of such analysis, the assessment step is not well supported by existing techniques. This step is concerned with evaluating how likely the obstacles to goals are and how likely and severe their consequences are. Those key factors drive the selection of most appropriate countermeasures to be integrated in the system goal model for increased completeness. Moreover, obstacles to probabilistic goals are currently not supported; such goals prescribe that some corresponding target property should be satisfied in at least X % of the cases. The paper presents a probabilistic framework for goal specification and obstacle assessment. The specification language for goals and obstacles is extended with a probabilistic layer where probabilities have a precise semantics grounded on system-specific phenomena. The probability of a root obstacle to a goal is thereby computed by up-propagation of probabilities of finer-grained obstacles through the obstacle refinement tree. The probability and severity of obstacle consequences is in turn computed by up-propagation from the obstructed leaf goals through the goal refinement graph. The paper shows how the computed information can be used to prioritize obstacles for countermeasure selection toward a more complete and robust goal model. A detailed evaluation of our framework on a non-trivial carpooling support system is also reported.",Yes,Having all relevant goals and obstacles identified in the goal model,Yes,,Probabilistic obstacle analysis,Identifies and assesses obstacles (exceptional conditions) that could prevent goal satisfaction,Proposed in this paper,,"Models goals and obstacles with probabilities
Propagates probabilities through obstacle refinement trees to assess likelihood of root obstacles
Propagates probabilities through goal models to assess severity of consequences
Identifies critical obstacle combinations that lead to goal violations",Leaf obstacle probability estimation,Estimates probabilities of leaf (most fine-grained) obstacles occurring,Proposed in this paper,,"Uses domain knowledge, statistical data, or runtime measures to estimate probabilities of leaf obstacles
Grounds probabilities on measurable system-specific phenomena",Goal satisfaction probability assessment,Assesses how likely goals are to be satisfied given obstacle probabilities,Proposed in this paper,,"Propagates obstacle probabilities up through goal model
Compares estimated probability of satisfaction to required degree of satisfaction for goals",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Estimated Probability of Satisfaction (EPS),The probability of a goal being satisfied given possible obstructions,P(G) where G is a goal,Proposed in this paper,,Required Degree of Satisfaction (RDS),The minimal probability of satisfaction admissible for a goal,RDS(G) where G is a goal,Proposed in this paper,,Severity of Violation (SV),Measures how severely a goal is violated,SV(G) = RDS(G) - P(G),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Probabilistic goal/obstacle modeling and analysis,odels goals and obstacles with probabilities and propagates them to assess risks,Proposed in this paper,,"Model goals and obstacles with probabilities
Propagate probabilities through obstacle and goal models
Identify critical obstacles based on probability and severity
Prioritize obstacles for resolution to increase completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Obstacle resolution,Selecting and applying countermeasures to resolve critical obstacles,Proposed in this paper,,"Identify critical obstacle combinations through probabilistic analysis
Prioritize obstacles for resolution based on probability and severity
Select appropriate countermeasures using risk reduction tactics
Integrate countermeasures into goal model to increase completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated on two case studies:

An ambulance dispatching system (illustrated in paper examples)
A carpooling support system (detailed evaluation reported)

Key results:

Helped identify and prioritize critical obstacles
Revealed incompleteness in initial requirements models
Guided selection of countermeasures to increase completeness
Scalable to non-trivial systems with many goals/obstacles

Limitations:

Relies on probability estimates that may be uncertain
Complexity in analyzing all obstacle combinations for large models",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
142,Yue 2015,aToucan: An automated framework to derive UML analysis models from use case models,Consensus,Yes,142,aToucan: An Automated Framework to Derive UML Analysis Models from Use Case Models,"Norway, Luxembourg, Canada",2015,Journal,ACM Transactions on Software Engineering and Methodology,"The transition from an informal requirements specification in natural language to a structured, precise
specification is an important challenge in practice. It is particularly so for object-oriented methods, defined in
the context of the OMG’s Model Driven Architecture (MDA), where a key step is to transition from a use case
model to an analysis model. However, providing automated support for this transition is challenging, mostly
because, in practice, requirements are expressed in natural language and are much less structured than
other kinds of development artifacts. Such an automated transformation would enable at least the generation
of an initial, likely incomplete, analysis model and enable automated traceability from requirements to code,
through various intermediate models. In this article, we propose a method and a tool called aToucan, building
on existing work, to automatically generate a UML analysis model comprising class, sequence and activity
diagrams from a use case model and to automatically establish traceability links between model elements of
the use case model and the generated analysis model. Note that our goal is to save effort through automated
support, not to replace human abstraction and decision making.
Seven (six) case studies were performed to compare class (sequence) diagrams generated by aToucan to the
ones created by experts, Masters students, and trained, fourth-year undergraduate students. Results show
that aToucan performs well regarding consistency (e.g., 88% class diagram consistency) and completeness
(e.g., 80% class completeness) when comparing generated class diagrams with reference class diagrams
created by experts and Masters students. Similarly, sequence diagrams automatically generated by aToucan
are highly consistent with the ones devised by experts and are also rather complete, for instance, 91%
and 97% message consistency and completeness, respectively. Further, statistical tests show that aToucan
significantly outperforms fourth-year engineering students in this respect, thus demonstrating the value of
automation. We also conducted two industrial case studies demonstrating the applicability of aToucan in two
different industrial domains. Results showed that the vast majority of model elements generated by aToucan
are correct and that therefore, in practice, such models would be good initial models to refine and augment
so as to converge towards to correct and complete analysis models. A performance analysis shows that the
execution time of aToucan (when generating class and sequence diagrams) is dependent on the number of
simple sentences contained in the use case model and remains within a range of a few minutes. Five different
software system descriptions (18 use cases altogether) were performed to evaluate the generation of activity
diagrams. Results show that aToucan can generate 100% complete and correct control flow information
of activity diagrams and on average 85% data flAow information completeness. Moreover, we show that
aToucan outperforms three commercial tools in terms of activity diagram generation.",No,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,R_CDcomplt (Class Diagram Completeness),"Measures the completeness of a class diagram based on missing classes, associations, and generalizations","R_CDcomplt = 1 - (R_clp1 + R_clp2 + R_clp3) / 3, where R_clp1, R_clp2, and R_clp3 represent the ratios of missing classes, associations, and generalizations respectively",Proposed in this paper,,R_SDcomplt (Sequence Diagram Completeness),"Measures the completeness of a sequence diagram based on message, interaction use, and combined fragment completeness","R_SDcomplt = (R_conMsg + R_conIU + R_conCF) / 3, where R_conMsg, R_conIU, and R_conCF represent message, interaction use, and combined fragment completeness respectively",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Class Diagram Completeness Evaluation,"Compares generated class diagrams to reference diagrams created by experts or Masters students, measuring missing classes, associations, and generalizations",Proposed in this paper,,Calculates ratios of missing elements and combines them into an overall completeness score,Sequence Diagram Completeness Evaluation,"Compares generated sequence diagrams to reference diagrams created by experts, measuring missing messages, interaction uses, and combined fragments
Source: Proposed in this paper",Proposed in this paper,,Calculates ratios of missing elements and combines them into an overall completeness score,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,aToucan,Proposed in this paper,,"Detect, Measure","Eclipse plug-in using EMF, Stanford Parser, and Kermeta","Automatically generates UML analysis models (class, sequence, and activity diagrams) from use case models written in RUCM","Implemented, Validated","Validated through seven case studies for class diagrams, six case studies for sequence diagrams, five case studies for activity diagrams, and two industrial case studies. Compared against expert solutions, Masters students' solutions, and trained fourth-year undergraduate students' solutions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
140,Ferrari 2014,Measuring and improving the completeness of natural language requirements,Consensus,Yes,140,Measuring and Improving the Completeness of Natural Language Requirements,Italy ,2014,Conference ,Requirements Engineering: Foundation for Software Quality (REFSQ) 2014,"[Context and motivation] System requirements specifications are normally written in natural language. These documents are required to be complete with respect to the input documents of the requirements definition phase, such as preliminary specifications, transcripts of meetings with the customers, etc. In other terms, they shall include all the relevant concepts and all the relevant interactions among concepts expressed in the input documents. [Question/Problem] Means are required to measure and improve the completeness of the requirements with respect to the input documents. [Principal idea/results] To measure this completeness, we propose two metrics that take into account the relevant terms of the input documents, and the relevant relationships among terms. Furthermore, to improve the completeness, we present a natural language processing tool named Completeness Assistant for Requirements (CAR), which supports the definition of the requirements: the tool helps the requirements engineer in discovering relevant concepts and interactions. [Contribution] We have performed a pilot test with CAR, which shows that the tool can help improving the completeness of the requirements with respect to the input documents. The study has also shown that CAR is actually useful in the identification of specific/alternative system behaviours that might be overseen without the tool.",Yes,"Backward functional completeness is achieved by a functional requirements specification when (1) all the relevant concepts expressed in the input documents are treated in the requirements specification; (2) all the relevant interactions among concepts expressed in the input documents are treated in the requirements specification.
Source: Proposed in this paper

A requirements specification is complete if all the necessary requirements are included
Source: Referenced from Boehm [6] (IEEE citation: B. Boehm, ""Verifying and validating software requirements and design specifications,"" IEEE Software, vol. 1, no. 1, pp. 75–88, 1984.)

A complete specification shall exhibit five properties: 1) No To-be-determined (TBD) items 2) No nonexistent references 3) No missing specification items (e.g., missing interface specifications) 4) No missing functions 5) No missing products (i.e., part of the actual software that are not mentioned in the specification).
Source: Referenced from Boehm [7] (IEEE citation: B. Boehm, ""Verifying and validating software requirements and design specifications,"" IEEE Software, vol. 1, no. 1, pp. 75–88, 1984.)

M has achieved semantic completeness if it contains all the statements about the domain D that are correct and relevant (i.e., D \ M = ∅).
Source: Referenced from Lindland et al. [9] (IEEE citation: O. Lindland, G. Sindre, and A. Solvberg, ""Understanding quality in conceptual modeling,"" IEEE Software, vol. 11, no. 2, pp. 42–49, 1994.)

Feasible semantic completeness as D \ M = S ≠ ∅. The set S is composed of correct and relevant statements, but there is no statement in S such as the benefit of including it in the specification exceeds the drawback of including it.
Source: Referenced from Lindland et al. [9] (IEEE citation: O. Lindland, G. Sindre, and A. Solvberg, ""Understanding quality in conceptual modeling,"" IEEE Software, vol. 11, no. 2, pp. 42–49, 1994.)",Yes,,Contrastive Analysis for Term Extraction,"This method uses natural language processing to identify domain-specific terms in input documents that are relevant to the requirements. It involves POS tagging, linguistic filtering, and computing a ""termhood"" metric (C-NC value) to rank terms. It then compares the frequency of these terms in domain-generic documents to identify those that are truly domain-specific.",Proposed in this paper,,The method identifies relevant domain-specific terms in the input documents. The absence of these terms in the requirements specification indicates potential incompleteness.,Relation Extraction,This technique identifies relevant relations between terms by analyzing their co-occurrence in the same or neighboring sentences. It uses the Log-likelihood metric to rank the strength of relations between terms.,Proposed in this paper,,The method identifies relevant relations between terms in the input documents. The absence of these relations in the requirements specification indicates potential incompleteness.,Degree of Concept Completeness (degCC),This metric measures how many relevant concepts from the input documents are present in the requirements specification.,Proposed in this paper,,It calculates the ratio of relevant terms present in the requirements to the total number of relevant terms identified in the input documents. A low score indicates incompleteness.,Degree of Interaction Completeness (degIC),This metric measures how many relevant interactions between concepts from the input documents are present in the requirements specification.,Proposed in this paper,,It calculates the ratio of relevant relations present in the requirements to the total number of relevant relations identified in the input documents. A low score indicates incompleteness.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Degree of Concept Completeness (degCC)
","Measures the completeness of concepts in the requirements specification compared to the input documents.
","degCC(D, I) = |Q| / |T|, where T is the set of relevant concepts in the input documents, and Q is the subset of T present in the requirements document D.",Proposed in this paper,,Degree of Interaction Completeness (degIC),"Measures the completeness of interactions between concepts in the requirements specification compared to the input documents.
","degIC(D, I) = |R| / |U|, where U is the set of relevant interactions in the input documents, and R is the subset of U present in the requirements document D.",Proposed in this paper,,Degree of Functional Encapsulation Completeness (degFEC),Measures the completeness of functional requirements specified in the requirements document compared to a reference model,"degFEC = |F| / |F_r|, where F_r is the set of functional requirements in the reference model, and F is the subset of F_r present in the requirements document.",Referenced ,"España et al. [10] (IEEE citation: S. España, N. Condori-Fernandez, A. Gonzalez, and O. Pastor, ""Evaluating the completeness and granularity of functional requirements specifications: A controlled experiment,"" in Proc. of RE 2009, pp. 161–170, 2009",Degree of Linked Communication Completeness (degLCC),Measures the completeness of linked communications specified in the requirements document compared to a reference model.,"degLCC = |LC| / |LC_r|, where LC_r is the set of linked communications in the reference model, and LC is the subset of LC_r present in the requirements document.",Referenced,"España et al. [10] (IEEE citation: S. España, N. Condori-Fernandez, A. Gonzalez, and O. Pastor, ""Evaluating the completeness and granularity of functional requirements specifications: A controlled experiment,"" in Proc. of RE 2009, pp. 161–170, 2009.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Term Extraction and Ranking," This methodology involves extracting terms from input documents using POS tagging and linguistic filters, then ranking them using the C-NC value metric and contrastive analysis.",Proposed in this paper,,"It identifies and ranks relevant terms in the input documents, which are then used to calculate the degree of concept completeness (degCC).","Relation Extraction and Ranking
","This methodology involves identifying relations between terms based on their co-occurrence in sentences, then ranking these relations using the Log-likelihood metric.",Proposed in this paper,,"It identifies and ranks relevant relations in the input documents, which are then used to calculate the degree of interaction completeness (degIC).",Completeness Assistant for Requirements (CAR) Tool,A tool that implements the term and relation extraction methodologies to assist in writing requirements and measure their completeness,Proposed in this paper,,The tool suggests relevant terms and relations to the requirements engineer and automatically calculates degCC and degIC as requirements are written.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Completeness Assistant for Requirements (CAR) Tool
", An interactive tool that suggests relevant terms and relations from input documents to the requirements engineer during the requirements writing process,Proposed in this paper,,"The tool suggests three terms to include in a requirement (one from relevant terms, two from relevant relations).
The user writes a requirement using the suggested terms.
The system checks if relevant terms or relations were used and updates completeness scores.
The system suggests new terms for the next requirement.
The process repeats, helping to improve completeness incrementally.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Here is my analysis of the paper based on the provided questions:
Paper inclusion/exclusion:
Should this paper be included or excluded in this research?

Yes

This paper should be included in the research on requirements completeness. It directly addresses methods for measuring and improving the completeness of natural language requirements specifications, which aligns with the research focus described.
General Information:
Study ID: [Not provided in the paper]
Title: Measuring and Improving the Completeness of Natural Language Requirements
Countries of the authors: Italy (All authors are from institutions in Pisa, Italy)
Year of Publication: 2014
Publication Type: 3. Conference
Name of the venue: Requirements Engineering: Foundation for Software Quality (REFSQ) 2014
Paper Abstract:
[Context and motivation] System requirements specifications are normally written in natural language. These documents are required to be complete with respect to the input documents of the requirements definition phase, such as preliminary specifications, transcripts of meetings with the customers, etc. In other terms, they shall include all the relevant concepts and all the relevant interactions among concepts expressed in the input documents. [Question/Problem] Means are required to measure and improve the completeness of the requirements with respect to the input documents. [Principal idea/results] To measure this completeness, we propose two metrics that take into account the relevant terms of the input documents, and the relevant relationships among terms. Furthermore, to improve the completeness, we present a natural language processing tool named Completeness Assistant for Requirements (CAR), which supports the definition of the requirements: the tool helps the requirements engineer in discovering relevant concepts and interactions. [Contribution] We have performed a pilot test with CAR, which shows that the tool can help improving the completeness of the requirements with respect to the input documents. The study has also shown that CAR is actually useful in the identification of specific/alternative system behaviours that might be overseen without the tool.
Definitions of Completeness:
Does the paper define the completeness of requirements?

Yes

List of definitions:

Text: ""Backward functional completeness is achieved by a functional requirements specification when (1) all the relevant concepts expressed in the input documents are treated in the requirements specification; (2) all the relevant interactions among concepts expressed in the input documents are treated in the requirements specification.""

Source: Proposed in this paper
Explanation: This definition focuses on the completeness of requirements with respect to input documents. It considers requirements complete when they cover all important concepts and relationships between concepts found in the initial documentation used to create the requirements.

Text: ""A requirements specification is complete if all the necessary requirements are included""

Source: Referenced from Boehm [6] (IEEE citation: B. Boehm, ""Verifying and validating software requirements and design specifications,"" IEEE Software, vol. 1, no. 1, pp. 75–88, 1984.)
Explanation: This is a general definition of completeness, suggesting that a specification is complete when it contains all required elements, without specifying what those elements might be.

Text: ""A complete specification shall exhibit five properties: 1) No To-be-determined (TBD) items 2) No nonexistent references 3) No missing specification items (e.g., missing interface specifications) 4) No missing functions 5) No missing products (i.e., part of the actual software that are not mentioned in the specification).""

Source: Referenced from Boehm [7] (IEEE citation: B. Boehm, ""Verifying and validating software requirements and design specifications,"" IEEE Software, vol. 1, no. 1, pp. 75–88, 1984.)
Explanation: This definition provides specific criteria for completeness, including the absence of placeholders, proper referencing, and coverage of all necessary specifications, functions, and products.

Text: ""M has achieved semantic completeness if it contains all the statements about the domain D that are correct and relevant (i.e., D \ M = ∅).""

Source: Referenced from Lindland et al. [9] (IEEE citation: O. Lindland, G. Sindre, and A. Solvberg, ""Understanding quality in conceptual modeling,"" IEEE Software, vol. 11, no. 2, pp. 42–49, 1994.)
Explanation: This definition views completeness in terms of a conceptual model (M) that includes all relevant and correct statements about the problem domain (D). It suggests completeness is achieved when there's no relevant information in the domain that's not in the model.

Text: ""Feasible semantic completeness as D \ M = S ≠ ∅. The set S is composed of correct and relevant statements, but there is no statement in S such as the benefit of including it in the specification exceeds the drawback of including it.""

Source: Referenced from Lindland et al. [9] (IEEE citation: O. Lindland, G. Sindre, and A. Solvberg, ""Understanding quality in conceptual modeling,"" IEEE Software, vol. 11, no. 2, pp. 42–49, 1994.)
Explanation: This definition acknowledges that perfect completeness may not be practical. It suggests that a specification is complete enough when any additional correct and relevant statements would not provide enough benefit to justify their inclusion.
Detection of Incompleteness:
Does the paper propose or reference any methods or techniques used to detect incompleteness of requirements?

Yes

List of methods/techniques:

Name: Contrastive Analysis for Term Extraction

Description: This method uses natural language processing to identify domain-specific terms in input documents that are relevant to the requirements. It involves POS tagging, linguistic filtering, and computing a ""termhood"" metric (C-NC value) to rank terms. It then compares the frequency of these terms in domain-generic documents to identify those that are truly domain-specific.
Source: Proposed in this paper
Detection Process: The method identifies relevant domain-specific terms in the input documents. The absence of these terms in the requirements specification indicates potential incompleteness.

Name: Relation Extraction

Description: This technique identifies relevant relations between terms by analyzing their co-occurrence in the same or neighboring sentences. It uses the Log-likelihood metric to rank the strength of relations between terms.
Source: Proposed in this paper
Detection Process: The method identifies relevant relations between terms in the input documents. The absence of these relations in the requirements specification indicates potential incompleteness.

Name: Degree of Concept Completeness (degCC)

Description: This metric measures how many relevant concepts from the input documents are present in the requirements specification.
Source: Proposed in this paper
Detection Process: It calculates the ratio of relevant terms present in the requirements to the total number of relevant terms identified in the input documents. A low score indicates incompleteness.

Name: Degree of Interaction Completeness (degIC)

Description: This metric measures how many relevant interactions between concepts from the input documents are present in the requirements specification.
Source: Proposed in this paper
Detection Process: It calculates the ratio of relevant relations present in the requirements to the total number of relevant relations identified in the input documents. A low score indicates incompleteness.
Quantification of Completeness:
Does the paper suggest methods or metrics to quantify the completeness of requirements?

Yes

List of metrics for quantification:

Name: Degree of Concept Completeness (degCC)
Description: Measures the completeness of concepts in the requirements specification compared to the input documents.
Formula: degCC(D, I) = |Q| / |T|, where T is the set of relevant concepts in the input documents, and Q is the subset of T present in the requirements document D.
Source: Proposed in this paper
Name: Degree of Interaction Completeness (degIC)
Description: Measures the completeness of interactions between concepts in the requirements specification compared to the input documents.
Formula: degIC(D, I) = |R| / |U|, where U is the set of relevant interactions in the input documents, and R is the subset of U present in the requirements document D.
Source: Proposed in this paper
Name: Degree of Functional Encapsulation Completeness (degFEC)
Description: Measures the completeness of functional requirements specified in the requirements document compared to a reference model.
Formula: degFEC = |F| / |F_r|, where F_r is the set of functional requirements in the reference model, and F is the subset of F_r present in the requirements document.
Source: Referenced from España et al. [10] (IEEE citation: S. España, N. Condori-Fernandez, A. Gonzalez, and O. Pastor, ""Evaluating the completeness and granularity of functional requirements specifications: A controlled experiment,"" in Proc. of RE 2009, pp. 161–170, 2009.)
Name: Degree of Linked Communication Completeness (degLCC)
Description: Measures the completeness of linked communications specified in the requirements document compared to a reference model.
Formula: degLCC = |LC| / |LC_r|, where LC_r is the set of linked communications in the reference model, and LC is the subset of LC_r present in the requirements document.
Source: Referenced from España et al. [10] (IEEE citation: S. España, N. Condori-Fernandez, A. Gonzalez, and O. Pastor, ""Evaluating the completeness and granularity of functional requirements specifications: A controlled experiment,"" in Proc. of RE 2009, pp. 161–170, 2009.)

List of methodologies for quantification:

Name: Term Extraction and Ranking
Description: This methodology involves extracting terms from input documents using POS tagging and linguistic filters, then ranking them using the C-NC value metric and contrastive analysis.
Source: Proposed in this paper
Quantification Process: It identifies and ranks relevant terms in the input documents, which are then used to calculate the degree of concept completeness (degCC).
Name: Relation Extraction and Ranking
Description: This methodology involves identifying relations between terms based on their co-occurrence in sentences, then ranking these relations using the Log-likelihood metric.
Source: Proposed in this paper
Quantification Process: It identifies and ranks relevant relations in the input documents, which are then used to calculate the degree of interaction completeness (degIC).
Name: Completeness Assistant for Requirements (CAR) Tool
Description: A tool that implements the term and relation extraction methodologies to assist in writing requirements and measure their completeness.
Source: Proposed in this paper
Quantification Process: The tool suggests relevant terms and relations to the requirements engineer and automatically calculates degCC and degIC as requirements are written.

Correction of Incompleteness:
Does the paper propose or reference any concepts, methods, or frameworks to correct the completeness of requirements?

Yes

List of methods/concepts for correction:

Name: Completeness Assistant for Requirements (CAR) Tool
Description: An interactive tool that suggests relevant terms and relations from input documents to the requirements engineer during the requirements writing process.
Source: Proposed in this paper
Process:
The tool suggests three terms to include in a requirement (one from relevant terms, two from relevant relations).
The user writes a requirement using the suggested terms.
The system checks if relevant terms or relations were used and updates completeness scores.
The system suggests new terms for the next requirement.
The process repeats, helping to improve completeness incrementally.

How were these methods or concepts evaluated?
The CAR tool was evaluated through a pilot test with the following characteristics:
Evaluation approaches used:

Comparative study: Two subjects wrote requirements for an Automatic Train Supervision (ATS) system with and without the CAR tool.

Metrics or criteria used to assess effectiveness:

Backward functional completeness: measured using degCC and degIC
Forward functional completeness: measured using degFEC and degLCC

Datasets or case studies employed:

Input document: IEEE Std 1474.1-2004 standard for Communications Based Train Control (CBTC) systems, specifically the chapter on ATS (about 5 pages long).
Reference model: A preliminary system specification defining 21 functions and 10 linked communications for the ATS system.

Key results and findings:

Backward functional completeness improved when using the CAR tool (average increase: ΔdegCC = 12.7% and ΔdegIC = 8.6%).
Results for forward functional completeness were mixed and inconclusive.
Qualitative analysis showed that requirements produced with CAR tended to be more specific and identified alternative behaviors of the system more often.

Limitations or challenges mentioned:

Small sample size (only two subjects) limits generalizability.
The order of tool usage may have influenced results (learning effect).
The subjects' prior knowledge of the tool's principles may have influenced their behavior.
The evaluation was limited to a single system (ATS) and a single input document.",Yes,,Completeness Assistant for Requirements (CAR),Proposed in this paper,,"Detect, Measure, Correct",The tool is implemented as a prototype that integrates natural language processing techniques for term and relation extraction from input documents. It provides an interactive interface for requirements writing.,"Extracts relevant terms and relations from input documents using contrastive analysis and linguistic techniques.
Suggests terms and relations to the user during requirements writing.
Automatically calculates and updates completeness metrics (degCC and degIC) as requirements are written.
Allows users to add or suspend terms and relations.
Displays the original input document for reference.","Proposed, Implemented, Validated","The tool was validated through a pilot test with two subjects writing requirements for an Automatic Train Supervision system. The test compared the completeness of requirements written with and without the tool. Results showed improved backward functional completeness when using the tool, but mixed results for forward functional completeness. The tool was found to be particularly useful in identifying specific cases and alternative behaviors that might be overlooked without tool support.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
133,Kaiya 2012,Improving software quality requirements specifications using spectrum analysis,Consensus,Yes,133,Improving Software Quality Requirements Specifications using Spectrum Analysis,Japan,2012,Conference ,2012 IEEE 36th International Conference on Computer Software and Applications Workshops,"A method called spectrum analysis for a software
requirements specification enables us to identify the complete-
ness and the correctness of the specification. The method can
be systematically applied when the specification is written in
a semi-formal notation based on the semantic structure of
each sentence in the specification. By using the rules based
on the semi-formal notation, necessary quality requirements
descriptions for each sentence can be recommended. However,
the case studies for evaluating the rules have not been fully
achieved. In addition, how to concretely update the require-
ments specification according to the recommendation rules is
not defined. In this paper, we report the case study to explore
how to improve a concrete specification based on the results
of spectrum analysis. Such an exploration can be a basis for
improving the way of defining the rules. As a result, the way of
defining the rules seems to be reasonable, but the organization
among the elements of the rules such as the concepts and types
should be introduced to facilitate the systematic application of
the rules. In addition, the current semi-formal notation should
be extended so as to explicitly represent the adverbs, which
are useful for specifying quality requirements.",No,,Yes,,Spectrum Analysis,Analyzes the distribution of quality requirements across a specification by comparing it to spectra of similar systems. Differences in spectra can indicate potential incompleteness.,Proposed in this paper,,"Create a list of requirements sentences from the specification
Use a catalog of quality requirements (e.g. ISO 9126 characteristics)
Map each requirement to relevant quality characteristics
Generate a ""spectrum"" showing the distribution of quality requirements
Compare to spectra of similar systems to identify potential gaps or incompleteness",Requirements Frame Model Analysis,Uses a semi-formal representation of requirements (noun frames and case frames) to detect missing or illegal elements.,Referenced ,"A. Ohnishi, ""Software requirements specification database based on requirements frame model,"" in ICRE, 1996, pp. 221–228.","Represent each requirement using noun frames and case frames
Check for missing required cases or illegal combinations based on predefined rules
Identify potential incompleteness where required elements are missing",Recommendation Rules,Rules that suggest quality requirements that should be included for certain types of functional requirements.,Proposed in this paper,"based on: H. Kaiya and A. Ohnishi, ""Quality requirements analysis using requirements frames,"" in QSIC, 2011, pp. 198–207.","Represent requirements using the case frame model
Apply recommendation rules based on the semantic structure
Identify potential incompleteness where recommended quality requirements are missing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Spectrum Analysis Similarity,Uses cosine similarity between quality requirement spectra to quantify completeness relative to a reference specification.,Proposed in this paper,,"Generate quality requirement spectra for the specification being evaluated and a reference ""complete"" specification
Calculate the cosine similarity between the two spectrum vectors
A similarity closer to 1 indicates higher completeness, while lower values suggest incompleteness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Recommendation Rule-Based Improvement,Applies recommendation rules to suggest quality requirements that should be added to functional requirements to improve completeness.,Proposed in this paper,"based on: H. Kaiya and A. Ohnishi, ""Finding incorrect and missing quality requirements definitions using requirements frame,"" IEICE Transactions, vol. 95-D, no. 4, pp. 1031–1043, 2012.","Apply recommendation rules to each functional requirement
For each recommended quality requirement:
a. Examine the recommendation's applicability
b. If applicable, add the quality requirement to the functional requirement
c. If not applicable, refine the rule or note exceptions
Iterate until no further recommendations are generated or deemed applicable",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper describes a case study to evaluate the recommendation rule-based improvement method:
Evaluation approaches:

Case study on a sample requirements specification for a web-based news browsing system
Comparison of results to expert-generated ""right requirements""

Metrics used:

Cosine similarity between quality requirement spectra

Datasets:

45 Conceptual Requirements Sentences (CRSs) extracted from a 13-page sample specification from: http://www.meti.go.jp/feedback/data/i30728aj.html, ""Guideline for writing requirements specifications (draft),"" 2003.
Expert-generated ""right requirements"" based on the original 45 CRSs

Key results:

Initial recommendations had 0.65 cosine similarity to expert requirements
After manual refinement, revised recommendations achieved 0.87 cosine similarity

Limitations:

Small dataset from a single domain
Reliance on expert judgment for ""right requirements""
Manual refinement required to achieve high similarity
Some recommendation rules found to be too general or not applicable in all cases",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
126,Barnat 2016,Analysing sanity of requirements for avionics systems,Consensus,Yes,126,Analysing sanity of requirements for avionics systems,Czech Republic,2016,Journal,Formal Aspects of Computing,"In the last decade it became a common practice to formalise software requirements to improve the clarity of users' expectations. In this work we build on the fact that functional requirements can be expressed in temporal logic and we propose new sanity checking techniques that automatically detect flaws and suggest improvements of given requirements. Specifically, we describe and experimentally evaluate approaches to consistency and redundancy checking that identify all inconsistencies and pinpoint their exact source (the smallest inconsistent set). We further report on the experience obtained from employing the consistency and redundancy checking in an industrial environment. To complete the sanity checking we also describe a semi-automatic completeness evaluation that can assess the coverage of user requirements and suggest missing properties the user might have wanted to formulate. The usefulness of our completeness evaluation is demonstrated in a case study of an aeroplane control system.",Yes,"a complete set of requirements extends to all sensible behaviours of a system.
Source: Proposed in this paper

Assuming that the user specifies what behaviour of the system is sensible, our coverage metric calculated what portion of this behaviour is described by the requirements specifying the system itself.
Source: Proposed in this paper",Yes,,Behavior-based coverage metric,This technique measures the completeness of requirements by comparing the behavior allowed by the assumptions (specified by the user) to the behavior described by the required and forbidden requirements,Proposed in this paper,,"Convert assumptions, required behavior, and forbidden behavior into Büchi automata
Enumerate almost-simple paths in the assumptions automaton
For each path, find the most similar path in the requirements automaton
Calculate average similarity across all paths to get overall coverage percentage",Candidate formula generation and evaluation,his method generates and evaluates candidate LTL formulae to improve the completeness of the requirements.,Proposed in this paper,,"Generate candidate LTL formulae based on atomic propositions used in existing requirements
Evaluate how much each candidate formula improves coverage when added to existing requirements
Suggest formulae that provide the largest coverage improvements to the user",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Directed partial coverage function,A function that measures the similarity between edge evaluations in two Büchi automata,"
δ(A1 = {l11, ..., l1n}, A2 = {l21, ..., l2m}) =
0 if ∃ i,j : l1i ≡ ¬l2j
p/m otherwise, where p = |A1 ∩ A2|",Proposed in this paper,, Path coverage,Measures how much one almost-simple path covers another," δ(π1, π2) = (Σ(i=0 to n) δ(A1i, A2i)) / n
Where n is the number of edges and Aji is the set of labels on the i-th edge of πj
",Proposed in this paper,,Automata coverage,"Measures how much one automaton covers another
"," δ(A1, A2) = (Σ(i=0 to m) max_π2i δ(π1i, π2i)) / m
Where m is the number of almost-simple paths in A1 ending in an accepting state",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Completeness evaluation algorithm,Iterative algorithm to evaluate completeness and suggest improvements,Proposed in this paper,,"Create automata for assumptions, required behavior, and forbidden behavior
Enumerate almost-simple paths in assumptions automaton
For each candidate formula:

Create automaton for requirements + candidate
Calculate coverage of assumptions by this automaton


Select candidate that improves coverage the most
Repeat until desired coverage or iteration limit reached",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Candidate formula suggestion,"Suggests new LTL formulae to improve completeness
",Proposed in this paper,,"Generate candidate LTL formulae
Evaluate coverage improvement for each candidate
Suggest top candidates to user for inclusion in requirements


Name: Interactive completion
Description: Semi-automatic process where system suggests formulae and user selects which to include
Source: Proposed in this paper
Process:


System suggests coverage-improving formulae
User reviews suggestions and selects which to add
Process repeats iteratively until user is satisfied with completeness",Interactive completion,Semi-automatic process where system suggests formulae and user selects which to include,Proposed in this paper,,"System suggests coverage-improving formulae
User reviews suggestions and selects which to add
Process repeats iteratively until user is satisfied with completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through:

Case study on an airplane control system


Applied consistency, redundancy, and completeness checking
Demonstrated ability to detect inconsistencies, redundancies, and suggest completeness improvements
Showed iterative improvement of coverage metric


Experiments with randomly generated LTL formulae


Evaluated performance and scalability of consistency and redundancy checking
Showed reduction in number of checks compared to naive approach


Industrial evaluation with Honeywell International


Applied consistency and redundancy checking to real-world avionics requirements
Demonstrated applicability to industrial-scale problems
Identified performance limitations with complex formulae",Yes,,"DiVinE
","Brim L, ˇ Ceˇ ska M, Ro ˇ ckai P (2010) DiVinE: parallel distributed model checker. In: Proceedings of HiBi/PDMC, pp ˇ
4–7",,"Detect, Measure",Parallel explicit-state LTL model checker,"Translates LTL to Büchi automata, performs automata operations","Implemented, Validated
","Used in experiments, but specific validation not described for completeness checking",Looney,Proposed in this paper,,"Detect, Measure",Reimplementation of consistency and redundancy checking algorithms using SPOT LTL translator,"Performs consistency, redundancy, and completeness checking of LTL requirements
","Implemented, Validated",Evaluated on case studies and industrial requirements from Honeywell,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
122,Eckhardt 2016,Challenging Incompleteness of Performance Requirements by Sentence Patterns,Consensus,Yes,122,Challenging Incompleteness of Performance Requirements by Sentence Patterns,Germany,2016,Conference ,2016 IEEE 24th International Requirements Engineering Conference (RE),"Performance requirements play an important role in software development. They describe system behavior that directly impacts the user experience. Specifying performance requirements in a way that all necessary content is contained, i.e., the completeness of the individual requirements, is challenging, yet project critical. Furthermore, it is still an open question, what content is necessary to make a performance requirement complete. To address this problem, we introduce a framework for specifying performance requirements. This framework (i) consists of a unified model derived from existing performance classifications, (ii) denotes completeness through a content model, and (iii) is operationalized through sentence patterns. We evaluate both the applicability of the framework as well as its ability uncover incompleteness with performance requirements taken from 11 industrial specifications. In our study, we were able to specify 86% of the examined performance requirements by means of our framework. Furthermore, we show that 68% of the specified performance requirements are incomplete with respect to our notion of completeness. We argue that our framework provides an actionable definition of completeness for performance requirements.",Yes,"Given a performance requirement, we define the completeness of the requirements with respect to the presence of all mandatory content elements, i.e., we call a requirement complete if all mandatory content elements are present in the textual representation of the requirement.
Source: Proposed in this paper

Definition (Strong Completeness of Performance Requirements). A performance requirement is strongly complete, if all mandatory content elements (w.r.t the content model) are explicitly contained in its textual representation.
Source: Proposed in this paper

Definition (Weak Completeness of Performance Requirements). A performance requirement is weakly complete, if all mandatory content elements (w.r.t. the content model) are explicitly or implicitly contained in its textual representation
Source: Proposed in this paper

Definition (Incompleteness of Performance Requirements). A performance requirement is incomplete, if at least one mandatory content elements (w.r.t. the content model) is missing in its textual representation.
Source: Proposed in this paper
",Yes,,Sentence Pattern Application,"The authors developed sentence patterns based on their content model for performance requirements. By attempting to apply these patterns to existing requirements, they can identify missing mandatory content elements.",Proposed in this paper,,"The authors apply the sentence patterns to each performance requirement. If they are unable to apply the patterns due to missing or vague information, the requirement is marked accordingly. Each sentence fragment in the pattern is then classified as explicit, implicit, or missing. Requirements with missing mandatory content elements are considered incomplete.",Content Model Mapping,"The authors map the content of existing requirements to their proposed content model, which specifies mandatory and optional content elements for performance requirements.",Proposed in this paper,,Each requirement is analyzed to determine which content elements from the model are present (explicitly or implicitly) and which are missing. Requirements missing any mandatory content elements are considered incomplete.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Completeness Classification,Requirements are classified into three categories based on their completeness level.,,Proposed in this paper,,Percentage of Complete Requirements,The percentage of requirements that are strongly complete or weakly complete out of the total number of requirements analyzed.,(Number of strongly complete requirements + Number of weakly complete requirements) / Total number of requirements * 100,Proposed in this paper,,Percentage of Incomplete Requirements,The percentage of requirements that are incomplete out of the total number of requirements analyzed.,"Number of incomplete requirements / Total number of requirements * 100
Source: Proposed in this paper",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Content Element Presence Analysis,"Analyzing the presence (explicit, implicit, or missing) of mandatory content elements in each requirement.",Proposed in this paper,,"For each requirement, the presence of each mandatory content element is assessed. The requirement is then classified as strongly complete, weakly complete, or incomplete based on the presence of these elements.",Sentence Pattern Application Analysis,Attempting to apply the proposed sentence patterns to each requirement and analyzing the results.,Proposed in this paper,,The sentence patterns are applied to each requirement. The ability to apply the patterns and the presence of mandatory content elements are used to classify the requirement's completeness.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Sentence Pattern-based Specification,"Using the proposed sentence patterns to specify performance requirements, ensuring completeness by construction.",Proposed in this paper,,"Choose the performance requirement type (Time Behavior, Throughput, or Capacity)
Specify the requirement using the provided sentence patterns, filling in the required information for each sentence fragment
Add cross-cutting aspects using the provided patterns for those elements
Review the resulting requirement to ensure all mandatory content elements are present",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Case study analysis of industrial requirements specifications

Metrics or criteria used to assess effectiveness:

Applicability: Percentage of requirements that could be expressed using the proposed framework
Ability to detect incompleteness: Percentage of requirements classified as incomplete, weakly complete, and strongly complete

Datasets or case studies employed:

58 performance requirements extracted from 11 industrial specifications from 5 different companies across various application domains

Key results and findings:

86% of the performance requirements could be expressed using the proposed framework
18% of the requirements were strongly complete
32% of the requirements were weakly complete
68% of the requirements were incomplete with respect to the proposed notion of completeness

Limitations or challenges mentioned:

The completeness assessment is relative to the notion of completeness used in the study
The classification and translation of requirements into patterns was performed by the authors, which could introduce bias
The study examined only requirements previously identified as performance requirements, potentially missing some relevant requirements or including irrelevant ones
The sample size of 58 performance requirements may not be large enough to draw general conclusions about applicability",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
115,Jurkiewicz 2015,HAZOP-based identification of events in use cases: An empirical study,Consensus,Yes,115,HAZOP-based identification of events in use cases: An empirical study,Poland,2015,Journal,Empirical Software Engineering,"Completeness is one of the main quality attributes of requirements specifications. If functional requirements are expressed as use cases, one can be interested in event completeness. A use case is event complete if it contains description of all the events that can happen when executing the use case. Missing events in any use case can lead to higher project costs. Thus, the question arises of what is a good method of identification of events in use cases and what accuracy and review speed one can expect from it. The goal of this study was to check if (1) HAZOP-based event identification is more effective than ad hoc review and (2) what is the review speed of these two approaches. Two controlled experiments were conducted in order to evaluate ad hoc approach and H4U method to event identification. The first experiment included 18 students, while the second experiment was conducted with the help of 82 professionals. In both cases, accuracy and review speed of the investigated methods were measured and analyzed. Moreover, the usage of HAZOP keywords was analyzed. In both experiments, a benchmark specification based on use cases was used. The first experiment with students showed that a HAZOP-based review is more effective in event identification than ad hoc review and this result is statistically significant. However, the reviewing speed of HAZOP-based reviews is lower. The second experiment with professionals confirmed these results. These experiments showed also that event completeness is hard to achieve. It on average ranged from 0.15 to 0.26. HAZOP-based identification of events in use cases is an useful alternative to ad hoc reviews. It can achieve higher event completeness at the cost of an increase in effort.",Yes,"A use case is event complete if it contains description of all the events that can happen when executing the use case.
",Yes,,Ad hoc review,"Reviewers identify events in use cases without following any specific process or using any tools.
",Referenced ,commonly used in practice,"Analysts review use case scenarios and try to identify possible events based on their experience and intuition, without following a structured approach.",H4U (HAZOP for Use Cases) method,A structured approach adapting the HAZOP (Hazard and Operability Study) technique to analyze use cases and identify potential events.,Proposed in this paper,,Reviewers systematically analyze each step of a use case using a set of guidewords (primary and secondary keywords) to stimulate thinking about possible deviations from the intended behavior. This structured approach helps identify events that may not be apparent through ad hoc review.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Accuracy,Measures how many events a reviewer identifies compared to the total number of distinct events identified by all reviewers,"Accuracy(p) = Σ(from s=1 to distance(p)) #events(p,s) / Σ(from s=1 to distance(p)) #Events(s)
Where:


p is a participant in the experiment
distance(p) is the furthest step in the specification analyzed by participant p
#events(p,s) is the number of distinct events identified by participant p based on step s
#Events(s) is the number of distinct events identified by all participants based on step s", Proposed in this paper,,"Speed
",Measures how quickly a reviewer can analyze use case steps.,"Speed(p) = #steps(p) / T [steps/minute]
Where:


p is a participant in the experiment
#steps(p) is the number of steps reviewed by participant p
T is the total time spent on the review (constant: 60 min)", Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Empirical approximation of maximal set of events,Constructing an approximate maximal set of possible events based on all distinct events identified by participants in the experiments,Proposed in this paper,,"Collect all events identified by participants
Remove irrelevant and undetectable events
Group similar events into abstract classes
Use this set as a benchmark to calculate accuracy",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
110,Gralha 2015,Metrics for measuring complexity and completeness for social goal models,Consensus,Yes,110,Metrics for measuring complexity and completeness for social goal models,Portugal,2015,Journal,Information Systems,"Goal-oriented Requirements Engineering approaches have become popular in the Requirements Engineering community as they provide expressive modelling languages for requirements elicitation and analysis. However, as a common challenge, such approaches are still struggling when it comes to managing the accidental complexity of their models. Furthermore, those models might be incomplete, resulting in insufficient information for proper understanding and implementation. In this paper, we provide a set of metrics, which are formally specified and have tool support, to measure and analyse complexity and completeness of goal models, in particular social goal models (e.g. i*). Concerning complexity, the aim is to identify refactoring opportunities to improve the modularity of those models, and consequently reduce their accidental complexity. With respect to completeness, the goal is to automatically detect model incompleteness. We evaluate these metrics by applying them to a set of well-known system models from industry and academia. Our results suggest refactoring opportunities in the evaluated models, and provide a timely feedback mechanism for requirements engineers on how close they are to completing their models.",No,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,PGWME (Percentage of Goals With Means-End),Measures the percentage of goals that have means-end links,"PGWME = (NGWD / NGIAB) * 100
Where NGWD is the Number of Goals With Decompositions and NGIAB is the Number of Goals Inside Actors' Boundaries",Proposed in this paper,,PSWC (Percentage of Softgoals With Contributions),Measures the percentage of softgoals that have contribution links,"PSWC = (NSWD / NSIAB) * 100
Where NSWD is the Number of Softgoals With Decompositions and NSIAB is the Number of Softgoals Inside Actors' Boundaries",Proposed in this paper,,PAWEI (Percentage of Actors With Elements Inside),Measures the percentage of actors that have elements inside their boundary,"PAWEI = (NAWEI / NAct) * 100
Where NAWEI is the Number of Actors With Elements Inside and NAct is the Number of Actors
",Proposed in this paper,,PAWOUEI (Percentage of Actors WithOut Unconnected Elements Inside),Measures the percentage of actors that do not have unconnected elements inside their boundary,"PAWOUEI = 100 - PAWUEI
Where PAWUEI is the Percentage of Actors With Unconnected Elements Inside",Proposed in this paper,,PAWDOA (Percentage of Actors With Dependencies Or Associations),Measures the percentage of actors that have dependency or association links,"PAWDOA = (NAWDOA / NAct) * 100
Where NAWDOA is the Number of Actors With Dependencies Or Associations and NAct is the Number of Actors",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,Goal-Question-Metric (GQM) approach,"The paper uses the GQM approach to define and organize the metrics for quantifying completeness. This involves defining goals, questions related to those goals, and metrics to answer those questions",Referenced,"Basili, V.R., Caldiera, G., Rombach, H.D.: The Goal Question Metric Paradigm. Encyclopedia of Software Engineering, 1st ed., vol. 2. John Wiley & Sons, Inc., New Jersey, USA (1994)","The process involves defining completeness-related goals, formulating questions about those goals, and then defining metrics to answer those questions quantitatively.",OCL-based metric definition,The metrics are formally defined using the Object Constraint Language (OCL) upon the i* meta-model.,Proposed in this paper,,"The metrics are formally specified using OCL, which allows for precise calculation based on the structure of the i* models.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Model refinement based on metric feedback
",The paper suggests using the metrics as a feedback mechanism to guide the refinement and completion of i* models.,Proposed in this paper,,"Calculate completeness metrics for the current model
Identify areas of incompleteness based on low metric values
Refine the model by adding missing elements or relationships
Recalculate metrics to verify improvement","Refactoring patterns (proposed for future work)
",The authors mention defining and applying refactoring patterns for GORE models as future work.,Proposed in this paper,,Not fully specified as it's proposed for future work,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Application of metrics to existing models
Analytical evaluation of metric results

Metrics or criteria used to assess effectiveness:

The defined complexity and completeness metrics themselves

Datasets or case studies employed:
Ten well-known i* models were used:

Media Shop (MS)
Newspaper Office (NO)
Health Care (HC)
Health Protection Agency (HPA)
National Air Traffic Services (NATS)
My Courses (MC)
Mobile Media (MM)
By The Way (BTW)
Meeting Scheduler (MSr)
Patient Wellness Tracking (PWT)

Key results and findings:

The metrics were able to identify potential issues in the evaluated models, such as actors with unusually high responsibilities or low levels of completeness.
The results suggested refactoring opportunities in the evaluated models.
The metrics provided feedback on how close the models were to completion.

Limitations or challenges mentioned:

The paper mentions that further validation with more models is needed.
The need for establishing thresholds for suggesting model improvements is mentioned as future work.
The authors note that sometimes high complexity might be essential rather than accidental, requiring careful interpretation of the metrics.",Yes,,Eclipse-based i* editor with metrics support,Proposed in this paper,,"Detect, Measure","The tool is implemented as an Eclipse-based i* editor using Epsilon, EMF/GMF, and Ecore Tools.","Allows creation of i* models using a visual language
Computes complexity and completeness metrics on demand during the modelling process
Metrics are defined using OCL upon the i* meta-model","Implemented, Validated
",The tool was validated by applying it to ten well-known i* models from industry and academia. The results demonstrated the tool's ability to compute the defined metrics and provide insights into model complexity and completeness.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
102,Stephen 2017,Framework for measuring the quality of software specification,Consensus,Yes,102,Framework for Measuring the Quality of Software Specification,Malaysia ,2017,Journal,"Journal of Telecommunication, Electronic and Computer Engineering","This paper proposes a platform for measuring the quality
of structure and functional requirement in software requirement
specification (SRS). The SRS contains information needed to ensure the
quality of the software. Measurement will be proposed based on four
quality properties namely preciseness, consistency, completeness and
correctness. The completeness properties will be used to measure the
SRS which is based on IEEE 830 as a minimal standard. Meanwhile, the
consistency, correctness and preciseness properties are proposed to be
used for measuring the functional requirement in the document. The
measurement of the overall quality of the SRS will be calculated based
on all quality properties. The rules and formula for computing the SRS
quality are embedded in proposed framework., which is a basis for
platform for assessing the software quality",No,,Yes,, IEEE 830 Standard Comparison,The method compares the topics in the SRS table of contents with the topics specified in the IEEE 830 standard.,Proposed in this paper,,"The process involves matching topics in the SRS with topics in the IEEE 830 standard, using similarity semantic techniques to identify synonyms. Unmatched topics are considered additional. The completeness is then calculated based on the number of matched and additional topics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Structure Completeness Metric,A percentage-based metric that quantifies the completeness of the SRS structure based on the number of matched and additional topics compared to the IEEE 830 standard.,"S = ((∑Mt + At) / (C1 + ∑At)) * 100%

Where:
S = degree of completeness of structure
Mt = total number of matched topics
At = added topics by tested SRS table of content
C1 = constant of 23 (representing the 23 topics in IEEE 830)",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SRS Structure Analysis,"This methodology involves analyzing the SRS table of contents, comparing it with the IEEE 830 standard, and calculating a completeness score.",Proposed in this paper,,"Extract the table of contents from the SRS
Compare each topic with the IEEE 830 standard topics
Use similarity semantic techniques to identify synonyms
Count matched and additional topics
Apply the Structure Completeness Metric formula to calculate the completeness percentage",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94,Alshareef 2020,Validation framework for aspectual requirements engineering (ValFAR),Consensus,Yes,94,Validation Framework for Aspectual Requirements Engineering (ValFAR),Libya,2020,Conference ,ICEMIS'20 (International Conference on Engineering & MIS 2020),"Aspect-Oriented Requirements Engineering (AORE) extends the existing requirements engineering approaches to support the identification and handling of crosscutting concerns. Crosscutting concerns are considered as potential aspects and can lead to the phenomenal ""tyranny of the dominant decomposition"". Requirements-level aspects are responsible for producing scattered and tangled descriptions of requirements in the requirements document. Requirements validation artifact is an essential task in software development. This task ensures that requirements are correct and valid in terms of completeness and consistency, hence, reducing the development cost, maintenance and establish an approximately correct estimate of effort and completion time of the project. In this paper, we present a validation framework for aspectual requirements that can be used with AORE approaches to facilitate the validation of the resulting crosscutting relationships and aspects. The proposed framework comprises a high-level and low-level validation. The high-level validation is to validate the concerns with stakeholders, whereas the low-level validation validates the aspectual requirement by developers using a checklist. The approach has been evaluated using a case study. The results demonstrate that the proposed framework is feasible and acceptable.",No,,Yes,,High-level validation,Validates concerns with stakeholders using UML sequence diagrams and structured templates,Proposed in this paper,,Models functional concerns using UML sequence diagrams and validates them with stakeholders. Non-functional concerns are described in structured templates and linked to related functional concerns.,"Concern completeness checklist
",A checklist of questions to evaluate the completeness and consistency of concerns,Proposed in this paper,,Developers inspect concerns using a checklist of quality questions aimed at evaluating completeness and consistency. All questions must be answered satisfactorily.,Low-level validation,"Validates aspectual requirements using a checklist
",Proposed in this paper,,"Developers validate aspectual requirements using a checklist of questions targeting core concepts of aspects at the requirements level. All questions in the requirements section must be answered ""Yes"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Concern decomposition,Decomposing general concerns into sub-concerns,Proposed in this paper,,"If parts of the concern present limitations or design constraints
If parts are not used by other concerns but describe the issue
If the concern contains references to other concerns
If there's a need to derive new concerns",Iterative validation process,Repeating the validation process until all checklist questions are answered satisfactorily,Proposed in this paper,,"Apply the checklist to evaluate concerns
If any question is not answered satisfactorily, repeat the process
Continue iterations until all questions are answered ""Yes""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used: Case studies on two existing AORE approaches (AORE with ArCaDe and Theme/Doc)
Key results and findings:

The ValFAR method showed that identified concerns needed to be modified and refined several times before forming the basis for aspectual identification.
The framework demonstrated feasibility and acceptability in validating AORE artifacts.",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80,Chattopadhyay 2023,Completeness of Natural Language Requirements: A Comparative Study of User Stories and Feature Descriptions,Consensus,Yes,80,Completeness of Natural Language Requirements: A Comparative Study of User Stories and Feature Descriptions,"USA, Denmark",2023,Conference ,2023 IEEE 24th International Conference on Information Reuse and Integration for Data Science (IRI),"Checking the completeness of requirements is critical for software validation, as incomplete requirements can adversely affect the delivery of high-quality software within budget. Many existing methods rely on the domain model that defines the correct and relevant constructs, against which the requirements completeness is checked. However, building accurate and updated domain models requires considerable human effort, which is often challenging in practical settings. To operate in the absence of domain models, we propose to measure a textual requirement's completeness based on a universal linguistic theory, namely Fillmore's frame semantics. Our approach treats the frame elements (FEs) associated with a requirement's verb as the roles that should participate in the syntactic structure evoked by the verb. The FEs thus give rise to a linguistic measure of completeness, through which we compute a requirement's actual completeness. Using our linguistic-theoretic approach allows for a fully automatic completeness check of different real-world requirements. The comparisons show that our studied feature descriptions are more complete than user stories.",Yes,"Requirements are complete if all the correct and relevant statements for solving the problem in a given domain are expressed in an explicit manner.
Source: Referenced from [1] O. I. Lindland, G. Sindre, and A. Sølvberg, ""Understanding quality in conceptual modeling,"" IEEE Software, vol. 11, no. 2, pp. 42–49, March 1994.
",Yes,,Frame Semantics-based Completeness Analysis,This approach uses Fillmore's frame semantics theory to analyze the completeness of natural language requirements. It identifies verbs in a requirement sentence and compares the frame elements (FEs) that should be evoked by these verbs with the FEs that actually appear in the sentence.,Proposed in this paper,,"Identify verbs in the requirement sentence using Part-of-Speech tagging.
Map each verb to a lexical unit (LU) in FrameNet.
Look up the frame elements (FEs) associated with each LU in FrameNet.
Compare the FEs that should be evoked (based on FrameNet) with the FEs that actually appear in the sentence.
Calculate a completeness ratio based on the number of FEs present versus the number expected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Frame Elements Completeness Ratio,This metric calculates the ratio of frame elements (FEs) that actually appear in a requirement sentence to the total number of FEs that should be evoked by the verbs in the sentence.,Completeness Ratio = (Number of FEs actually present) / (Number of FEs expected based on FrameNet),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Automated Frame Semantics Analysis,"The authors developed a tool chain that automatically processes natural language requirements, identifies verbs, maps them to lexical units in FrameNet, and computes the completeness ratio.",Proposed in this paper,,"Use Open-SESAME for Part-of-Speech tagging to identify verbs.
Map verbs to lexical units in FrameNet.
Use NLTK to look up associated frame elements in FrameNet.
Compare expected FEs with actually present FEs.
Calculate the completeness ratio for each sentence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Frame Semantics-based Completeness Analysis Tool Chain,Proposed in this paper,,"Detect, Measure","The tool chain integrates several components:

Open-SESAME for Part-of-Speech tagging and verb identification
FrameNet for lexical unit and frame element lookup
NLTK (Natural Language Toolkit) for processing","utomatically processes natural language requirements, identifies verbs, maps them to lexical units in FrameNet, identifies expected and actual frame elements, and computes a completeness ratio.
","Implemented, Validated",The tool was validated through a comparative study of 133 user stories from the Scholar@UC project and 133 feature descriptions from Zoom. Statistical tests (Mann-Whitney U test) were used to compare the completeness ratios between the two types of requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79,Luitel 2023,Using Language Models for Enhancing the Completeness of Natural-Language Requirements,Consensus,Yes,79,Using Language Models for Enhancing the Completeness of Natural-Language Requirements,Canada,2023,Conference ,International Working Conference on Requirements Engineering: Foundation for Software Quality (REFSQ 2023),"[Context and motivation] Incompleteness in natural-language requirements is a challenging problem. [Question/problem] A common technique for detecting incompleteness in requirements is checking the requirements against external sources. With the emergence of language models such as BERT, an interesting question is whether language models are useful external sources for finding potential incompleteness in requirements. [Principal ideas/results] We mask words in requirements and have BERT's masked language model (MLM) generate contextualized predictions for filling the masked slots. We simulate incompleteness by withholding content from requirements and measure BERT's ability to predict terminology that is present in the withheld content but absent in the content disclosed to BERT. [Contribution] BERT can be configured to generate multiple predictions per mask. Our first contribution is to determine how many predictions per mask is an optimal trade-off between effectively discovering omissions in requirements and the level of noise in the predictions. Our second contribution is devising a machine learning-based filter that post-processes predictions made by BERT to further reduce noise. We empirically evaluate our solution over 40 requirements specifications drawn from the PURE dataset [1]. Our results indicate that: (1) predictions made by BERT are highly effective at pinpointing terminology that is missing from requirements, and (2) our filter can substantially reduce noise from the predictions, thus making BERT a more compelling aid for improving completeness in requirements.",,"Internal completeness is concerned with requirements being closed with respect to the functions and qualities that one can infer exclusively from the requirements
Source: Referenced from D. Zowghi and V. Gervasi, ""On the interplay between consistency, completeness, and correctness in requirements evolution,"" Information and Software Technology, vol. 45, no. 14, pp. 993–1009, 2003.

External completeness is concerned with ensuring that requirements are encompassing of all the information that external sources of knowledge suggest the requirements should cover.
Source: Referenced from D. Zowghi and V. Gervasi, ""On the interplay between consistency, completeness, and correctness in requirements evolution,"" Information and Software Technology, vol. 45, no. 14, pp. 993–1009, 2003.

External completeness is a relative measure, since the external sources may be incomplete themselves or not all the relevant external sources may be known
",Yes,,BERT-based Masked Word Prediction,The approach uses BERT's masked language model (MLM) to generate contextualized predictions for masked words in requirements. It simulates incompleteness by withholding content from requirements and measures BERT's ability to predict terminology present in the withheld content but absent in the disclosed content.,Proposed in this paper,,"Randomly partition the requirements specification into two subsets of equal sizes.
Disclose one subset to BERT and withhold the other.
Apply NLP preprocessing to the disclosed subset.
Mask words (nouns and verbs) in the disclosed subset one at a time.
Use BERT to generate predictions for each masked word.
Compare the predictions to the terminology in the withheld subset to identify potentially missing terms.",NLP-based completeness checking against stakeholder interviews,"Using NLP to check completeness of requirements against transcripts of stakeholder interviews
",Referenced,"A. Ferrari, F. dell'Orletta, G. O. Spagnolo, and S. Gnesi, ""Measuring and improving the completeness of natural language requirements,"" in International Working Conference on Requirements Engineering: Foundation for Software Quality. Springer, 2014, pp. 23–38.
Detection Process: Not detailed in the paper",Not detailed in the paper,NLP and visualization for identifying differences in stakeholder viewpoints,"Using NLP and visualization techniques to identify differences among stakeholders' viewpoints, which are then investigated as potential incompleteness issues",Referenced,"F. Dalpiaz, I. van der Schalk, and G. Lucassen, ""Pinpointing ambiguity and incompleteness in requirements engineering via information visualization and NLP,"" in International Working Conference on Requirements Engineering: Foundation for Software Quality. Springer, 2018, pp. 119–135.",Not detailed in the paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Accuracy,"Measures the proportion of BERT's predictions that match novel terminology in the withheld portion of requirements.
","Accuracy = |{t ∈ D | t matches some t' ∈ N }|/|D|
Where:
D = set of lemmatized predictions by BERT
N = novel terminology in the withheld portion
t matches t' if their word embeddings have a cosine similarity ≥ 85%",Proposed in this paper,,Coverage,"Measures the proportion of novel terminology in the withheld portion that is hinted at by BERT's predictions.
","Coverage = |{t ∈ N | t matches some t' ∈ D}|/|N|
Where:
N = novel terminology in the withheld portion
D = set of lemmatized predictions by BERT
t matches t' if their word embeddings have a cosine similarity ≥ 85%",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,BERT-based Terminology Recommendation with ML Filtering,"The approach uses BERT to generate predictions for masked words in requirements, then applies a machine learning-based filter to reduce noise in the predictions. The resulting list of recommended terms can be used to identify and potentially correct incompleteness in requirements.",Proposed in this paper,,"Apply NLP preprocessing to the requirements.
Mask words (nouns and verbs) in the requirements one at a time.
Use BERT to generate predictions for each masked word.
Apply a machine learning-based filter to remove non-relevant predictions.
Present the filtered list of recommended terms to requirements engineers for consideration in improving completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Empirical evaluation using 40 requirements specifications from the PURE dataset
Simulation of incompleteness by randomly withholding content from requirements
Cross-validation for machine learning model selection

Metrics or criteria used to assess effectiveness:

Accuracy: proportion of relevant predictions
Coverage: proportion of novel terminology hinted at by predictions
Classification Accuracy, Precision, and Recall for the ML-based filter

Datasets or case studies employed:

40 requirements specifications from the PURE dataset, covering 15 domains
Dataset split into development/training set (P1) and testing set (P2)

Key results and findings:

BERT predictions with 15 masked words per mask provided the best trade-off between accuracy and coverage.
Without filtering, BERT achieved an average accuracy of 12.11% and coverage of 40.04% on the test set.
ML-based filtering improved accuracy significantly:

Strict filter: increased accuracy by ~36% while decreasing coverage by ~20%
Lenient filter: increased accuracy by ~13% while decreasing coverage by ~5%


With filtering, approximately one in two to one in four recommendations were relevant, hinting at 20-35% of simulated missing terminology.

Limitations or challenges mentioned in the evaluation process:

Lack of access to domain experts for identifying genuine cases of incompleteness
Simulation of incompleteness through withholding may not perfectly represent real-world scenarios
Evaluation metrics based on automatically calculated similarity measures, not human judgment
Need for further research to establish the sensitivity limit of the approach to incompleteness",Yes,,BERT-based Completeness Enhancement Tool (not explicitly named in the paper),Proposed in this paper,,"Detect, Measure","Python-based implementation using various libraries:

SpaCy 3.2.2 for NLP pipeline
GloVe for word embeddings
Transformers 4.16.2 by Hugging Face for BERT
PyTorch 1.10.2+cu113 for BERT operation
WEKA 3-8-5 for ML-based filters
scikit-learn 1.0.2 for TF-IDF vectorization","Preprocesses requirements using NLP techniques
Masks words in requirements
Generates predictions using BERT
Filters predictions using ML-based classifiers
Provides recommendations for potentially missing terminology","Implemented, Validated
",Empirically validated using 40 requirements specifications from the PURE dataset. Validation involved simulating incompleteness and measuring the tool's ability to predict missing terminology.,WikiDoMiner,Referenced,"S. Ezzini, S. Abualhaija, and M. Sabetzadeh, ""WikiDoMiner: wikipedia domain-specific miner,"" in Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering, 2022, pp. 1749–1753.",Other (Domain-specific corpus extraction),Not detailed in the paper,Automatically extracts domain-specific corpora from Wikipedia based on input requirements specifications,Referenced,Not validated in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,BERT (Bidirectional Encoder Representations from Transformers),Detecting/Measuring,"The paper uses BERT's masked language model (MLM) to generate contextualized predictions for masked words in requirements. Specifically:

BERT Base model is used (12 encoder layers, hidden size of 768, ~110 million trainable parameters)
Cased model is employed as previous RE research suggests it's preferred for analyzing requirements
Configured to generate multiple predictions per masked word (optimal number determined to be 15)
Used to predict potentially missing terminology in requirements",Referenced,"J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, ""BERT: Pre-training of deep bidirectional transformers for language understanding,"" in Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 2019, pp. 4171–4186.","Machine Learning Classifiers (Random Forest, Support Vector Machine)",Filtering non-relevant predictions,"Various ML algorithms (including Neural Networks, Decision Trees, Logistic Regression) were evaluated for filtering BERT predictions. Random Forest and Support Vector Machine were found to be the most effective for different filtering strategies (strict vs. lenient).",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77,Amaral 2022,AI-Enabled Automation for Completeness Checking of Privacy Policies,Consensus,Yes,77,AI-Enabled Automation for Completeness Checking of Privacy Policies," Luxembourg, Canada, USA",2022,Journal, IEEE Transactions on Software Engineering,"Technological advances in information sharing have raised concerns about data protection. Privacy policies contain privacy-related requirements about how the personal data of individuals will be handled by an organization or a software system (e.g., a web service or an app). In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). A prerequisite for GDPR compliance checking is to verify whether the content of a privacy policy is complete according to the provisions of GDPR. Incomplete privacy policies might result in large fines on violating organization as well as incomplete privacy-related software specifications. Manual completeness checking is both time-consuming and error-prone. In this paper, we propose AI-based automation for the completeness checking of privacy policies. Through systematic qualitative methods, we first build two artifacts to characterize the privacy-related provisions of GDPR, namely a conceptual model and a set of completeness criteria. Then, we develop an automated solution on top of these artifacts by leveraging a combination of natural language processing and supervised machine learning. Specifically, we identify the GDPR-relevant information content in privacy policies and subsequently check them against the completeness criteria. To evaluate our approach, we collected 234 real privacy policies from the fund industry. Over a set of 48 unseen privacy policies, our approach detected 300 of the total of 334 violations of some completeness criteria correctly, while producing 23 false positives. The approach thus has a precision of 92.9% and recall of 89.8%. Compared to a baseline that applies keyword search only, our approach results in an improvement of 24.5% in precision and 38% in recall.",Yes,"A privacy policy is deemed ""complete"" according to GDPR if it explicitly contains certain information mandatory for ensuring data protection and privacy rights, e.g., about the rights individuals have over their personal data.
Source: Proposed in this paper
",Yes,,CompAI (Compliance checking of privacy policies using Artificial Intelligence against GDPR),CompAI is an AI-based approach that uses a combination of natural language processing and machine learning to automatically identify GDPR-relevant metadata in privacy policies and check them against completeness criteria.,Proposed in this paper,,"The approach first applies NLP techniques to preprocess and vectorize the text of privacy policies.
It then uses a combination of ML-based classification, similarity-based classification, and keyword-based classification to identify metadata types present in each sentence.
The identified metadata are then checked against a set of completeness criteria derived from GDPR to detect any incompleteness issues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Precision,The proportion of actual incompleteness issues correctly identified by the approach out of all issues identified.,"Precision = TP / (TP + FP), where TP is true positives and FP is false positives",Proposed in this paper,,Recall, The proportion of actual incompleteness issues correctly identified by the approach out of all actual issues.,"Recall = TP / (TP + FN), where TP is true positives and FN is false negatives",Proposed in this paper,,F2-measure,"The harmonic mean of precision and recall, with more weight given to recall.",F2 = 5 * (Precision * Recall) / (4 * Precision + Recall),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Manifestation-based evaluation,"Evaluates the presence or absence of metadata types in a privacy policy, rather than evaluating individual sentences.",Proposed in this paper,,"Identifies manifestations of metadata types in privacy policies
Computes precision, recall, and F2-measure based on correctly identified manifestations vs. actual manifestations
Aggregates results across multiple privacy policies to get overall quantification of completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,CompAI,Proposed in this paper,,"Detect, Measure"," Implemented in Java with approximately 7,500 lines of code. Uses DKPro toolkit for NLP, pre-trained GloVe word embeddings, Deeplearning4j for vector operations, and WEKA for machine learning.","Preprocesses and vectorizes privacy policy text
Identifies GDPR-relevant metadata using ML, similarity, and keyword-based classification
Checks identified metadata against completeness criteria
Generates a completeness analysis report","Implemented, Validated","Validated on a test set of 48 privacy policies. Achieved 92.9% precision and 89.8% recall in detecting incompleteness issues. Compared against a keyword-based baseline, showing significant improvements in accuracy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Machine learning classifiers (specifically Support Vector Machines),Detecting/Measuring,Used as part of an ensemble approach with similarity-based and keyword-based classification to identify GDPR-relevant metadata in privacy policy sentences. The classifiers are trained on word embedding features of annotated sentences.,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73,Bankauskaite 2018,An approach: SysML-based automated completeness evaluation of the system requirements specification,Consensus,Yes,73,An Approach: SysML-based Automated Completeness Evaluation of the System Requirements Specification,Lithuania,2018,Conference ,Not explicitly stated in the paper,"Model-Based Systems Engineering (MBSE) is systems engineering methodology that emphasizes the application of strict visual modeling principles. Models are created to deal with complexity, they allow to understand an area of interest or concern and provide unambiguous communication amongst interested sides. MBSE improves the quality of models of the system by providing the ability to evaluate it for completeness, correctness and consistency. MBSE is enabled by Systems Modeling Language (SysML) that supports the analysis, specification, design, verification, validation of complex systems and is used for modeling system requirements, behavior, structure, and parametrics. SysML is not a methodology, nor a method. In this case, it is necessary to choose a specific method in combination with system modeling language to comprehensively and accurately evaluate the completeness of system requirements specification (SRS). This opens up discussions of how to apply SysML provided infrastructure to evaluate the system requirements specification throughout the entire specifying process of SRS and achieve a high-quality of the SRS. In this paper, a new approach of how requirements specification, expressed with sufficient precision in SysML can be used for automated completeness evaluation",Yes,"We understand the completeness of the SRS as atomic requirements coverage by atomic model elements
Source: Proposed in this paper

",Yes,,Requirements Refinement Metrics,"Evaluates the completeness of the White Box stage of the Problem layer in MBSE Grid.
",Proposed in this paper,,"Calculates the percentage of stakeholder needs refined by model elements at the white box layer. Includes separate metrics for functional, physical, interface, and performance requirements.",Requirements Satisfaction Metrics,valuates the completeness of the Solution layer in MBSE Grid.,Proposed in this paper,,"Calculates the percentage of system requirements satisfied by atomic model elements at the solution layer. Includes separate metrics for functional, physical, interface, and performance requirements.",Requirements Derivation Metric,Evaluates the system requirements derivation from stakeholder needs.,Proposed in this paper,,Calculates the percentage of atomic system requirements derived from stakeholder needs.,Requirements Verification Metric,valuates the verification of system requirements by test cases.,Proposed in this paper,,Calculates the percentage of atomic system requirements verified by test cases.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Functional Requirements Refinement by Behavior Elements Metric (RR_FR),Evaluates the refinement of functional requirements by behavior elements.,"RR_FR = (FR_SN / FR) × 100%
",Proposed in this paper,,Physical Requirements Refinement by Structure Elements metric (RR_PhR),Evaluates the refinement of physical requirements by structure elements.,RR_PhR = (PhR_SN / PhR) × 100%,Proposed in this paper,,Interface Requirements Refinement by Proxy Ports Elements metric (RR_IR),Evaluates the refinement of interface requirements by proxy ports.,RR_IR = (IR_SN / IR) × 100%,Proposed in this paper,,Performance Requirements Refinement by Parameters Elements metric (RR_PR),"Evaluates the refinement of performance requirements by parameters.
", RR_PR = (PR_SN / PR) × 100%,Proposed in this paper,,Functional Requirements Satisfaction by Behavior Elements metric (RS_FR),Evaluates the satisfaction of functional requirements by behavior elements.,RS_FR = (FR_S / FR) × 100%,Proposed in this paper,,Physical Requirements Satisfaction by Structure Elements metric (RS_PhR),Evaluates the satisfaction of physical requirements by structure elements.,RS_PhR = (PhR_S / PhR) × 100%,Proposed in this paper,,Interface Requirements Satisfaction by Proxy Elements metric (RS_IR), Evaluates the satisfaction of interface requirements by proxy ports.,"RS_IR = (IR_S / IR) × 100%
",Proposed in this paper,,Performance Requirements Satisfaction by Parameters Elements metric (RS_PR),Evaluates the satisfaction of performance requirements by parameters.,RS_PR = (PR_S / PR) × 100%,Proposed in this paper,,"System Requirements Derivation metric (RD_SR)
","Evaluates the system requirements derivation from stakeholder needs.
",RD_SR = (SR_D / SR) × 100%,Proposed in this paper,,System Requirements Verification metrics (RV_SR),"Evaluates the verification of system requirements by test cases.
",V_SR = (SR_V / SR) × 100%,Proposed in this paper,,,SysML-based Automated Completeness Evaluation,An approach that uses SysML modeling in combination with the MBSE Grid method to evaluate the completeness of system requirements specifications throughout the entire specifying process.,Proposed in this paper,,"Model the system requirements using SysML following the MBSE Grid method.
Establish traceability relationships between atomic requirements and atomic model elements.
Calculate various completeness metrics for different aspects of the requirements (refinement, satisfaction, derivation, verification).
Analyze the metric results to determine the completeness of the requirements at different stages of the specification process.
Use a threshold (e.g., 90% in the case study) to determine when a particular stage of specification is sufficiently complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,, Iterative Refinement and Satisfaction Process,The paper implicitly suggests an iterative process of refining and satisfying requirements based on the completeness metrics.,Proposed in this paper,,"Calculate completeness metrics for a specific stage of requirements specification.
Analyze the results to identify areas of incompleteness.
Continue specifying and refining requirements in areas with low completeness scores.
Recalculate metrics and repeat the process until desired completeness thresholds are met.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Case study on a commercial project
Iterative application of the proposed metrics throughout the requirements specification process

Metrics or criteria used to assess effectiveness:

Various completeness metrics (refinement, satisfaction, derivation, verification) as defined in the paper
A threshold of 90% completeness for each metric to determine sufficient completeness

Datasets or case studies employed:

A commercial project modeled in SysML using the MagicDraw toolset
The system requirements specification was modeled according to the principles of MBSE grid

Key results and findings:

The approach allowed for continuous monitoring of requirements completeness throughout the specification process
Managers could make informed decisions about when to move to the next stage of specification based on metric results
The iterative process helped identify and address areas of incompleteness
The case study demonstrated successful application of the approach in a real-world project",Yes,,MagicDraw,Referenced,No specific citation provided,"Detect, Measure",CASE tool that supports SysML modeling and implements the proposed completeness evaluation approach,"upports SysML modeling following the MBSE Grid method
Calculates and displays completeness metrics
Generates charts for visualizing completeness data","Implemented, Validated",The tool was used in the case study to implement the proposed approach and evaluate the completeness of requirements in a commercial project. The paper demonstrates the tool's ability to calculate metrics and generate charts for analysis.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70,Crapo 2017,Requirements Capture and Analysis in ASSERT(TM),Consensus,Yes,70,Requirements Capture and Analysis in ASSERT™,USA,2017,Conference ,2017 IEEE 25th International Requirements Engineering Conference,"Capturing high-level requirements in a human readable but formal representation suitable for analysis is an important goal for GE. To that end we have augmented an existing controlled-English modeling language with a new controlled-English requirements capture language to create the Requirements Capture frontend of the ASSERT™ tool suite. Requirements captured in ASSERT™ can be analyzed for a number of possible shortcomings, both individually and collectively. Once a set of requirements has reached a satisfactory level of completeness, consistency, etc., it can then be further used to generate test cases and test procedures. This paper will focus on the requirements capture and analysis functions of ASSERT™ and will illustrate its capabilities with a sample problem previously used as a challenge problem for requirements specification.",No,,Yes,,ACL2s analysis,ACL2s is a requirements analysis tool that checks for completeness among other properties.,Referenced ,"Manolios, P. ""Scalable methods for analyzing formalized requirements and localizing errors"", U.S. Patent 9639450 B2, May 2, 2017.","The paper does not provide details on how ACL2s specifically detects incompleteness. It mentions that ACL2s runs checks including completeness, but does not elaborate on the process.",Two-stage Translation Process,"Requirements are translated from SRL (SADL Requirements Language) to a first-order logic form, then to ACL2s Lisp representation for analysis.",Proposed in this paper,,"hile not specifically for incompleteness detection, this translation process enables the use of ACL2s for various analyses including completeness checks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Iterative Refinement Process,"Requirements are captured, analyzed, and then refined based on the analysis results.",Proposed in this paper,,"Capture requirements using SADL Requirements Language (SRL)
Translate requirements to First Order Logic (FOL) form
Translate FOL form to ACL2s Lisp representation
Analyze requirements using ACL2s
Review analysis results
Refine requirements based on analysis results
Repeat process until satisfactory results are achieved",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper mentions one avionics project where the ASSERT™ tool was used:

Evaluation approaches:
Real-world application on an avionics project

Metrics or criteria:
Number of requirements processed
Number of errors detected
Number of test cases and test procedures generated

Datasets or case studies:
One avionics project (details not provided)

Key results and findings:
1002 requirements processed
No errors detected in the final iteration
19,276 test cases generated
38,272 test procedures generated",Yes,,ASSERT™,"Proposed
",,"Detect, Measure, Correct","The ASSERT™ platform includes components for requirements capture (using SRL), requirements analysis (using translation to FOL and then to target analysis tool format), and test case generation.
","Captures requirements in a controlled natural language, translates them for analysis, performs analysis including completeness checks, and generates test cases and procedures.","Proposed, Implemented, Validated","Validated through use on multiple projects within GE. In one avionics project, it processed 1002 requirements and generated over 19,000 test cases. A representative subset of test cases was manually verified.","ACL2s
",Referenced,"ACL2s: ""The ACL2 Sedan"" for Eclipse. [Online] http://acl2.ccs.neu.edu/acl2s","Detect, Measure", ACL2s is a requirements analysis tool that operates on requirements translated into Lisp format,"Performs checks including contingency, conflict, completeness, independence and surjectivity on requirements","Implemented
",Not validated in this paper.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64,Iqbal 2019,Forward engineering completeness for software by using requirements validation framework,Consensus,Yes,64,Forward Engineering Completeness for Software by Using Requirements Validation Framework,"China (Chongqing University)
Pakistan (University of Agriculture Faisalabad)",2019,Conference ,31st International Conference on Software Engineering and Knowledge Engineering (SEKE 2019),"In software development environment, software companies usually ignore the user requirements validation process in requirement gathering phase, which results in large number of modifications being required in the software maintenance phase to fulfill the customer requirements. Identification of accurate requirements from user stories and determining the effectiveness of work deliverable of software industry has always been a challenging task. In this paper, a new measurement approach for forward engineering completeness for software was introduced by using requirements validation framework. The forward engineering completeness for software was measured in two steps. In the first step, software component structure was developed in order to find the functional and non-functional requirements rejected by the customers in the requirement validation framework. In the second step, completeness of software from component-based development was determined in which the following parameters, such as functional, non-functional completeness attributes, were considered in the measurement process, and the unadopted attributes of the reuse code were also considered. Quality level for the attributes were assigned based upon the valuation of interior quality of the source code. Therefore, it resulted in the reduction of development time required for the software and the cost required for the software development was also reduced. A case study was incorporated in this research to explain the measurement process of forward engineering completeness. If the forward engineering code is satisfying the quality standards, then the code is in the completeness form. The attributes of code that negates to be used were considered as unadopted attributes.",Yes,"Completeness is defined as 'the state or condition of having all the necessary or appropriate parts
Source: Referenced (Oxford Dictionary citation provided: [16] G. D. S. Hadad, C. S. Litvak, J. H. Doorn, M. Ridao, Dealing with Completeness in Requirements Engineering, McGraw-Hill Education, New York, USA, 5th ed, 2015.)

Whereas requirements completeness is defined as 'a quality demanded to the set of software requirements and to each requirement itself, in order to ensure that there is no information left aside
Source: Referenced (Citation provided: [17] M. K. Pour, ""Encyclopedia of Information Science and Technology"", IGI Global, USA, 4th ed, 2017.)

The software after the development process is said to be in the completeness form, if it satisfies all the functional and non-functional requirements.
Source: Proposed in this paper",Yes,,Requirements Validation Framework,A framework that involves various stakeholders to validate and identify unadopted and adjusted requirements before software development.,Proposed in this paper,,"The framework uses a table (Table 1) to present software requirements to stakeholders. In a meeting, different categories of end-users from various regions present their views. This process helps identify requirements that are rejected (unadopted) or need modification (adjusted).",Software Component Structure Analysis,Development of a software component structure to identify rejected functional and non-functional requirements.,Proposed in this paper,,The software component structure is developed and presented in the requirements validation framework. This helps in identifying which functional and non-functional requirements are rejected by the customers.,Unadopted Attributes Identification,A process to identify attributes that are not required in the software.,Proposed in this paper,,"During the requirements validation framework meeting, attributes that are deemed unnecessary or rejected by stakeholders are identified as unadopted attributes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Functional Requirement Attributes Completeness (FRAC),Measures the completeness of functional requirements attributes,"FRAC = FRA / TA
Where FRA = Number of Functional Requirement Attributes
TA = Total number of Attributes (Functional + Non-Functional)",Proposed in this paper,,Non-Functional Requirements Attributes Completeness (NFRAC),Measures the completeness of non-functional requirements attributes,"NFRAC = NFRA / TA
Where NFRA = Number of Non-Functional Requirement Attributes
TA = Total number of Attributes (Functional + Non-Functional)",Proposed in this paper,,Unadopted Attributes Completeness (UAC),Measures the proportion of unadopted attributes,"UAC = UA / TA
Where UA = Number of Unadopted Attributes
TA = Total number of Attributes (Functional + Non-Functional)",Proposed in this paper,,Software Completeness,"Overall measure of software completeness considering functional, non-functional, and unadopted attributes",Software Completeness = FRAC + NFRAC - UAC,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Forward Engineering Completeness (FEC) Approach,A two-step methodology to measure forward engineering completeness for software,Proposed in this paper,,"Step 1: Identify unadopted requirements using the requirements validation framework and develop a software component structure.
Step 2: Calculate software completeness using the formulas for FRAC, NFRAC, UAC, and overall Software Completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Requirements Validation Framework,A framework to validate requirements and identify necessary adjustments before software development,Proposed in this paper,,"Gather business requirements from users
Specify functional and non-functional requirements
Create a software specification table (Table 1)
Hold a framework meeting with various stakeholders
Identify unadopted and adjusted requirements
Update the requirements based on stakeholder feedback",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Case study
Comparative analysis (FEC vs FE)

Metrics or criteria used to assess effectiveness:

Number of errors/defects in various categories (IES, MCC, IDS, ICI, MIS)
Number of Correct Functionalities (CF)
Development time
Maintenance time
Percentage of errors in software requirements

Datasets or case studies employed:

A software development project with 1398-1430 functional and non-functional requirements

Key results and findings:

FEC approach resulted in fewer errors (7% vs 48% in FE)
FEC approach led to more correct functionalities (93% vs 52% in FE)
FEC approach reduced development time and maintenance time
FEC approach improved budget utilization

",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63,Luitel 2024,Improving requirements completeness: automated assistance through large language models,Consensus,Yes,63,Improving requirements completeness: automated assistance through large language models,Canada,2024,Journal,Requirements Engineering,"Natural language (NL) is arguably the most prevalent medium for expressing systems and software requirements. Detecting 
incompleteness in NL requirements is a major challenge. One approach to identify incompleteness is to compare require-
ments with external sources. Given the rise of large language models (LLMs), an interesting question arises: Are LLMs 
useful external sources of knowledge for detecting potential incompleteness in NL requirements? This article explores this 
question by utilizing BERT. Specifically, we employ BERT’s masked language model to generate contextualized predictions 
for filling masked slots in requirements. To simulate incompleteness, we withhold content from the requirements and assess 
BERT’s ability to predict terminology that is present in the withheld content but absent in the disclosed content. BERT can 
produce multiple predictions per mask. Our first contribution is determining the optimal number of predictions per mask, 
striking a balance between effectively identifying omissions in requirements and mitigating noise present in the predictions. 
Our second contribution involves designing a machine learning-based filter to post-process BERT’s predictions and further 
reduce noise. We conduct an empirical evaluation using 40 requirements specifications from the PURE dataset. Our findings 
indicate that: (1) BERT’s predictions effectively highlight terminology that is missing from requirements, (2) BERT outper-
forms simpler baselines in identifying relevant yet missing terminology, and (3) our filter reduces noise in the predictions, 
enhancing BERT’s effectiveness for completeness checking of requirements",,"The RE literature identifies two different notions of completeness [53]: (1) Internal completeness pertains to requirements being closed in terms of the functions and qualities that can be deduced solely from the requirements. (2) External completeness focuses on ensuring that requirements encompass all the information suggested by external sources of knowledge. These sources can include individuals (such as stakeholders) or artifacts like higher-level requirements and existing system descriptions [4].

Source: Referenced from Didar Z, Vincenzo G (2003) On the interplay between consistency, completeness, and correctness in requirements evolution. Inf Softw Technol 45(14):993–1009",Yes,,BERT-based prediction of missing terminology, The approach uses BERT's masked language model to generate contextualized predictions for filling masked slots in requirements. It simulates incompleteness by withholding content and assesses BERT's ability to predict terminology present in the withheld content but absent in the disclosed content.,Proposed in this paper,,"The process involves masking words in requirements, using BERT to predict the masked words, and then comparing these predictions to the withheld content to identify potentially missing terminology.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,"Accuracy
","Ratio of terms in BERT predictions matching some term in the novel terminology of the withheld portion, to the total number of predicted terms.","Accuracy = |{t ∈ D s.t. t matches some t' ∈ N}| / |D|
",Proposed in this paper,,"Coverage
","Ratio of terms in the novel terminology of the withheld portion matching some term in BERT predictions, to the total number of novel terms.",Coverage = |{t ∈ N s.t. t matches some t' ∈ D}| / |N|,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Simulated incompleteness evaluation,"Randomly withhold a portion of requirements specification, use BERT to predict missing terminology based on disclosed portion, compare predictions to withheld portion.", Proposed in this paper,,Calculate Accuracy and Coverage metrics to assess how well BERT predicts missing terminology.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,BERT-based terminology recommendation,"Uses BERT to generate predictions for masked words in requirements, applies filtering to remove non-relevant predictions, and recommends remaining terms as potentially missing terminology.",Proposed in this paper,,"Parse requirements using NLP
Obtain predictions from BERT for masked words
Remove obviously unuseful predictions
Generate domain-specific corpus
Build feature matrix for filtering
Apply ML-based filter to remove noise from predictions
Output list of recommended terms likely relevant but absent from requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated as follows:

Evaluation approaches: Empirical evaluation using 40 requirements specifications from the PURE dataset
Metrics used: Accuracy, Coverage, Classification Accuracy, Precision, Recall
Datasets: Subset of 40 documents from the PURE dataset [Ferrari A, Spagnolo GO, Gnesi S (2017) PURE: a dataset of public requirements documents. In: 25th IEEE international requirements engineering conference (RE'17)]
Key results:

BERT can predict approximately 40% of missing terminology, regardless of the level of incompleteness
Filtering improves accuracy while trading off some coverage
Lenient filtering provides the best trade-off between accuracy and coverage


Limitations:

Simulated incompleteness may not accurately represent real-world scenarios
Limited dataset size and diversity
Lack of user studies with domain experts",Yes,,BERT-based requirements completeness checker,Proposed in this paper,,"Detect, Measure","Python implementation using SpaCy version 3.2.2, Transformers library version 4.16.2 by Hugging Face, WEKA 3-8-5, WikiDoMiner","Parses requirements, generates BERT predictions, filters predictions, recommends potentially missing terminology","Implemented, Validated","Evaluated on 40 requirements documents from PURE dataset, using simulated incompleteness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,BERT (Bidirectional Encoder Representations from Transformers),Detecting/Measuring,Uses BERT's masked language model to generate contextualized predictions for missing words in requirements. These predictions are used to identify potentially missing terminology.,Proposed in this paper,"referencing the original BERT paper: Devlin J, Chang M-W, Lee K, Toutanova K (2019) BERT: pre-training of deep bidirectional transformers for language understanding. In: Annual conference of the North American chapter of the association for computational linguistics: human language technologies (NAACL-HLT'19)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62,Ahmad 2018,A tool-based boilerplate technique to improve SRS quality: An evaluation,Consensus,Yes,62,A Tool-based Boilerplate Technique to Improve SRS Quality: An Evaluation,Malaysia,2018,Journal,"Journal of Telecommunication, Electronic and Computer Engineering","This paper presents an evaluation of a boilerplate technique with the assistance of a tool-based prototype in order to improve Software Requirements Specification (SRS) quality in terms of comprehensibility, correctness and consistency. The value behind this boilerplate is to ease the process of identifying essential requirements for a generic information management system and translating them into standard requirements statements in the SRS. An empirical investigation environment is adapted and expert judgment method is used for evaluation. Results showed that the tool-based boilerplate technique improves the completeness, correctness and consistency of requirements in SRS",No,,Yes,,Tool-based Boilerplate Technique,"A prototype tool developed to aid requirements engineers in eliciting requirements from stakeholders and recording requirements statements appropriately in SRS. It covers Section 3.2 of SRS, which elaborates on functional requirements.",Proposed in this paper,,"The tool guides requirements engineers to write complete software requirements by providing a structure for essential requirements of a generic information management system. It includes basic functionalities like registration, login, searching, adding information, and maintaining information with edit, delete, and update capabilities. By providing this structure, it helps identify potentially missing requirements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Expert Judgment Scoring, Experts score the completeness of the software requirements in the SRS produced using the tool-based boilerplate technique on a 5-point Likert scale.,,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Empirical Investigation with Expert Judgment,"Ten experts with 5-20 years of experience in system development, particularly software requirements, evaluated the SRS produced using the tool-based boilerplate technique.",Proposed in this paper,,Experts used a case study (library system) to write software requirements using the tool-based boilerplate. They then evaluated the completeness of the resulting SRS using a questionnaire with a 5-point Likert scale.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Tool-based Boilerplate Technique,A prototype tool that guides requirements engineers in writing complete software requirements for a generic information management system.,Proposed in this paper,,"Provide a guide to properly write requirements statements
Use predefined templates for essential requirements
Auto-generate wireframe interfaces to improve correctness and completeness
Use uniform sentence structure to improve consistency and completeness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used: Empirical investigation using expert judgment
Metrics or criteria used to assess effectiveness:

Comprehensibility
Correctness
Consistency (which contributes to completeness)
Datasets or case studies employed: A library system case study
Key results and findings:
Mean score for comprehensibility: 3.9 out of 5
Mean score for correctness: 4.0 out of 5
Mean score for consistency: 4.0 out of 5
Most experts at least agreed that the boilerplate technique improves comprehensibility, correctness, and consistency of requirements statements in the SRS, which indirectly improves completeness",Yes,,Tool-based Boilerplate Prototype,Proposed in this paper,,"Detect, Measure, Correct","A prototype developed for producing an SRS for an information management system, covering Section 3.2 of SRS (functional requirements)","Guides requirements engineers in writing complete software requirements
Provides templates for essential requirements to ensure completeness
Auto-generates wireframe interfaces to improve correctness and completeness
Ensures uniform sentence structure for consistency and completeness","Proposed, Implemented, Validated","Validated through expert judgment. Ten experts evaluated the tool using a case study and provided feedback on a 5-point Likert scale for comprehensibility, correctness, and consistency, which indirectly assess completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59,Audacio 2021,"A Method to Evaluating Consistency, Completeness and Correctness in Evolution Requirements",Consensus,Yes,59,"A Method to Evaluating Consistency, Completeness and Correctness in Evolution Requirements",Brazil,2021,Conference ,Not explicitly stated,"Changes in the domain in which a specific software was developed can generate a demand for new requirements known as requirements evolution. However, it is expected that these will be specified in a consistent, complete and correct manner. This work defines a method that makes it possible to assess the consistency, completeness and correctness of requirements defined during the software evolution. The developed method is composed of two phases: (1) analysis of units of information, i.e., the analysis of each requirement and its domain; and (2) analysis of these items through indicators for consistency and completeness. For verification purposes, the method was applied through a case study in a software company and, the results presents positive indicators for the improvement of quality in requirements evolution. The project, object of this study, originally had a high rework load, that is, correction in the codification of the requirements of the case study. Through the application of the method, it was possible to identify that most of the evaluated requirements, which presented inconsistency or completeness problem, were associated with rework efforts.",Yes,"For a requirement to be complete, it must contain at least three characteristics, namely: 1) No information should be left as undeclared, undetermined or unrelated to the domain; 2) The information must not contain objects, entities or indefinite terms, that is, each operation or condition must be constructed using syntax and semantic rules and 3) No information must be absent, that is, all parts or units must be present and each part or unit must be fully developed
",Yes,,"Two-phase method for evaluating consistency, completeness and correctness","The method consists of two main phases:

Analysis of the sentences described in the Service Order
Assessment of consistency, completeness and correctness in the sentences",Proposed in this paper,,"In the first phase, the customer's request is analyzed and broken down into requirements. Each requirement is then broken down into Units of Information (U.I.).
In the second phase, each U.I. is evaluated against a set of questions for consistency and completeness.
For completeness, three questions are asked:
a) All information referring to the requirement must be declared in the domain
b) The information must not contain objects, entities or indefinite terms
c) No information should be missing
If any of these completeness criteria are not met, the requirement is considered incomplete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Completeness assessment through question-based evaluation,The method uses a set of three questions to assess the completeness of each Unit of Information (U.I.) derived from the requirements.,Proposed in this paper,,"Each U.I. is evaluated against three completeness questions:
a) All information referring to the requirement must be declared in the domain
b) The information must not contain objects, entities or indefinite terms
c) No information should be missing
The results are recorded as either meeting the criteria or not (essentially a binary yes/no for each question).
While not explicitly stated, the quantification appears to be based on the number of criteria met. A U.I. is considered complete only if it meets all three criteria.
The overall completeness of requirements can be quantified by the proportion of U.I.s that are deemed complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50,Muhairat 2020,An intelligent recommender system based on association rule analysis for requirement engineering,Consensus,Yes,50,An Intelligent Recommender System Based on Association Rule Analysis for Requirement Engineering,Jordan,2020,Journal,Journal of Universal Computer Science,"Requirement gathering is a vital step in software engineering. Even though many recent researches concentrated on the improvement of the requirement gathering process, many of their works lack completeness especially when the number of users is large. Data Mining techniques have been recently employed in various domains with promising results. In this work, we propose an intelligent recommender system for requirement engineering based on association rule analysis, which is a main category in Data Mining. Such recommender would contribute in enhancing the accuracy of the gathered requirements and provide more comprehensive results. Conducted experiments in this work prove that FP Growth outperformed Apriori in terms of execution and space consumption, while both methods were efficient in term of accuracy.",No,,Yes,,Association Rule Analysis,Uses data mining techniques (specifically Apriori and FP Growth algorithms) to discover associations between requirements provided by different users.,Proposed in this paper,,Analyzes the set of requirements provided by users to find frequent patterns and associations. These associations can then be used to suggest potentially missing requirements for other users who have provided similar requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,, Rule Confidence,Ratio of the support of rule items to the support of rule head,Confidence(Rule) = (Support(A∪B))/(Support(A)),,This is a standard metric in association rule mining,Rule Lift,Ratio of the confidence to the support of rule head,Lift(Rule) = (Confidence(Rule))/(Support(A)),,This is a standard metric in association rule mining,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Intelligent Recommender System,Uses discovered association rules to suggest potentially missing requirements to users,Proposed in this paper,,"Collect requirements from multiple users
Apply association rule mining (Apriori or FP Growth) to discover relationships between requirements
When a new user provides requirements, use the discovered rules to suggest additional related requirements that the user may have overlooked",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Empirical experiments on synthesized datasets

Metrics used:

Rule Extraction Time: Time needed to extract association rules
Rule Confidence: Strength of association between requirements
Rule Lift: Importance of the rule
Recommendation Time: Time needed to suggest new requirements

Datasets:

Medical dataset: 10,000 users, 512 unique requirements
Library dataset: 2,000 users, 190 unique requirements
IT dataset: 4,000 users, 344 unique requirements

Key results:

FP Growth outperformed Apriori in terms of execution time and space consumption
Both methods (Apriori and FP Growth) were efficient in terms of accuracy (measured by rule confidence and lift)
The approach showed good scalability with increasing numbers of users and requirements

Limitations mentioned:

Used synthesized datasets due to limited availability of real-world requirements data
Did not evaluate the quality or relevance of the suggested requirements from a domain expert perspective",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41,Kravari 2021,Sense: A flow-down semantics-based requirements engineering framework,Consensus,Yes,41,SENSE: A Flow-Down Semantics-Based Requirements Engineering Framework,Greece,2021,Journal,Algorithms,"The processes involved in requirements engineering are some of the most, if not the most, important steps in systems development. The need for well-defined requirements remains a critical issue for the development of any system. Describing the structure and behavior of a system could be proven vague, leading to uncertainties, restrictions, or improper functioning of the system that would be hard to fix later. In this context, this article proposes SENSE, a framework based on standardized expressions of natural language with well-defined semantics, called boilerplates, that support a flow-down procedure for requirement management. This framework integrates sets of boilerplates and proposes the most appropriate of them, depending, among other considerations, on the type of requirement and the developing system, while providing validity and completeness verification checks using the minimum consistent set of formalities and languages. SENSE is a consistent and easily understood framework that allows engineers to use formal languages and semantics rather than the traditional natural languages and machine learning techniques, optimizing the requirement development. The main aim of SENSE is to provide a complete process of the production and standardization of the requirements by using semantics, ontologies, and appropriate NLP techniques. Furthermore, SENSE performs the necessary verifications by using SPARQL (SPIN) queries to support requirement management.",No,,Yes,,SPARQL queries," SPARQL queries are used to identify issues regarding requirements, system framework, and relationships.","Proposed in this paper
",,Queries are formulated to check for specific incompleteness issues in the requirements ontology.,SPIN constraints, SPARQL Inference Notation (SPIN) constraints are used to detect constraint violations in the requirements ontology,"Proposed in this paper
",,SPIN constraints are placed at appropriate classes in the ontology and evaluated to indicate violations.,Ontology-based reasoning,Uses ontology and semantic reasoning to detect inconsistencies and omissions in requirements,"Proposed in this paper
",,"Requirements are formalized in an ontology, allowing semantic reasoning to identify incompleteness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Validation statistics,"Statistical analysis of validation checks in three categories: incompleteness, inconsistency, and system model deficiencies.",,Proposed in this paper,, Sub-case percentage analysis,"Percentage breakdown of different types of requirement specification issues detected.
",,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SENSE validation framework,"Uses ontology validation checks in three categories (incompleteness, inconsistency, system model deficiencies) to quantify aspects of completeness",Proposed in this paper,,Runs validation checks and produces statistics on different types of issues detected.,Sub-case analysis,Analyzes percentage breakdown of different requirement specification issues to quantify aspects of completeness,Proposed in this paper,,Categorizes and calculates percentages of different types of issues detected in requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Boilerplate recommendations,"Recommends appropriate standardized requirement expressions (boilerplates) based on requirement type and system context.
",Proposed in this paper,, Uses semantic reasoning to suggest boilerplates that may address incompleteness.,SPIN rules,"Uses SPARQL Inference Notation (SPIN) rules to draw tacit relationships and fill gaps in requirements.
",Proposed in this paper,,Applies inference rules to identify and potentially correct missing relationships in requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper describes two main evaluation approaches:

User experiment:


A postdoc researcher used the SENSE GUI to input requirements for two use cases (ATM and Shopy) over 10 iterations.
Ontology validation checks were performed after each iteration.
Results showed improvement in completeness as the user became more familiar with the system.


Statistical analysis:


SPIN models for the ATM and Shopy use cases were analyzed over 10 iterations (5 for each).
Issues were categorized into 5 types: non-initialization of abstract requirements, non-specification of abstract claims, entities not related to demands, conflicting requirements, and non-coverage of system states.
Percentage analysis of these categories was performed to identify common issues and evaluate the framework's effectiveness.

Key findings:

User performance improved with system familiarity.
The framework's validation functionality supported better quality requirements.
Different types of incompleteness issues were identified and quantified.

Limitations mentioned:

The approach is limited to static structural correctness and completeness, not dynamic/behavioral correctness.
Evaluation was conducted with a limited number of iterations and use cases.",Yes,,"SENSE Framework
",Proposed in this paper,,"Detect, Measure, Correct","Java-based framework using Apache Jena for ontology processing
","Formalizes requirements using boilerplates, provides recommendations, performs completeness validation checks","Proposed, Implemented, Validated",Validated through user experiments and statistical analysis as described in the paper,TopBraid Composer,Referenced ,"no citation provided, commercial tool","Detect, Measure
",RDF Schema and OWL model editor,"Used for ontology development and SPARQL/SPIN implementation
", Implemented,Not validated in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38,Abbadi 2022,Enhancing Requirements Completeness of Automated Driving System in Concept Phase,Consensus,Yes,38,Enhancing Requirements Completeness of Automated Driving System in Concept Phase,Czech Republic,2022,Conference ,International Conference on Modeling and Simulation for Autonomous Systems (MESAS),"During the product lifecycle, a change in the requirements may involve expensive consequences on the system development. Nevertheless, having a decent understanding of the system and documenting the correct requirements from different perspectives help to minimize the changes caused by missing functionalities, therefore, reduce the development cost.
Developing comprehensive understanding of the system in the concept phase promotes the completeness and reduces the requirements' changes. That helps also to create a good model of the system and develop simulation and test cases, which reveal the bugs and the design issues early.
This work focus on thinking strategy to answer the research questions, ""How to analyze the Automated Driving System (ADS) to improve the requirements' completeness"".
ADS is a complex system that works in non-deterministic environment, in addition, it is a safety related system, meaning that, any malfunction during the operation can cause a harm to people or properties.
Three systematic methods were investigated. First, identify the gaps of the stakeholders. It uses product life cycle to identify a list of internal and external stakeholders and then identify their expected needs. The second systematic process utilizes holistic thinking perspectives method to build a broad understanding of ADS and its neighbor systems. This process tries to direct the system definition using external, internal, progressive, quantitative and scientific perspectives. The last method deals with safety requirements identification tools.",Yes,"A set of requirements is complete if and only if all stakeholders approve the set of requirements
Source: Referenced from ""R.S. Carson, et al., ""Requirements completeness,"" in INCOSE International Symposium, p. 14, 2004, https://doi.org/10.1002/j.2334-5837.2004.tb00546.x""
",Yes,,Stakeholder identification based on product lifecycle,"Systematically identify stakeholders at each stage of the product lifecycle (concept, development, production, utilization and support, retirement) to ensure all potential stakeholders are considered.",Proposed in this paper,,"By comprehensively identifying stakeholders across the entire lifecycle, gaps in stakeholder representation can be detected, which may indicate incomplete requirements.",Holistic thinking perspectives method,"Analyzes the system from multiple perspectives: external (big picture, operational), internal (functional, structural), progressive (generic, continuum, temporal), quantitative, and scientific.",Proposed in this paper,"based on ""J.E. Kasser, Holistic thinking: creating innovative solutions to complex problems, 2015.""","By examining the system from diverse perspectives, gaps or inconsistencies in requirements can be identified that may not be apparent from a single viewpoint.","Safety analysis tools (HAZOP, FTA, FMEA, STPA)",Systematic methods to identify potential hazards and safety issues.,Referenced,"BS: IEC61882 HAZOP guide (2001)
Robert Bosch GmbH: FTA fault-tree-analysis (2015)
Ford: FMEA Handbook (2011)
Nancy Leveson, JOHN THOMAS: STPA handbook (2018)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Stakeholder needs elicitation techniques,"Various techniques to capture stakeholder needs, including strategy documents, technical documents, prototypes, interviews, brainstorming sessions, modeling and simulation reports.",Proposed in this paper,,"Identify stakeholders using product lifecycle analysis
Apply elicitation techniques to capture needs
Document needs using textual requirements, models, diagrams, use scenarios, or use cases
Refine and prioritize captured needs",Holistic thinking perspectives method,Systematic approach to analyze the system from multiple perspectives to identify gaps and enhance completeness., Proposed in this paper,"based on ""J.E. Kasser, Holistic thinking: creating innovative solutions to complex problems, 2015.""","Examine the system from each perspective (external, internal, progressive, quantitative, scientific)
Use guiding questions (who, when, where, what, why, how) to explore information
Challenge identified needs to ensure they are solution-independent
Refine and document requirements based on the comprehensive analysis",Safety requirements elicitation process,"Systematic approach to identify and refine safety-related requirements
Source: Proposed in this paper, based on safety standards",Proposed in this paper,based on safety standards,"Identify safety-related functions
Identify corresponding hazards and risks
Evaluate risks based on relevant standard criteria
Generate high-level safety goals
Derive safety concepts to eliminate or mitigate risks
Elicit technical safety requirements from safety concepts
Verify and validate the system
Iterate if hazards exceed safety limits",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,HAZOP (Hazard and Operability Study),Referenced,BS: IEC61882 HAZOP guide (2001),Detect,Not described in detail,Systematic method to identify potential hazards and operational problems,Referenced,Not validated in this paper,FTA (Fault Tree Analysis),Referenced,Robert Bosch GmbH: FTA fault-tree-analysis (2015),Detect,Not described in detail,Top-down approach to identify potential causes of system failures,Referenced,Not validated in this paper,FMEA (Failure Mode and Effects Analysis),Referenced,Ford: FMEA Handbook (2011),Detect,Not described in detail,Systematic method to identify potential failure modes and their impacts,Referenced,Not validated in this paper,"STPA (System-Theoretic Process Analysis)
",Referenced,"Nancy Leveson, JOHN THOMAS: STPA handbook (2018)",Detect,Not described in detail,,Referenced,Not validated in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34,HuffmanHayes 2020,Towards Improved Network Security Requirements and Policy: Domain-Specific Completeness Analysis via Topic Modeling,Consensus,Yes,34,Towards Improved Network Security Requirements and Policy: Domain-Specific Completeness Analysis via Topic Modeling,USA,2020,Conference ,IEEE Seventh International Workshop on Artificial Intelligence for Requirements Engineering (AIRE),"Network security policies contain requirements –
including system and software features as well as expected and
desired actions of human actors. In this paper, we present a
framework for evaluation of textual network security policies as
requirements documents to identify areas for improvement.
Specifically, our framework concentrates on completeness. We use
topic modeling coupled with expert evaluation to learn the
complete list of important topics that should be addressed in a
network security policy. Using these topics as a checklist, we
evaluate (students) a collection of network security policies for
completeness, i.e., the level of presence of these topics in the text.
We developed three methods for topic recognition to identify
missing or poorly addressed topics. We examine network security
policies and report the results of our analysis: preliminary success
of our approach.",Yes,"Informally, we define a network policy document to be complete if the document describes all issues necessary for a wireless network acceptable use policy, and if each issue is discussed to a sufficient level of detail.
Source: Proposed in this paper",Yes,,LDA-based Topic Modeling,"Uses Latent Dirichlet Allocation (LDA) to automatically identify topics in a collection of Acceptable Use Policy (AUP) documents and determine their coverage in individual documents.
",Proposed in this paper,,"Process: LDA analyzes the document collection to identify latent topics. For each document, LDA provides topic loadings (percentage of words attributed to each topic). Lower topic loading values indicate insufficient coverage or absence of a topic, suggesting incompleteness.","Frequency Count Method
",Counts occurrences of top words associated with each topic identified by LDA, Proposed in this paper,,Counts the total combined occurrences of the top 25 words associated with each topic (from LDA output) in a document. The count is normalized by document size and compared to the mean normalized count for the collection. Documents with normalized frequency 25% below the mean are considered to have insufficient coverage of the topic.,"Section Headings Method
",Examines section headings in documents to determine topic coverage.,"Extracts all words found in document headings. If a phrase/sentence containing words from a specific topic is found in a heading, the topic is declared as sufficiently represented.",,"Extracts all words found in document headings. If a phrase/sentence containing words from a specific topic is found in a heading, the topic is declared as sufficiently represented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Topic Loading Values,Percentage of words in a document attributed to each topic by LDA,,Proposed in this paper,,Normalized Word Frequency," Normalized count of topic-related words in a document
","(Count of top 25 topic words in document) / (Total words in document)
",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,LDA-based Quantification,"Uses LDA topic loadings to quantify topic coverage in documents
", Proposed in this paper,,"Higher topic loading values indicate substantial coverage of a topic, while lower values suggest insufficient coverage or absence.",Frequency-based Quantification,Uses normalized word frequency to quantify topic coverage, Proposed in this paper,,Compares normalized frequency of topic-related words to the mean of the collection. Documents with frequency 25% below mean are considered to have insufficient coverage.,Section Heading-based Quantification,Uses presence of topic-related words in section headings to quantify coverage, Proposed in this paper,,"If a phrase/sentence containing words from a specific topic is found in a heading, the topic is considered sufficiently represented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,LDA-based Topic Modeling Tool,"Proposed in this paper
",,"Detect, Measure","Utilizes Latent Dirichlet Allocation (LDA) to analyze a collection of AUP documents and identify latent topics.

","Identifies topics in AUP documents, provides topic loadings for each document, and helps determine topic coverage.","Proposed, Implemented, Validated","Validated through expert evaluation by 25 students on 23 randomly selected policy documents. Accuracy, recall, precision, and F1 measures were used to assess performance.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Latent Dirichlet Allocation (LDA),Detecting/Measuring/Quantifying,"LDA is used to automatically identify topics in a collection of Acceptable Use Policy (AUP) documents. It provides topic loadings for each document, which are used to determine the level of coverage for each topic. This information is then used to assess the completeness of the AUP documents.",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33,Xiang 2023,PolicyChecker: Analyzing the GDPR Completeness of Mobile Apps' Privacy Policies,Consensus,Yes,33,PolicyChecker: Analyzing the GDPR Completeness of Mobile Apps' Privacy Policies,USA,2023,Conference ,ACM SIGSAC Conference on Computer and Communications Security (CCS '23),"The European General Data Protection Regulation (GDPR) man-
dates a data controller (e.g., an app developer) to provide all in-
formation specified in Articles (Arts.) 13 and 14 to data subjects
(e.g., app users) regarding how their data are being processed and
what are their rights. While some studies have started to detect the
fulfillment of GDPR requirements in a privacy policy, their explo-
ration only focused on a subset of mandatory GDPR requirements.
In this paper, our goal is to explore the state of GDPR-completeness
violations in mobile apps’ privacy policies. To achieve our goal, we
design the PolicyChecker framework by taking a rule and semantic
role based approach. PolicyChecker automatically detects complete-
ness violations in privacy policies based not only on all mandatory
GDPR requirements but also on all if-applicable GDPR require-
ments that will become mandatory under specific conditions. Using
PolicyChecker, we conduct the first large-scale GDPR-completeness
violation study on 205,973 privacy policies of Android apps in the
UK Google Play store. PolicyChecker identified 163,068 (79.2%)
privacy policies containing data collection statements; therefore,
such policies are regulated by GDPR requirements. However, the
majority (99.3%) of them failed to achieve the GDPR-completeness
with at least one unsatisfied requirement; 98.1% of them had at least
one unsatisfied mandatory requirement, while 73.0% of them had
at least one unsatisfied if-applicable requirement logic chain. We
conjecture that controllers’ lack of understanding of some GDPR re-
quirements and their poor practices in composing a privacy policy
can be the potential major causes behind the GDPR-completeness
violations. We further discuss recommendations for app develop-
ers to improve the completeness of their apps’ privacy policies to
provide a more transparent personal data processing environment
to users",Yes,"GDPR-complete, i.e., all information pertinent to the mandatory and if-applicable requirements specified in Arts. 13 and 14 must be presented in a privacy policy.
Source: Proposed in this paper",Yes,,PolicyChecker framework, A rule and semantic role based approach that automatically detects completeness violations in privacy policies based on both mandatory and if-applicable GDPR requirements., Proposed in this paper,,"olicyChecker processes each sentence from a privacy policy using an NLP pipeline comprising five main steps:

Practice Identification: Determines the practice described in a sentence by matching verbs against predefined mappings.
Predicate-Argument Construction: Constructs the predicate-argument structure of the sentence using semantic role labeling.
Rule-Based Semantic Role Matching: Matches semantic roles against predefined roles for the practice.
Rule-Based Semantic Argument Validation: Validates the meaning of each semantic argument using named entity recognition and textual similarity comparison.
Rule-Based Completeness Analysis: Generates an analysis report based on fulfilled requirements, legal bases, and predefined logic chains.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Number of completeness violations,The total number of unsatisfied mandatory requirements and unsatisfied if-applicable requirement logic chains in a privacy policy.,, Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,PolicyChecker's GDPR-Completeness Checking Algorithm,An algorithm that detects unsatisfied mandatory requirements and unsatisfied if-applicable requirements based on identified requirement logic chains.,Proposed in this paper,,The algorithm calculates the set difference between mandatory requirements and satisfied requirements to detect unsatisfied mandatory requirements. It then applies requirement logic chains to detect unsatisfied if-applicable requirements. The process generates a completeness analysis report containing information on violations.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Recommendations for app developers,A set of recommendations provided to app developers to improve the completeness of their apps' privacy policies.,Proposed in this paper,,"The recommendations include:

Reviewing internal compliance processes and establishing channels for users to exercise their rights.
Disclosing established channels to users through privacy policy updates.
Identifying appropriate legal bases for justifying personal data processing.
Reviewing privacy policies of third-party services before integration.
Paying attention to additional requirements that may apply when including certain information in privacy policies.
Exercising caution when using automatic policy generation tools.
Performing due diligence to make app-specific modifications to ensure accuracy in reflecting data processing practices and legal stances.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches used:

Manual annotation of 300 privacy policies to create a ground-truth dataset
Comparison of PolicyChecker's results against the ground-truth dataset

Metrics used to assess effectiveness:

Accuracy
Precision
Recall
F1-score

Key results and findings:

PolicyChecker achieved 88.5% accuracy, 78.2% precision, 83.0% recall, and 80.0% F1-score on average over the 300 ground-truth policies.
The recall ratio on 200 randomly-sampled ground-truth policies was 81.0%.

Limitations mentioned:

Reliance on an SRL model trained on a generic English semantic dataset
Limited extraction of contextual information among sentences
Focus only on English-language privacy policies
Limited to privacy policies from the UK Google Play store",Yes,,PolicyChecker,Proposed in this paper,,"Detect, Measure","A framework implemented using Natural Language Processing techniques, including Semantic Role Labeling, Named Entity Recognition, and textual similarity comparison.",Automatically detects completeness violations in privacy policies based on GDPR requirements (both mandatory and if-applicable).,"Proposed, Implemented, Validated","Validated using a dataset of 300 manually annotated privacy policies. Achieved 88.5% accuracy, 78.2% precision, 83.0% recall, and 80.0% F1-score on average.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,AllenNLP Semantic Role Labeling model, Detecting/Measuring,Used for constructing the predicate-argument structure of sentences in privacy policies. The model is trained on the Ontonotes 5.0 dataset for the English PropBank SRL task.,Referenced,"Gardner, Matt, et al. ""AllenNLP: A Deep Semantic Natural Language Processing Platform."" Proceedings of Workshop for NLP Open Source Software (NLP-OSS).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
30,Al-Kasabera 2020,An automated approach to validate requirements specification,Consensus,Yes,30,An Automated Approach to Validate Requirements Specification,Jordan,2020,Journal,"COMPUSOFT, An International Journal of Advanced Computer Technology","Requirements engineering processes aim to acquire functions, services and constraints. These processes are important to satisfy the customer by applying correctness, completeness through consistency according to the control instructions to achieve product quality. Both functions and services face changeability issue that is hard to regulate, depending on the precise request of the customer. This research addresses the achievement of correctness, completeness, and consistency by applying an automated approach. The evaluation is established using a standard use case diagram from the UML official website. The proposed approach detects the incorrect requirement specifications to enhance Software quality. The proposed approach includes three levels; the first level is the Structured Document, the second level is the Dynamic Language, which describes the transforming of use case diagram as dynamic, and the third level is the completeness checking procedures, which is based on the implemented standard rules. The approach is supported by a programmed tool on MS excel and XML due to IBM Rational Rose and Visual Paradigm and experimented ""Online Shopping"" use case diagram as a case study.",Yes,"Software Requirements Specification (SRS) is complete [13] if it includes the following elements: First, all the requirements related to functionality attributes in SRS should be treated. Second, the definition of the responses of the software to all realizable classes of input data, in all realizable classes of situations, note that it is important to specify the responses to both valid and invalid input values. Third, all the diagrams, labels, figures, term definitions and measures should be referenced and labelled.
Source: A. Al-Hroob, A. T. Imam, and R. Al-Heisa, ""The use of artificial neural networks for extracting actions and actors from requirements document,"" Information and Software Technology, vol. 101, pp. 1-15, 2018.",Yes,,Three-level automated approach,An automated approach consisting of three levels to validate requirements specification and detect incompleteness.,Proposed in this paper,,"Level 1 (Structured Document): Uses a UML use case diagram to represent requirements specification.
Level 2 (Dynamic Language): Transforms the use case diagram into XML format, extracting elements like actors, use cases and relationships.
Level 3 (Completeness): Applies standard UML rules to check correctness and completeness of the extracted elements against formal descriptions. If elements do not match rules, incompleteness is detected.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Unnamed programmed tool,Proposed in this paper,,Detect,"Developed using Microsoft Excel and XML, used in conjunction with IBM Rational Rose and Visual Paradigm software"," Transforms use case diagrams into XML format, extracts elements, and applies UML rules to check correctness and completeness","Implemented, Validated","Validated through case study on ""Online Shopping"" use case diagram",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29,Stephen 2020,Evaluation of software requirement specification based on IEEE 830 quality properties,Consensus,Yes,29,Evaluation of Software Requirement Specification Based on IEEE 830 Quality Properties,Malaysia,2020,Journal," International Journal on Advanced Science, Engineering and Information Technology",,No,,Yes,,IEEE 830 Topic Similarity Detection,The prototype extracts text from the provided SRS document and performs pattern-matching against topics from the IEEE 830 standard table of contents. It also uses a corpus of synonym topics to identify possible matches.,Proposed in this paper,,"The prototype scans the SRS document, extracts text, and compares it against a list of 23 topics from the IEEE 830 table of contents. It also checks for synonym topics that may be similar to the standard topics. The number of matched topics is used to calculate a completeness percentage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Topic Similarity Percentage, The percentage of topics in the SRS that match or are similar to the topics in the IEEE 830 standard table of contents.,(Number of matched topics / Total number of topics in IEEE 830) * 100,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Automated Topic Matching and Scoring,"A prototype system that automatically extracts text from the SRS, performs pattern matching against IEEE 830 topics and synonyms, and calculates a completeness score.",Proposed in this paper,,"The system extracts text from the SRS, cleanses it, performs pattern matching against IEEE 830 topics and a corpus of synonyms, calculates the number of matched topics, and generates a completeness percentage based on the number of matches out of the total 23 IEEE 830 topics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,, Topic Amendment Suggestion,The prototype suggests possible amendments to the SRS structure based on detected synonym topics and missing IEEE 830 topics.,Proposed in this paper,,"The system identifies topics in the SRS that are synonyms of IEEE 830 topics but not exact matches.
It suggests to the developer which topics could be amended to match the IEEE 830 standard.
The developer can choose to update the SRS based on these suggestions to improve completeness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Evaluation approaches:

Case study using an SRS from the accounting domain

Metrics used:

Percentage of completeness for structural elements
Percentages for correctness, consistency, and preciseness of functional requirements

Datasets:

One SRS document from the accounting domain

Key results and findings:

Overall completeness of the SRS structure: 26.1%
Correctness of functional requirements: 43.8%
Consistency of functional requirements: 72.5%
Preciseness of functional requirements: 37.3%
Overall quality score: 45%

Limitations mentioned:

The evaluation was done on a single SRS document
The prototype's effectiveness depends on the quality and comprehensiveness of its knowledge base, which needs regular updates",Yes,,SRS Quality Evaluation Prototype,Proposed in this paper,,"Detect, Measure, Correct",Web-based system with a database for storing knowledge bases and SRS documents,"Extracts text from SRS documents
Performs pattern matching against IEEE 830 topics and synonyms
Identifies stakeholders and functional requirements
Detects vague words and possible data types
Evaluates test cases for functional requirements
Calculates quality scores for completeness, correctness, consistency, and preciseness","Implemented, Validated",alidated through a case study on an accounting domain SRS. The tool successfully measured various quality aspects of the SRS and provided quantitative results.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27,UmarOng 2023,A Meta-Requirement Approach to Validate User Requirement Specification: Threshold Definition,Consensus,Yes,27,A Meta-Requirement Approach to Validate User Requirement Specification: Threshold Definition,Malaysia,2023,Conference ,2023 IEEE 8th International Conference On Software Engineering and Computer Systems (ICSECS),"The software requirement specification document is critical for ensuring that software development projects are completed on time, within budget, and meet the needs of all stakeholders. User requirement completeness refers to the extent to which user requirements accurately and fully capture the needs and expectations of stakeholders for a given system or application. The completeness of user requirements is critical for the successful design and implementation of information systems, as incomplete requirements can lead to a range of issues, including system failure, delays, and cost overruns. The author has developed a meta-requirement validation approach to validate the completeness of a set of requirements. Based on a numerical reading, the user of the approach will be able to determine the completeness of the requirement. This publication's main objective is to identify the threshold value through a method of literature search. The identified threshold value will be used to determine the minimum reading for the result to be deemed complete. The result of a 70% value has been identified to be suitable for the use of the validation approach.",Yes,"User requirement completeness refers to the extent to which user requirements accurately and fully capture the needs and expectations of stakeholders for a given system or application.
Source: Proposed in this paper",Yes,,Meta-requirement Validation Approach,This approach uses meta-requirements (MR) as a high-level abstract artifact to guide the validation of requirements completeness. It involves mapping User Requirements (UR) to Meta-Requirements (MR) and analyzing the traceability between them.,Proposed in this paper,,"The approach compares the percentage of mapped URs to the MR graph pattern and conducts a similarity pattern analysis. If the similarity reaches a defined threshold (70% in this case), the requirements are considered complete. If it falls below this threshold, it indicates incompleteness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,STATE,STATE is a proposed unit of measurement used to quantify the completeness of requirements. It represents the percentage of User Requirements (URs) that successfully map to the Meta-Requirements (MR) graph pattern.,,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Meta-requirement Based Validation Model,This model uses the STATE metric to quantify completeness. It involves mapping URs to MRs and calculating the percentage of successful mappings.,Proposed in this paper,,"Defining Meta-Requirements (MR)
Mapping User Requirements (UR) to MR
Calculating the percentage of URs that successfully map to the MR graph pattern (STATE)
Comparing the STATE value to a predefined threshold (70%)
If STATE ≥ 70%, the requirements are considered complete; if STATE < 70%, they are considered incomplete",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16,Torre 2020,An AI-Assisted Approach for Checking the Completeness of Privacy Policies against GDPR,Consensus,Yes,16,An AI-assisted Approach for Checking the Completeness of Privacy Policies Against GDPR,"Luxembourg, Canada",2020,Conference ,2020 IEEE 28th International Requirements Engineering Conference (RE),"Privacy policies are critical for helping individuals make informed decisions about their personal data. In Europe, privacy policies are subject to compliance with the General Data Protection Regulation (GDPR). If done entirely manually, checking whether a given privacy policy complies with GDPR is both time-consuming and error-prone. Automated support for this task is thus advantageous. At the moment, there is an evident lack of such support on the market. In this paper, we tackle an important dimension of GDPR compliance checking for privacy policies. Specifically, we provide automated support for checking whether the content of a given privacy policy is complete according to the provisions stipulated by GDPR. To do so, we present: (1) a conceptual model to characterize the information content envisaged by GDPR for privacy policies, (2) an AI-assisted approach for classifying the information content in GDPR privacy policies and subsequently checking how well the classified content meets the completeness criteria of interest; and (3) an evaluation of our approach through a case study over 24 unseen privacy policies. For classification, we leverage a combination of Natural Language Processing and supervised Machine Learning. Our experimental material is comprised of 234 real privacy policies from the fund industry. Our empirical results indicate that our approach detected 45 of the total of 47 incompleteness issues in the 24 privacy policies it was applied to. Over these policies, the approach had eight false positives. The approach thus has a precision of 85% and recall of 96% over our case study.",Yes,"We use the term ""complete"" rather than ""compliant"" to signify the fact that our current approach can only detect the presence (or absence) of the information content types that GDPR envisages for privacy policies; we do not yet perform a deep semantic analysis of the detected content for verifying compliance.
Source: Proposed in this paper
",Yes,,AI-assisted metadata identification and completeness checking approach,The approach uses NLP and ML techniques to automatically classify the content of privacy policies according to a conceptual model of metadata types derived from GDPR. It then checks the classified content against predefined completeness criteria to detect incompleteness issues.,Proposed in this paper,,"Pre-process the privacy policy text
Apply text generalization
Transform sentences into word embeddings
Use ML classifiers to predict level-1 and level-2 metadata types
Use similarity-based classification for level-2 metadata types
Use keyword-based classification for level-2 and level-3 metadata types
Combine the classification results to predict final metadata types
Apply post-processing to refine results
Check the identified metadata against completeness criteria to detect incompleteness issues",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Precision,The ratio of correctly identified incompleteness issues to the total number of identified issues,TP / (TP + FP),Proposed in this paper,,Recall,The ratio of correctly identified incompleteness issues to the total number of actual issues,TP / (TP + FN),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Completeness criteria checking,A set of criteria derived from GDPR are applied to the identified metadata to check for completeness. Violations of these criteria indicate incompleteness issues.,Proposed in this paper,,"Identify metadata in privacy policy using AI-assisted approach
Apply completeness criteria to the identified metadata
Count the number of criteria violations (incompleteness issues)
Calculate precision and recall based on true positives, false positives, and false negatives",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,AI-assisted metadata identification and completeness checking tool,Proposed in this paper,,"Detect, Measure","The tool implements the proposed approach using NLP and ML techniques. It uses the DKPro toolkit for NLP, GloVe for word embeddings, and WEKA for ML classification.","The tool processes privacy policy text, identifies metadata types, and checks for completeness against predefined criteria.","Proposed, Implemented, Validated",The tool was validated through a case study on 24 unseen privacy policies. It achieved a precision of 85% and recall of 96% in detecting incompleteness issues.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,The tool was validated through a case study on 24 unseen privacy policies. It achieved a precision of 85% and recall of 96% in detecting incompleteness issues.,Detecting/Measuring, SVM classifiers are used to predict level-1 and level-2 metadata types in privacy policy sentences. The classifiers are trained on sentence embeddings derived from pre-trained GloVe word vectors.,Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15,Huayllani 2020,A granular conceptual model to define requirements for evaluating the functional completeness of a pharmacy information system,Consensus,Yes,15,A Granular Conceptual Model to Define Requirements for Evaluating the Functional Completeness of a Pharmacy Information System,Peru,2020,Conference ,WSSE 2020: 2020 3rd World Symposium on Software Engineering,"Due to the fact that the existing quality models fail to define the methodologies, tools and techniques used to meet the software product standards, a concern arises to provide and integrate empirically validated models in the software industry. Functional completeness is a quality attribute that is part of the ISO / IEC 25010 standard and represents the degree to which the set of functionalities delivered covers all the tasks and objectives requested by the user. For this reason, a conceptual model is presented to define functional requirements that provide a framework to clarify the sequence of events that are part of a requirement. The model is composed of the tasks: input data capture within the system limit, input data capture outside the system limit, restrictions according to the business model, information processing, and information output. Likewise, the model has obtained preliminary results to be applied in the development of Pharmacy software for a state entity. The results show that the definition of requirements using the proposed model generates a closer description of the sequence of interaction events between the system and its environment applied to the description of a functional requirement.",Yes,"Functional completeness is a quality attribute that is part of the ISO / IEC 25010 standard and represents the degree to which the set of functionalities delivered covers all the tasks and objectives requested by the user.
Source: Referenced from ISO 25010 standard. Full citation not provided in the paper.

According to the definition of ISO 25010, functional completeness is the 'Degree to which the set of functions covers all the specified tasks and user objectives.
Source: ISO/IEC, ""ISO/IEC 25010:2011.Systems and software engineering — Systems and software Quality Requirements and Evaluation (SQuaRE) — System and software quality models,"" ISO/IEC, 2011.",Yes,,Input Data Capture within the System Limits,"Identifies data inputs required for the execution of the requirement that come from within the same system.
", Proposed in this paper,,"By listing all required data inputs from within the system, it helps identify missing internal data dependencies.",Input Data Capture Outside the System Limits,"Identifies data inputs required from external sources, typically consumed through web services or sockets.
", Proposed in this paper,,"By listing all required external data inputs, it helps identify missing external data dependencies.",Restrictions According to the Business Model,"Identifies business rules, policies, standards, and restrictions in the execution of the process.
", Proposed in this paper,,"By listing all business rules and restrictions, it helps identify missing constraints that the requirement should adhere to.",Processing Information," Identifies tasks that carry out transformation of information according to business rules, including calculations or operations.
", Proposed in this paper,,"By listing all data processing tasks, it helps identify missing processing steps in the requirement.","Information Output
","Specifies the expected result after completing the sequence of interaction events.
", Proposed in this paper,,"By clearly defining the expected output, it helps identify if the requirement is missing any essential results or outcomes.",,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Conceptual Model for the Definition of Requirements,A framework that guides the definition of requirements by breaking them down into five key areas to ensure comprehensive coverage of all aspects of a requirement.,Proposed in this paper,,"Identify and list all input data capture within the system limits
Identify and list all input data capture outside the system limits
Specify all restrictions according to the business model
Detail all information processing steps
Define the expected information output",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper evaluates this method through a comparative study:

Evaluation approach: Comparison between requirements defined using the proposed model and those defined using brainstorming
Metrics: User perception scores (0-10) on how well the defined requirements reflected the normal flow of the process
Dataset: Two functional requirements for a Pharmacy Information System
Key results: Requirements defined using the proposed model consistently scored higher in perceived completeness compared to those defined using brainstorming
Limitations: Small sample size (only two functional requirements evaluated), subjective evaluation based on user perception",No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14,Ong 2019,Meta-requirement method towards analyzing completeness of requirements specification,Consensus,Yes,14,Meta-requirement Method Towards Analyzing Completeness of Requirements Specification,Malaysia,2019,Conference ,Future Technologies Conference (FTC) 2018,"In software development project, requirements validation plays an important role to ensure all requirements are captured as required. With the correct sets of requirements, producing a highly desired system is possible. However, due to time constraint, requirements validation steps are commonly ignored by developer. The objectives of this research are to identify the major factors in validating user requirements, development of a reverse engineered meta-requirement algorithm and validating with expert panel in requirements engineering of the algorithm usefulness. Expected result will be that the solution should be able to reverse engineer the meta-requirements of a set of user requirements. By building a repository of meta-requirement, this will enable comparison of meta-requirements of two different system within the same domain and producing a meta-requirement gap analysis. With this, requirement validation steps can be done within a small amount of time. The contribution of this research should be beneficial to industry and researchers.",No,,Yes,,Meta-requirement method,The method involves reverse engineering user requirements to their originated requirements (meta-requirements). This allows for comparison of meta-requirements between different systems within the same domain to produce a meta-requirement gap analysis.,Proposed in this paper,,The method aims to identify missing requirements by comparing the meta-requirements of a given set of requirements to a repository of meta-requirements for systems in the same domain. Gaps in the meta-requirements would indicate potential incompleteness in the original requirements.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Meta-requirement repository and gap analysis,The proposed approach involves building a repository of meta-requirements and using it to perform a gap analysis between different systems in the same domain.,Proposed in this paper,,"Reverse engineer user requirements to meta-requirements
Build a repository of meta-requirements
Compare meta-requirements of two different systems within the same domain
Produce a meta-requirement gap analysis
Use the gap analysis to identify potential missing requirements",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13,Azeem 2024,A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs,Consensus,Yes,13,A Multi-solution Study on GDPR AI-enabled Completeness Checking of DPAs,Luxembourg,2024,Journal,Empirical Software Engineering,"Specifying legal requirements for software systems to ensure their compliance with the
applicable regulations is a major concern of requirements engineering. Personal data which
is collected by an organization is often shared with other organizations to perform certain
processing activities. In such cases, the General Data Protection Regulation (GDPR) requires
issuing a data processing agreement (DPA) which regulates the processing and further ensures
that personal data remains protected. Violating GDPR can lead to huge fines reaching to bil-
lions of Euros. Software systems involving personal data processing must adhere to the legal
obligations stipulated both at a general level in GDPR as well as the obligations outlined
in DPAs highlighting specific business. In other words, a DPA is yet another source from
which requirements engineers can elicit legal requirements. However, the DPA must be com-
plete according to GDPR to ensure that the elicited requirements cover the complete set of
obligations. Therefore, checking the completeness of DPAs is a prerequisite step towards
developing a compliant system. Analyzing DPAs with respect to GDPR entirely manually is
time consuming and requires adequate legal expertise. In this paper, we propose an automa-
tion strategy that addresses the completeness checking of DPAs against GDPR provisions
as a text classification problem. Specifically, we pursue ten alternative solutions which are
enabled by different technologies, namely traditional machine learning, deep learning, lan-
guage modeling, and few-shot learning. The goal of our work is to empirically examine how
these different technologies fare in the legal domain. We computed F2 score on a set of 30
real DPAs. Our evaluation shows that best-performing solutions yield F2 score of 86.7% and
89.7% are based on pre-trained BERT and RoBERTa language models. Our analysis further
shows that other alternative solutions based on deep learning (e.g., BiLSTM) and few-shot
learning (e.g., SetFit) can achieve comparable accuracy, yet are more efficient to develop",No,,Yes,,Binary Classification,"For each GDPR provision, a binary classifier is trained to predict whether a given text span satisfies that provision or not.",Proposed in this paper,,"Each sentence in a DPA is classified by all binary classifiers. If no classifier predicts a sentence satisfies a particular provision, that provision is considered missing from the DPA.","Multi-class Classification
",A single classifier is trained to predict which GDPR provision (if any) a given text span satisfies,Proposed in this paper,,"Each sentence in a DPA is classified. If no sentence is predicted to satisfy a particular provision, that provision is considered missing from the DPA.", LLM-based Solutions,"Large language models like BERT, RoBERTa, ALBERT, and Legal-BERT are fine-tuned on labeled DPA data to perform the classification task.",Proposed in this paper,,The fine-tuned LLM classifies each sentence in a DPA. Missing provisions are identified based on the classification results.,ML-based Solutions,"Traditional machine learning algorithms like Logistic Regression, Random Forest, SVM, and neural networks like MLP and BiLSTM are trained on sentence embeddings from DPAs.",Proposed in this paper,,The trained ML model classifies each sentence in a DPA. Missing provisions are identified based on the classification results.,Few-shot Learning Solution,The SetFit framework is used to perform few-shot learning for the classification task using a small labeled dataset.,Proposed in this paper,,The few-shot model classifies each sentence in a DPA after being trained on a small set of examples. Missing provisions are identified based on the classification results.,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Accuracy (A),The proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.,"A = (TP + TN) / (TP + TN + FP + FN)
",Proposed in this paper,,Precision (P),The proportion of true positive predictions among all positive predictions., P = TP / (TP + FP),Proposed in this paper,,Recall (R),The proportion of true positive predictions among all actual positive cases.,R = TP / (TP + FN),Proposed in this paper,,F2 Score,"A weighted harmonic mean of precision and recall, giving more weight to recall.",F2 = ((2^2 + 1) * P * R) / (2^2 * P + R),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Binary Classification Evaluation,Evaluate the performance of binary classifiers for each GDPR provision using the above metrics.,Proposed in this paper,,"Calculate accuracy, precision, recall, and F2 score for each binary classifier and average across all provisions.","Multi-class Classification Evaluation
","Evaluate the performance of the multi-class classifier using the above metrics.
",Proposed in this paper,,"Calculate accuracy, precision, recall, and F2 score for the multi-class classifier.","Cross-validation
",Use cross-validation to ensure robust evaluation of the models.,Proposed in this paper,,Perform k-fold cross-validation and report average metric scores.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,BERT (Bidirectional Encoder Representations from Transformers),Detecting/Measuring/Quantifying completeness of DPAs,Pre-trained language model fine-tuned for binary and multi-class classification of DPA sentences,Proposed in this paper,,RoBERTa (Robustly Optimized BERT Pretraining Approach),Detecting/Measuring/Quantifying,"Variant of BERT with improved pre-training, fine-tuned for binary and multi-class classification of DPA sentences",Proposed in this paper,,ALBERT (A Lite BERT),Detecting/Measuring/Quantifying,"Lightweight variant of BERT, fine-tuned for binary and multi-class classification of DPA sentences",Proposed in this paper,,Legal-BERT,Detecting/Measuring/Quantifying,"BERT model pre-trained on legal texts, fine-tuned for binary and multi-class classification of DPA sentences
",Proposed in this paper,,SetFit,Detecting/Measuring/Quantifying ,"Few-shot learning framework using sentence transformers, applied to binary and multi-class classification of DPA sentences with limited training data",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,
10,Jiménez 2023,USQA: A User Story Quality Analyzer prototype for supporting software engineering students,Consensus,Yes,10,USQA: A User Story Quality Analyzer prototype for supporting software engineering students,México,2023,Journal,Computer Applications in Engineering Education,"The Standish Group Reports 83.9% of IT Projects fail, and one of the top factors in failed projects is the incomplete requirements or user stories. Therefore, it is essential to teach undergraduate students from computer science degree programs how to create complete user stories. Computer science programs include some subjects or topics involving requirements or user stories collection and writing, such as Requirements Engineering, Software Engineering, Project Management, or Quality Software Assurance. For that reason, we designed a web application called User Story Quality Analyzer (USQA) that uses Natural Language Processing modules to detect errors regarding aspects of usefulness, completeness, and polysemes in the user stories creation. The tool was proved from three perspectives: (1) a reliability test, where 35 user stories developed by experts were tested in the app to prove the prototype's reliability; (2) usability and utility analysis; 48 students interacted with the tool and responded a Satisfaction Usability Scale and an open‐ended question, the students reported a high usability score; (3) finally, error classification, we gathered 159 user stories processed by the system, and we classified the students' common errors considering incompleteness and polysemes. After the evaluations, we concluded that USQA could evaluate the user stories as an expert, which could help the professors/teachers/instructors in their courses by providing feedback to the students when they are writing user stories.",Yes,"Implementing a set of user stories creates a feature‐complete application, no steps are missing
Source: Referenced from G. Lucassen, F. Dalpiaz, J. M. E. M. van der Werf, and S. Brinkkemper, ""Forging high‐quality user stories: towards a discipline for agile requirements,"" 2015 IEEE 23rd Int. Requir. Eng. Conf. (RE), 2015, pp. 126–135. https://doi.org/10.1109/RE.2015.7320415",Yes,, Pattern-based completeness check,"The system uses 15 pattern rules to check whether a user story has the correct structure, including the User, Something, and Benefit components.",Proposed in this paper,,"The system analyzes the part of speech (POS) of each token in the user story and checks if it matches predefined patterns for each component (User, Something, Benefit). If all three components are present, the user story is considered complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,USCompleteness,A binary measure of completeness based on the presence of all three required components in a user story.,"USCompleteness = (USp1, USp2, USp3), where USp1 represents the User component, USp2 represents the Something component, and USp3 represents the Benefit component.",Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Component-based completeness analysis,"The system analyzes each user story to identify the presence of the three required components (User, Something, Benefit) using predefined patterns.",Proposed in this paper,,"The system checks for the presence of each component using pattern matching. If all three components are present, the user story is considered complete (USCompleteness = 1); otherwise, it is considered incomplete (USCompleteness = 0).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,USQA feedback system,"The USQA tool provides feedback to users about the completeness of their user stories, allowing them to correct and improve their writing.",Proposed in this paper,,"User inputs a user story into the USQA web interface
System analyzes the user story for completeness, usefulness, and polysemes
System provides feedback to the user about any detected issues
User can revise and resubmit the user story based on the feedback",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through three experiments:

Reliability test:


Approach: Comparison of USQA results with expert evaluation
Metrics: Percentage of accuracy for completeness, polysemes, correct length, and spelling errors
Dataset: 35 user stories written by 5 experienced developers
Key results: High accuracy for completeness (91.42%), correct length (91.42%), and spelling errors (80%). Lower accuracy for polysemes (45.71%).


Usability and utility evaluation:


Approach: System Usability Scale (SUS) survey and open-ended questions
Metrics: SUS score, qualitative feedback
Dataset: 48 undergraduate students
Key results: SUS score of 74.36 (considered ""good usability""), 95.7% of students found the application useful


Common errors analysis:


Approach: Classification of errors in student-written user stories
Metrics: Percentage of incomplete user stories, spelling mistakes, incorrect length, and polysemes
Dataset: 159 user stories written by students
Key results: 40.88% incomplete user stories, 3% spelling mistakes, 30.81% incorrect length, 61% polysemes",Yes,,User Story Quality Analyzer (USQA),Proposed in this paper,,"Detect, Measure","Web-based application using Python, Flask, and Natural Language Processing libraries (Spacy, NLTK, Hunspell, Matcher)","Analyzes user stories for completeness, usefulness (length), and polysemes
Provides feedback to users on the quality of their user stories
Detects spelling errors","Implemented, Validated","Validated through three experiments: reliability test with expert-written user stories, usability evaluation with students, and error classification analysis. Results showed high accuracy for completeness detection and good usability scores.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
3,Ko 2019,Automatic recommendation to omitted steps in use case specification,Consensus,Yes,3,Automatic recommendation to omitted steps in use case specification,Republic of Korea,2019,Journal,Requirements Engineering,"Completeness is one of the key attributes for a high-quality software requirements specification. Although incomplete requirements frequently occur in the requirements specification, it is rarely discovered. This turns out to be one of the major causes of software project failure. In order to handle this issue, this paper proposes an automatic approach to recommending omitted steps in a use case-based requirements specification. First, we automatically extract diverse scenario patterns by using the verb clustering algorithm and scenario flow graphs. Based on the scenario patterns, our approach detects omitted steps of user's scenarios by the pattern matching algorithm and automatically recommends appropriate steps for the omitted parts. For validation of our approach, we have developed tool support, named ScenarioAmigo, and collected 231 use case specifications composing of 1874 scenario steps from 12 academic or proprietary projects. We first carried out the preliminary study to decide appropriate thresholds and weights. Then, we conducted three experiments as a quantitative performance evaluation. First, the cross-validation for the collected scenarios shows the 76% precision and 80% recall. Second, the comparison of recall of ScenarioAmigo to that of human experts obtained the 20% higher score. As the last experiment, we compared the result of ScenarioAmigo and human experts in terms of severity of each scenario and found that our approach could recommend normal as well as important scenarios, compared to the human experts",No,,Yes,,Scenario Pattern Matching,The approach uses automatically extracted scenario patterns and a pattern matching algorithm to detect omitted steps in user scenarios.,Proposed in this paper,,"Extract main verbs from scenario steps
Generate verb clusters
Build scenario flow graphs
Identify scenario patterns
Convert evaluation scenarios to scenario flow graphs
Generate candidate scenario patterns
Select best scenario patterns for the evaluation scenario
Detect omitted steps by comparing the evaluation scenario to the best matching scenario patterns",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Precision,The ratio of correctly recommended steps to the total number of recommended steps,Precision = Number of True Alarms / Number of Recommended Steps,Proposed in this paper,,"Recall
",The ratio of correctly recommended steps to the total number of omitted steps,Recall = Number of True Alarms / Number of Omitted Steps,Proposed in this paper,,F1-Score,The harmonic mean of precision and recall,F1-Score = 2 * (Precision * Recall) / (Precision + Recall),Proposed in this paper,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ScenarioAmigo,An automated tool that implements the proposed approach for detecting and recommending omitted steps in use case scenarios,Proposed in this paper,,"Extract scenario patterns from training scenarios
Analyze evaluation scenarios using the extracted patterns
Detect omitted steps and recommend appropriate steps
Calculate precision, recall, and F1-score based on the recommendations",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,,Automatic Recommendation of Omitted Steps,The approach recommends appropriate steps for the omitted parts of use case scenarios based on extracted scenario patterns.,Proposed in this paper,,"Detect omitted steps using the scenario pattern matching algorithm
Identify the best-fit scenario patterns for the given scenario
Recommend steps from the matched patterns to fill in the omitted parts",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The methods were evaluated through three experiments:

Cross-validation:

Approach: 12-fold cross-validation on 231 use case specifications with 1874 scenario steps
Metrics: Precision, Recall, F1-Score
Results: 76% precision and 80% recall


Comparison with human experts:

Approach: Compared ScenarioAmigo's performance with three human experts on 183 sample scenarios
Metrics: Recall
Results: ScenarioAmigo achieved 20% higher recall than human experts


Significance of recommended steps:

Approach: Evaluated the importance of recommended steps by ScenarioAmigo and human experts
Metrics: Very Important, Important, Normal categories
Results: ScenarioAmigo recommended steps across all importance categories, performing better than or comparable to human experts



Limitations mentioned:

The approach may not be directly applicable to real-time systems, aerospace, or defense fields that do not use use case techniques.
The completeness of the training scenario set depends on expert judgment.
The approach focuses only on basic and alternative flows in use case specifications, not covering all components.",Yes,,ScenarioAmigo,Proposed in this paper,,"Detect, Measure, Correct"," Developed using Java, SWT, JUNG, WordNet, JAWS, Stanford Parser, and MySQL","Manage scenario lists for projects
Specify use case specifications
Automatically identify scenario patterns
Recommend steps for omitted parts in scenarios
Visualize scenario flow graphs and patterns","Implemented, Validated",Validated through three experiments as described in the Evaluation section above,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
2,Meincke 2020,"Requirements in the loop : A computer-Aided analysis of consistency, completeness, and correctness of requirements",Consensus,Yes,2,"Requirements in the loop: A computer-aided analysis of consistency, completeness and correctness of requirements",Germany,2020,Conference ,2020 IEEE 28th International Requirements Engineering Conference (RE),"Today many applications have safety-critical parts and their number of functions and their complexity increase. Although there are many techniques to make sure that the requirements are consistent, correct, complete and unambiguous, all of these aspects are inspected manually. In contrast to the resultant implementation of the requirements that can easily be simulated, requirements are not represented in a machine-readable format. Wouldn't it be a great benefit to have the ability to simulate requirements as well?
This paper will show an approach based on a simple control unit for a Beamer how requirements can be transformed in a machine-readable format and how to analyze their consistency, correctness and completeness. It will cover how to analyze an inconsistency issue and how it can be solved to get consistent set of requirements.",Yes,"Completeness is given if for each requirement a fulfilling trace was generated that obeys all other requirements.
Source: Proposed in this paper",Yes,,Completeness Analysis," Uses model checking technology to generate a system-under-test based on formalized requirements. For each requirement, it checks if there is a fulfilling trace that obeys all other requirements.",Proposed in this paper,,"The tool creates a system model from all formalized requirements. It then attempts to generate a trace (scenario) for each requirement that satisfies that requirement while also obeying all other requirements. If such a trace can be generated for all requirements, the set is considered complete. If any requirement lacks a fulfilling trace, it indicates incompleteness.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Yes,, Iterative Refinement Process,An iterative approach where formalization and analysis results are used to identify and correct issues in requirements., Proposed in this paper,,"Formalize requirements using the Universal Pattern language
Perform consistency and completeness analyses
Review analysis results, including any inconsistency traces or missing fulfilling traces
Modify or add requirements to address identified issues
Repeat the process until consistency and completeness are achieved",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"The paper provides a demonstration of the approach using a simple LCD projector control unit example. The evaluation includes:
Evaluation approaches:

Case study / demonstration with a simple control unit example
Manual analysis of formalized requirements and analysis results

Metrics or criteria:

Ability to detect and resolve inconsistencies
Ability to verify completeness of requirements
Ability to verify correctness against test cases

Key results and findings:

The approach successfully identified an inconsistency between two requirements in the example
After correction, the approach verified consistency and completeness of the requirements
A test case was used to verify correctness of a specific requirement

Limitations mentioned:

The approach requires more time in the early stages of a project
Practical implementation may face challenges due to established processes and habits",Yes,,BTC EmbeddedPlatform,Proposed in this paper,,"Detect, Measure, Correct",Software tool implementing the Universal Pattern language for requirement formalization and model checking for analysis,"Imports requirements from various sources (e.g., Excel)
Provides a graphical interface for formalizing requirements using the Simplified Universal Pattern language
Performs consistency, completeness, and correctness analyses using model checking
Generates traces for inconsistencies and completeness verification
Allows creation and verification of test cases for correctness checking
","Implemented, Validated
","Demonstrated through a case study with a simple LCD projector control unit. The tool successfully identified inconsistencies, verified completeness after corrections, and allowed correctness checking through test cases.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,No,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
